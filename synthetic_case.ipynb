{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.special import logsumexp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "import geometry\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "import target\n",
    "import controler\n",
    "import utils\n",
    "from functools import reduce\n",
    "import linear_regression\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import geometry\n",
    "import itertools \n",
    "from itertools import islice\n",
    "import games\n",
    "import feedexp3\n",
    "import geometry_v2\n",
    "\n",
    "def evaluate_parallel(nbCores, n_folds, horizon, alg, game):\n",
    "    print(\"nbCores:\", nbCores, \"nbFolds:\", n_folds, \"Horizon:\", horizon)\n",
    "    pool = Pool(processes = nbCores) \n",
    "    task = Evaluation(horizon, outcome_distribution)\n",
    "    return np.asarray(  pool.map( partial( task.eval_policy_once, alg, game ), range(n_folds) ) ) \n",
    "\n",
    "def runif_in_simplex(n):\n",
    "  ''' Return uniformly random vector in the n-simplex '''\n",
    "  k = np.random.exponential(scale=1.0, size=n)\n",
    "  return k / sum(k)\n",
    "\n",
    "class Evaluation:\n",
    "\n",
    "    def __init__(self, horizon, outcome_distribution ):\n",
    "\n",
    "        self.horizon = horizon\n",
    "        self.outcome_distribution = outcome_distribution\n",
    "\n",
    "    def get_outcomes(self, game, job_id):\n",
    "        np.random.seed(job_id)\n",
    "        # self.means = runif_in_simplex( self.game.n_outcomes )\n",
    "        outcomes = np.random.choice( game.n_outcomes , p=self.outcome_distribution, size= self.horizon) \n",
    "        return outcomes\n",
    "\n",
    "    def get_feedback(self, game, action, outcome):\n",
    "        return game.FeedbackMatrix[ action ][ outcome ]\n",
    "\n",
    "    def eval_policy_once(self, alg, game, jobid):\n",
    "\n",
    "        cumRegret = np.zeros( self.horizon )\n",
    "        cumSufferedLoss = 0\n",
    "        cumAllLosses = np.zeros( game.n_actions )\n",
    "\n",
    "        # generate outcomes obliviously\n",
    "        outcomes = self.get_outcomes(game, jobid)\n",
    "\n",
    "        for t in range(self.horizon):\n",
    "\n",
    "            # policy chooses one action\n",
    "            action = alg.get_action(t)\n",
    "\n",
    "            # Environment chooses one outcome\n",
    "            outcome = outcomes[t]\n",
    "            feedback =  self.get_feedback(game, action, outcome )\n",
    "\n",
    "            alg.update(game,  action, feedback)\n",
    "            # print('outcome', outcome, 'action',action, 'eta', alg.eta, 'gamma', alg.gamma, 'pbt',alg.pbt, 'pbt_hat', alg.pbt_hat)\n",
    "\n",
    "            # policy suffers loss and regret\n",
    "            cumAllLosses += game.LossMatrix[...,outcome]\n",
    "            cumSufferedLoss += game.LossMatrix[action,outcome]\n",
    "            cumRegret[t] = cumSufferedLoss - min(cumAllLosses)\n",
    "\n",
    "        return cumRegret\n",
    "\n",
    "def eval_cpbvanilla_parallel(task, nbCores, n_folds, horizon, alpha):\n",
    "    print(\"nbCores:\", nbCores, \"nbFolds:\", n_folds, \"Horizon:\", horizon)\n",
    "    pool = Pool(processes = nbCores) \n",
    "    return np.asarray(  pool.map( partial( task.cpb_vanilla_v2 ,alpha ), range(n_folds) ) ) \n",
    "\n",
    "def runif_in_simplex(n):\n",
    "  ''' Return uniformly random vector in the n-simplex '''\n",
    "\n",
    "  k = np.random.exponential(scale=1.0, size=n)\n",
    "  return k / sum(k)\n",
    "\n",
    "class SyntheticCase:\n",
    "\n",
    "    def __init__(self, LossMatrix, FeedbackMatrix, horizon ):\n",
    " \n",
    "        self.LossMatrix = LossMatrix \n",
    "        self.FeedbackMatrix = FeedbackMatrix \n",
    "        \n",
    "\n",
    "        self.horizon = horizon\n",
    "        self.n_actions = len(self.LossMatrix)\n",
    "        self.n_outcomes = len(self.LossMatrix[0])\n",
    "\n",
    "    def set_outcomes(self, job_id):\n",
    "        np.random.seed(job_id)\n",
    "        #self.means = runif_in_simplex( len( LossMatrix[0] ) )\n",
    "        self.outcomes = np.random.choice( self.n_outcomes , p= [0.05, 0.95], size= self.horizon) # [0.05, 0.95]\n",
    "\n",
    "    def get_feedback(self, FeedbackMatrix, action, outcome):\n",
    "        return FeedbackMatrix[ action ][ outcome ] \n",
    "\n",
    "    def W(self, mathcal_N, N_bar, observer_vector ):\n",
    "        N = len(N_bar)\n",
    "        W = np.zeros( N )\n",
    "        for pair in mathcal_N:\n",
    "            for k in range(N):\n",
    "                value = np.fabs( observer_vector[ pair[0] ][ pair[1] ][k] ).max()\n",
    "                #print(value)\n",
    "                W[k] = max( W[k], value  )\n",
    "        return W\n",
    "\n",
    "    def cpb_vanilla_v2(self, alpha, job_id):\n",
    "\n",
    "        cumRegret = np.zeros( self.horizon )\n",
    "        cumSufferedLoss = 0\n",
    "        cumAllLosses = np.zeros( self.n_actions )\n",
    "\n",
    "        self.set_outcomes(job_id)\n",
    "\n",
    "        N_bar = set(range(self.n_actions))\n",
    "        M_bar = set(range(self.n_outcomes))\n",
    "        e = np.eye(self.n_outcomes)\n",
    "\n",
    "        n = np.zeros(self.n_actions)\n",
    "        nu = [  np.zeros( len( set(i) ) ) for i in self.FeedbackMatrix ] \n",
    "        N, M = LossMatrix.shape\n",
    "        \n",
    "        mathcal_P = [  i for i in N_bar if geometry.isParetoOptimal(i, LossMatrix)  ]#geometry.get_P_t([], LossMatrix) #geometry.getParetoOptimalActions(LossMatrix, []) #get_P_t(half_space, self.LossMatrix, mathcal_P, mathcal_N) #[ a for a in N_bar if geometry.isParetoOptimal(a, self.LossMatrix )] # set of pareto optimal actions\n",
    "        mathcal_N = [ [i,j] for i in N_bar for j in N_bar if geometry.areNeighbours(i,j,LossMatrix) ]#geometry.get_N_t([], self.LossMatrix) #geometry.getNeighbors(LossMatrix, []) #[ pair for pair in list( itertools.combinations(N_bar, 2) ) if geometry.areNeighbours(pair[0], pair[1], self.LossMatrix ) ] #set of unordered neighboring actions\n",
    "        print('mathcal_P',mathcal_P)\n",
    "        print('mathcal_N',mathcal_N)\n",
    "        mathcal_N_plus = collections.defaultdict(dict)\n",
    "        for pair in mathcal_N:\n",
    "            mathcal_N_plus[ pair[0] ][ pair[1] ] = geometry.get_neighborhood_action_set(pair, N_bar, self.LossMatrix )\n",
    "        print('neighborhood action set:', mathcal_N_plus)\n",
    "\n",
    "        S_vectors = [ np.array([ [1],[1] ]), np.array([ [0,1],[1,0]] ) ] #geometry.global_signal(FeedbackMatrix) #geometry.get_signal_matrices(self.FeedbackMatrix)\n",
    "        print('S vectors', S_vectors)\n",
    "\n",
    "        # print('mathcalP', mathcal_P)\n",
    "        # print('mathcalN', mathcal_N)\n",
    "        # observer_set = collections.defaultdict(dict)\n",
    "        # for pair in mathcal_N : \n",
    "        #     if geometry.ObservablePair(pair[0], pair[1], self.LossMatrix, [geometry.signal_vecs(i, self.FeedbackMatrix) for i in geometry.Neighbourhood(pair[0], pair[1], self.LossMatrix )]):\n",
    "        #         observer_set [ pair[0] ][ pair[1] ] =   mathcal_N_plus[ pair[0] ][ pair[1] ] \n",
    "        #     else:\n",
    "        #         observer_set [ pair[0] ][ pair[1] ] = None\n",
    "        #         print('Observer set -- not implemented')\n",
    "\n",
    "        observer_vector = collections.defaultdict(dict)\n",
    "        for pair in mathcal_N :\n",
    "            # print('pair', pair)\n",
    "            observer_vector[ pair[0] ][ pair[1] ] = geometry_v2.get_observer_vector(pair ,self.LossMatrix ,self.FeedbackMatrix, S_vectors ) #geometry.get_observer_vector_v2(pair, LossMatrix, FeedbackMatrix ) \n",
    "        print( 'Observer vectors', observer_vector )\n",
    "\n",
    "\n",
    "        W = self.W( mathcal_N, N_bar, observer_vector )\n",
    "        print('W', W)\n",
    "\n",
    "        # print('mathcal P', mathcal_P)\n",
    "        # print('mathcal N', mathcal_N)\n",
    "\n",
    "        for t in range(self.n_actions):\n",
    "\n",
    "            action  = t\n",
    "            outcome = self.outcomes[t]\n",
    "            Y = geometry.signal_vecs(action, self.FeedbackMatrix) @ e[outcome]\n",
    "            n[action] += 1\n",
    "            nu[action] += Y\n",
    "\n",
    "            # policy suffers loss and regret\n",
    "            cumAllLosses += self.LossMatrix[...,outcome]\n",
    "            cumSufferedLoss += self.LossMatrix[action,outcome]\n",
    "            cumRegret[t] = cumSufferedLoss - min(cumAllLosses)\n",
    "\n",
    "                    \n",
    "        for t in range(self.n_actions, self.horizon):\n",
    "\n",
    "            mathcal_P_t = mathcal_P\n",
    "            mathcal_N_t = mathcal_N\n",
    "\n",
    "            outcome = self.outcomes[t]\n",
    "            half_space = []\n",
    "\n",
    "            for pair in mathcal_N:\n",
    "                # print( 'inside', [  observer_vector[ pair[0] ][ pair[1] ][k].T * v[k]/n[k]   for k in mathcal_N_plus ] )\n",
    "                d_ij, c = 0, 0 \n",
    "                for k in range(N):\n",
    "                    # print('observer vector',observer_vector[ pair[0] ][ pair[1] ][k],'nu',nu[k] )\n",
    "                    d_ij +=   observer_vector[ pair[0] ][ pair[1] ][k].T @ nu[k]  / n[k] \n",
    "                    c += np.fabs(  observer_vector[ pair[0] ][ pair[1] ][k] ).max()  * np.sqrt(alpha * np.log(t) / n[k] )  \n",
    "                # print('pair',pair,'d_ij',d_ij, 'c', c)\n",
    "                        \n",
    "                if abs( d_ij ) >= c:\n",
    "                    half_space.append(  ( pair, np.sign(d_ij) ) )\n",
    "                else:\n",
    "                    half_space.append(  ( pair, 0 ) )\n",
    "\n",
    "            print('halfspace',half_space)\n",
    "\n",
    "            # print('halfspace', half_space)\n",
    "\n",
    "            #print('P before:',mathcal_P)\n",
    "            mathcal_P_t = geometry.get_P_t(half_space, LossMatrix)#geometry.getParetoOptimalActions(LossMatrix, half_space) #get_P_t(half_space, self.LossMatrix, mathcal_P, mathcal_N)\n",
    "            print('mathcal_P_t',mathcal_P)\n",
    "\n",
    "            #print('N before:',mathcal_N)\n",
    "            mathcal_N_t = geometry.get_N_t(half_space, self.LossMatrix) #getNeighbors(LossMatrix, half_space) #get_N_t(half_space, self.LossMatrix, mathcal_P, mathcal_N)\n",
    "            print('mathcal_N_t:',mathcal_N_t)\n",
    "            #print()\n",
    "\n",
    "            \n",
    "            #print('mathcal_n_plus', mathcal_N_plus)\n",
    "            Q = reduce( np.union1d, [ mathcal_N_plus[ pair[0] ][ pair[1] ]  for pair in mathcal_N_t ]  )\n",
    "            # print('Q', Q)\n",
    "            values = [ W[k]**2/n[k] for k in Q ]\n",
    "            \n",
    "            action = np.argmax(values)\n",
    "            Y = S_vectors[action] @ e[outcome]\n",
    "            n[action] += 1\n",
    "            nu[action] += Y\n",
    "\n",
    "            # print('values', values, 'action', action, 'n', n, 'nu', nu)\n",
    "\n",
    "            # policy suffers loss and regret\n",
    "            cumAllLosses += self.LossMatrix[...,outcome]\n",
    "            cumSufferedLoss += self.LossMatrix[action,outcome]\n",
    "            cumRegret[t] = cumSufferedLoss - min(cumAllLosses)\n",
    "\n",
    "        return np.array(cumRegret)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "n_cores = 16\n",
    "horizon = 100\n",
    "n_folds = 25\n",
    "\n",
    "LossMatrix = np.array( [ [1, 0], [0, 1] ] )\n",
    "FeedbackMatrix =  np.array([ [1, 1],[1, 0] ])\n",
    "\n",
    "task = SyntheticCase(LossMatrix, FeedbackMatrix, horizon) \n",
    "result = task.cpb_vanilla_v2( 1.1, 2)  \n",
    "plt.plot(result)\n",
    "\n",
    "# result =  eval_feedexp_parallel(task, n_cores, n_folds, horizon, True, 'Piccolboni' ) \n",
    "# plt.plot(  np.mean( result , 0 ) , label = 'Piccolboni', color = 'green' )\n",
    "\n",
    "# result =  eval_feedexp_parallel(task, n_cores, n_folds, horizon, True, 'Bianchi' ) \n",
    "# plt.plot(  np.mean( result , 0 ) , label = 'Bianchi', color = 'orange' )\n",
    "\n",
    "# plt.legend()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "open polytope A 1-dimensional polyhedron in QQ^2 defined as the convex hull of 2 points\n",
      "Ci_inter_Cj A 1-dimensional polyhedron in QQ^2 defined as the convex hull of 1 point, 1 ray\n",
      "intersection:,  A 1-dimensional polyhedron in QQ^2 defined as the convex hull of 2 points\n",
      "open polytope A 1-dimensional polyhedron in QQ^2 defined as the convex hull of 2 points\n",
      "Ci_inter_Cj A 0-dimensional polyhedron in QQ^2 defined as the convex hull of 1 point\n",
      "intersection:,  A 0-dimensional polyhedron in QQ^2 defined as the convex hull of 1 point\n",
      "open polytope A 1-dimensional polyhedron in QQ^2 defined as the convex hull of 2 points\n",
      "Ci_inter_Cj A 0-dimensional polyhedron in QQ^2 defined as the convex hull of 1 point\n",
      "intersection:,  A 0-dimensional polyhedron in QQ^2 defined as the convex hull of 1 point\n",
      "open polytope A 1-dimensional polyhedron in QQ^2 defined as the convex hull of 2 points\n",
      "Ci_inter_Cj A 1-dimensional polyhedron in QQ^2 defined as the convex hull of 1 point, 1 ray\n",
      "intersection:,  A 1-dimensional polyhedron in QQ^2 defined as the convex hull of 2 points\n",
      "mathcal_P [0, 1]\n",
      "mathcal_N []\n",
      "neighborhood action set: defaultdict(<class 'dict'>, {})\n",
      "S vectors [array([[1],\n",
      "       [1]]), array([[0, 1],\n",
      "       [1, 0]])]\n",
      "Observer vectors defaultdict(<class 'dict'>, {})\n",
      "W [0. 0.]\n",
      "halfspace []\n",
      "mathcal_P_t [0, 1]\n",
      "open polytope A 1-dimensional polyhedron in QQ^2 defined as the convex hull of 2 points\n",
      "Ci_inter_Cj A 1-dimensional polyhedron in QQ^2 defined as the convex hull of 1 point, 1 ray\n",
      "intersection:,  A 1-dimensional polyhedron in QQ^2 defined as the convex hull of 2 points\n",
      "open polytope A 1-dimensional polyhedron in QQ^2 defined as the convex hull of 2 points\n",
      "Ci_inter_Cj A 0-dimensional polyhedron in QQ^2 defined as the convex hull of 1 point\n",
      "intersection:,  A 0-dimensional polyhedron in QQ^2 defined as the convex hull of 1 point\n",
      "open polytope A 1-dimensional polyhedron in QQ^2 defined as the convex hull of 2 points\n",
      "Ci_inter_Cj A 0-dimensional polyhedron in QQ^2 defined as the convex hull of 1 point\n",
      "intersection:,  A 0-dimensional polyhedron in QQ^2 defined as the convex hull of 1 point\n",
      "open polytope A 1-dimensional polyhedron in QQ^2 defined as the convex hull of 2 points\n",
      "Ci_inter_Cj A 1-dimensional polyhedron in QQ^2 defined as the convex hull of 1 point, 1 ray\n",
      "intersection:,  A 1-dimensional polyhedron in QQ^2 defined as the convex hull of 2 points\n",
      "mathcal_N_t: []\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "reduce() of empty sequence with no initial value",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m FeedbackMatrix \u001b[38;5;241m=\u001b[39m  np\u001b[38;5;241m.\u001b[39marray([ [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m],[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m] ])\n\u001b[1;32m      8\u001b[0m task \u001b[38;5;241m=\u001b[39m SyntheticCase(LossMatrix, FeedbackMatrix, horizon) \n\u001b[0;32m----> 9\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpb_vanilla_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(result)\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mSyntheticCase.cpb_vanilla_v2\u001b[0;34m(self, alpha, job_id)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmathcal_N_t:\u001b[39m\u001b[38;5;124m'\u001b[39m,mathcal_N_t)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m#print()\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \n\u001b[1;32m    237\u001b[0m \n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m#print('mathcal_n_plus', mathcal_N_plus)\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m Q \u001b[38;5;241m=\u001b[39m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munion1d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43mmathcal_N_plus\u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43mpair\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43mpair\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpair\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmathcal_N_t\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# print('Q', Q)\u001b[39;00m\n\u001b[1;32m    241\u001b[0m values \u001b[38;5;241m=\u001b[39m [ W[k]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39mn[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m Q ]\n",
      "\u001b[0;31mTypeError\u001b[0m: reduce() of empty sequence with no initial value"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "n_cores = 16\n",
    "n_folds = 25\n",
    "horizon = 100\n",
    "\n",
    "outcome_distribution = [0.05, 0.95] "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "game = games.apple_tasting(False)\n",
    "\n",
    "alg = feedexp3.FeedExp3(  game, horizon, 'Bianchi',)\n",
    "result1 = evaluate_parallel(n_cores, n_folds, horizon, alg, game)\n",
    "plt.plot(  np.mean( result1 , 0 ) , label = 'Bianchi', color = 'green' )\n",
    "\n",
    "alg = feedexp3.FeedExp3(  game, horizon, 'Piccolboni',)\n",
    "result2 = evaluate_parallel(n_cores, n_folds, horizon, alg, game)\n",
    "plt.plot(  np.mean( result2 , 0 ) , label = 'Piccolboni', color = 'orange' )\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# result = evaluate_parallel(n_cores, n_folds, horizon, feedexp3, game)\n",
    "\n",
    "# task = Evaluation(horizon, outcome_distribution)\n",
    "# result = task.eval_policy_once(feedexp3, game, 30)\n",
    "# plt.plot(result)\n",
    "\n",
    "# result =  eval_feedexp_parallel(task, n_cores, n_folds, horizon, True, 'Piccolboni' ) \n",
    "# plt.plot(  np.mean( result , 0 ) , label = 'Piccolboni', color = 'green' )\n",
    "\n",
    "# result =  eval_feedexp_parallel(task, n_cores, n_folds, horizon, True, 'Bianchi' ) \n",
    "# plt.plot(  np.mean( result , 0 ) , label = 'Bianchi', color = 'orange' )\n",
    "\n",
    "# plt.legend()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nbCores: 16 nbFolds: 25 Horizon: 100\n",
      "nbCores: 16 nbFolds: 25 Horizon: 100\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f88d0063a90>"
      ]
     },
     "metadata": {},
     "execution_count": 41
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "game = games.bandit(False)\n",
    "\n",
    "alg = feedexp3.FeedExp3(  game, horizon, 'Bianchi',)\n",
    "result = evaluate_parallel(n_cores, n_folds, horizon, alg, game)\n",
    "plt.plot(  np.mean( result , 0 ) , label = 'Bianchi', color = 'green' )\n",
    "\n",
    "alg = feedexp3.FeedExp3(  game, horizon, 'Piccolboni',)\n",
    "result = evaluate_parallel(n_cores, n_folds, horizon, alg, game)\n",
    "plt.plot(  np.mean( result , 0 ) , label = 'Piccolboni', color = 'orange' )\n",
    "\n",
    "plt.legend()\n",
    "# task = Evaluation(horizon, outcome_distribution)\n",
    "# result = task.eval_policy_once(feedexp3, game, 30)\n",
    "# plt.plot(result)\n",
    "\n",
    "# result =  eval_feedexp_parallel(task, n_cores, n_folds, horizon, True, 'Piccolboni' ) \n",
    "\n",
    "\n",
    "# result =  eval_feedexp_parallel(task, n_cores, n_folds, horizon, True, 'Bianchi' ) \n",
    "# plt.plot(  np.mean( result , 0 ) , label = 'Bianchi', color = 'orange' )\n",
    "\n",
    "# plt.legend()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "game = games.label_efficient()\n",
    "\n",
    "alg = feedexp3.FeedExp3(  game, horizon, 'Bianchi',)\n",
    "result1 = evaluate_parallel(n_cores, n_folds, horizon, alg, game)\n",
    "plt.plot(  np.mean( result1 , 0 ) , label = 'Bianchi', color = 'green' )\n",
    "\n",
    "alg = feedexp3.FeedExp3(  game, horizon, 'Piccolboni',)\n",
    "result2 = evaluate_parallel(n_cores, n_folds, horizon, alg, game)\n",
    "plt.plot(  np.mean( result2 , 0 ) , label = 'Piccolboni', color = 'orange' )\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# task = Evaluation(horizon, outcome_distribution)\n",
    "# result = task.eval_policy_once(feedexp3, game, 30)\n",
    "# plt.plot(result)\n",
    "\n",
    "# result =  eval_feedexp_parallel(task, n_cores, n_folds, horizon, True, 'Piccolboni' ) \n",
    "# plt.plot(  np.mean( result , 0 ) , label = 'Piccolboni', color = 'green' )\n",
    "\n",
    "# result =  eval_feedexp_parallel(task, n_cores, n_folds, horizon, True, 'Bianchi' ) \n",
    "# plt.plot(  np.mean( result , 0 ) , label = 'Bianchi', color = 'orange' )\n",
    "\n",
    "# plt.legend()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import ppl\n",
    "M = 2\n",
    "p = [ppl.Variable(j) for j in range(M)]\n",
    "    \n",
    "# declare polytope constraints\n",
    "cs = ppl.Constraint_System()\n",
    "    \n",
    "# probabilies constraints on p\n",
    "cs.insert( sum( p[j] for j in range(M)) == 1 )\n",
    "for j in range(M):\n",
    "    cs.insert(p[j] >= 0)\n",
    "\n",
    "cs.insert(p[0] - p[1] <= 0)   \n",
    "cs.insert(p[1] - p[0] <= 0)   \n",
    "\n",
    "poly = ppl.C_Polyhedron(cs)\n",
    "\n",
    "poly.minimized_generators()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('climate-ai': conda)"
  },
  "interpreter": {
   "hash": "0215ed8d73c40df5de54d647d65b604dcf02460a7de2b27ed9878602c67cf72c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}