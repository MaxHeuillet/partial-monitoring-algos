{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "import geometry\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "import target\n",
    "import controler\n",
    "import utils\n",
    "from functools import reduce\n",
    "import linear_regression\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "class SyntheticCase:\n",
    "\n",
    "    def __init__(self, LossMatrix, FeedbackMatrix, horizon ):\n",
    " \n",
    "        self.LossMatrix = LossMatrix \n",
    "        self.FeedbackMatrix = FeedbackMatrix \n",
    "        self.horizon = horizon\n",
    "        self.n_actions = len(self.LossMatrix)\n",
    "\n",
    "    def parameters_Bianchi(self, C):\n",
    "        # [Bianchi et al. 2006 \"Regret minimization under partial monitoring\"]\n",
    "        eta = 1 / C * pow( np.log( self.n_actions ) / ( self.n_actions * self.horizon ) , 2./3.) \n",
    "        gamma = C * pow( ( np.log( self.n_actions ) * self.n_actions **2) / self.horizon , 1./3.)\n",
    "        return eta, gamma \n",
    "\n",
    "    def parameters_Piccolboni(self, ):\n",
    "        ## [Piccolboni Schindelhauer \"Discrete Prediction Games with Arbitrary Feedback and Loss\" 2000]\n",
    "        ## fixed-known-horizon settings\n",
    "        eta = pow( np.log(self.n_actions), 1./2.) / pow(self.horizon, 1./2.)\n",
    "        gamma = np.fmin(1., pow(self.n_actions, 1./2.) * pow( np.log(self.n_actions),1./4.) / pow(self.horizon, 1./4.))\n",
    "        return eta, gamma\n",
    "        \n",
    "    def feedexp3(self, method, job_id):\n",
    "        np.random.seed(job_id)\n",
    "\n",
    "        self.LinkMatrix = np.linalg.lstsq(self.FeedbackMatrix, self.LossMatrix,rcond=None )[0]\n",
    "        k_star = max( [1, np.fabs(self.LinkMatrix).max() ] )\n",
    "        C = pow( k_star * np.sqrt(np.exp(1.)-2.), 2./3.)\n",
    "\n",
    "        w = np.ones(self.n_actions)\n",
    "        cumRegret = []\n",
    "        cumAllLosses, cumSufferedLoss = 0 , 0 \n",
    "\n",
    "        if method == 'Bianchi' :\n",
    "            eta, gamma = self.parameters_Bianchi(C) \n",
    "        else:\n",
    "            eta, gamma = self.parameters_Piccolboni()\n",
    "\n",
    "        for t in range(self.horizon):\n",
    "\n",
    "            pbt = [ (1-gamma) * w[i] / sum(w)  + gamma/self.n_actions for i in range(self.n_actions)]\n",
    "            action = np.random.choice([0,1], p=pbt )\n",
    "\n",
    "            outcome = np.random.choice([0,1], p=[0.9, 0.1] )\n",
    "            feedback = self.FeedbackMatrix[action, outcome]\n",
    "\n",
    "            for i in range(self.n_actions):\n",
    "                l_i = self.LinkMatrix[i,action] * feedback / pbt[action]\n",
    "                w[i] = w[i] * np.exp(-eta * l_i)\n",
    "\n",
    "            # policy suffers loss and regret\n",
    "            cumAllLosses += self.LossMatrix[...,outcome]\n",
    "            cumSufferedLoss += self.LossMatrix[action,outcome]\n",
    "            cumRegret.append(  cumSufferedLoss - min(cumAllLosses) )\n",
    "\n",
    "        return np.array(cumRegret)\n",
    "\n",
    "    def f(self, alpha, t):\n",
    "        return (alpha ** 1/3) * (t**2/3) * ( np.log(t)**1/3 )\n",
    "\n",
    "    def W_k(self, L, H, pair,mathcal_N_plus):\n",
    "        v_ij = geometry.observer_vector(L, H, pair[0], pair[1], mathcal_N_plus)[1]\n",
    "\n",
    "        res =  max( [ np.fabs( v_ij[k]).max() for k in mathcal_N_plus ]  )\n",
    "        # print(res)\n",
    "        return res\n",
    "\n",
    "    # def get_confidence(x_t, t):\n",
    "    #     d = 1 # what is the value of d?\n",
    "    #     res = d * np.sqrt( d * np.log(t) + 2 * np.log( 1/ d_t)  )  * np.norm( x_t )\n",
    "    #     return \n",
    "\n",
    "    def cpb_vanilla(self,):\n",
    "\n",
    "        cumRegret = []\n",
    "        cumAllLosses, cumSufferedLoss = 0 , 0 \n",
    "        \n",
    "        alpha = 1.1 # alpha > 1\n",
    "        L = np.array([ [0,1],[1,0] ])\n",
    "        H = np.array([ [1., 1.], [1., 0.] ] )\n",
    "        N_bar = [0,1]\n",
    "        N = len(L)\n",
    "        n = np.zeros(N)\n",
    "        v = np.zeros(N)\n",
    "        mathcal_P = [ a for a in N_bar if geometry.isParetoOptimal(1, L)] # set of pareto optimal actions\n",
    "        mathcal_N = [ pair for pair in list( itertools.combinations([0,1], 2) ) if geometry.areNeighbours(pair[0], pair[1], L) ] #set of unordered neighboring actions\n",
    "\n",
    "        #mathcal_N_plus = [ geometry.get_neighborhood_action_set(pair, N_bar, L) for pair in mathcal_N] \n",
    "\n",
    "        mathcal_N_plus = [ geometry.get_neighborhood_action_set(pair, N_bar, L) for pair in mathcal_N]  #neighborhood action set of pair \n",
    "        v_ij = [ geometry.observer_vector(L, H, pair[0], pair[1], mathcal_N_plus) for pair in mathcal_N]\n",
    "        print(v_ij)\n",
    "\n",
    "        outcomes = np.random.choice([0,1], p=[0.9, 0.1],size= self.horizon)\n",
    "\n",
    "        for t in range(self.horizon):\n",
    "\n",
    "            if t < N:  # initialisation\n",
    "                I  = t\n",
    "                J = outcomes[t]\n",
    "                feedback = H[ I ][ J ]\n",
    "                n[I] += 1\n",
    "                v[I] += feedback\n",
    "\n",
    "                cumAllLosses += L[...,J]\n",
    "                cumSufferedLoss += L[I,J]\n",
    "                cumRegret.append(  cumSufferedLoss - min(cumAllLosses) )\n",
    "\n",
    "            else: \n",
    "                break\n",
    "                \n",
    "        for t in range(self.horizon):\n",
    "            J = outcomes[t]\n",
    "            half_space = collections.defaultdict(dict)\n",
    "\n",
    "            if t >= N:\n",
    "\n",
    "                for pair in mathcal_N:\n",
    "    \n",
    "                    d_ij = sum( [  v_ij[1][k].T * v[k]/n[k]   for k in mathcal_N_plus ] )\n",
    "                    c_ij = sum( [  np.fabs( v_ij[1][k]).max()  * np.sqrt(alpha * np.log(t) / n[k] )    for k in mathcal_N_plus ] )\n",
    "\n",
    "                    if abs( d_ij ) >= c_ij:\n",
    "                        half_space[ pair[0] ][ pair[1] ] = np.sign(d_ij)\n",
    "                    else:\n",
    "                        half_space[ pair[0] ][ pair[1] ] = 0\n",
    "\n",
    "                mathcal_P, mathcal_N = geometry.get_polytope(half_space, L, mathcal_P, mathcal_N)\n",
    "\n",
    "                Q = [  ]\n",
    "                for k in N_bar:\n",
    "                    for pair in mathcal_N:\n",
    "                        mathcal_N_plus =  geometry.Neighbourhood(pair[0], pair[1], L)\n",
    "                        if k in mathcal_N_plus:\n",
    "                            Q.append(k)\n",
    "\n",
    "                \n",
    "                values = [ self.W_k(L, H, pair,mathcal_N_plus)/n[k] for k in Q ]\n",
    "                print('values', values)\n",
    "                \n",
    "                I = np.argmax(values)\n",
    "                feedback = H[ I ][ J ]\n",
    "                n[I] += 1\n",
    "                v[I] += feedback\n",
    "\n",
    "                cumAllLosses += L[...,J]\n",
    "                cumSufferedLoss += L[I,J]\n",
    "                cumRegret.append(  cumSufferedLoss - min(cumAllLosses) )\n",
    "\n",
    "        return np.array(cumRegret)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eval_policy_parallel(nbCores, nbReps, horizon, method):\n",
    "    LossMatrix, FeedbackMatrix = np.array([ [1., 0.], [0., 1.] ]) , np.array([ [1., 1.], [1., 0.] ] )\n",
    "    print(\"nbCores:\", nbCores, \"nbReps:\", nbReps, \"Horizon:\", horizon)\n",
    "    pool = Pool(processes = nbCores) \n",
    "    task = SyntheticCase(LossMatrix, FeedbackMatrix, horizon) \n",
    "    return np.asarray(  pool.map( partial(task.feedexp3,method), range(nbReps) ) ) \n",
    "\n",
    "\n",
    "\n",
    "n_cores = 1\n",
    "horizon = 1000\n",
    "n_folds = 5\n",
    "\n",
    "LossMatrix, FeedbackMatrix = np.array([ [1., 0.], [0., 1.] ]) , np.array([ [1., 1.], [1., 0.] ] )\n",
    "task = SyntheticCase(LossMatrix, FeedbackMatrix, horizon) \n",
    "result = task.cpb_vanilla()\n",
    "plt.plot( result, label = 'CPB-vanilla' )\n",
    "\n",
    "# result = eval_policy_parallel(n_cores, n_folds, horizon,'Bianchi' )\n",
    "# mean = np.mean(  result,0)\n",
    "# plt.plot( mean, label = 'Bianchi' )\n",
    "# plt.fill_between( range(horizon), mean -  np.std(result, axis=0) / np.sqrt(n_folds), mean +  np.std(result, axis=0) / np.sqrt(n_reps), alpha=0.2, color = 'blue') \n",
    "\n",
    "# result = eval_policy_parallel(n_cores, n_folds, horizon,'Picolboni' )\n",
    "# mean = np.mean(  result,0)\n",
    "# plt.plot( mean, label = 'Picolboni' )\n",
    "# plt.fill_between( range(horizon), mean -  np.std(result, axis=0) / np.sqrt(n_folds), mean +  np.std(result, axis=0) / np.sqrt(n_reps), alpha=0.5, color = 'orange') \n",
    "\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.ylabel('Cumulative Regret')\n",
    "# plt.legend()\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n",
      "True\n",
      "[[array([-0.,  1.])]]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/mheuillet/Desktop/attack-detection/geometry.py:40: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  x, res, rank, s = np.linalg.lstsq(A.T, Lij)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 203>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m LossMatrix, FeedbackMatrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([ [\u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m0.\u001b[39m], [\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m1.\u001b[39m] ]) , np\u001b[38;5;241m.\u001b[39marray([ [\u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m1.\u001b[39m], [\u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m0.\u001b[39m] ] )\n\u001b[1;32m    202\u001b[0m task \u001b[38;5;241m=\u001b[39m SyntheticCase(LossMatrix, FeedbackMatrix, horizon) \n\u001b[0;32m--> 203\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpb_vanilla\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot( result, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCPB-vanilla\u001b[39m\u001b[38;5;124m'\u001b[39m )\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mSyntheticCase.cpb_vanilla\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m N:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m mathcal_N:\n\u001b[0;32m--> 153\u001b[0m         d_ij \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m( [  v_ij[\u001b[38;5;241m1\u001b[39m][k]\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m*\u001b[39m v[k]\u001b[38;5;241m/\u001b[39mn[k]   \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m mathcal_N_plus ] )\n\u001b[1;32m    154\u001b[0m         c_ij \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m( [  np\u001b[38;5;241m.\u001b[39mfabs( v_ij[\u001b[38;5;241m1\u001b[39m][k])\u001b[38;5;241m.\u001b[39mmax()  \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(alpha \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(t) \u001b[38;5;241m/\u001b[39m n[k] )    \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m mathcal_N_plus ] )\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m( d_ij ) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m c_ij:\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m N:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m mathcal_N:\n\u001b[0;32m--> 153\u001b[0m         d_ij \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m( [  \u001b[43mv_ij\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m[k]\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m*\u001b[39m v[k]\u001b[38;5;241m/\u001b[39mn[k]   \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m mathcal_N_plus ] )\n\u001b[1;32m    154\u001b[0m         c_ij \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m( [  np\u001b[38;5;241m.\u001b[39mfabs( v_ij[\u001b[38;5;241m1\u001b[39m][k])\u001b[38;5;241m.\u001b[39mmax()  \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(alpha \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(t) \u001b[38;5;241m/\u001b[39m n[k] )    \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m mathcal_N_plus ] )\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m( d_ij ) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m c_ij:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import numpy as np\n",
    "import geometry\n",
    "import itertools \n",
    "L = np.array([ [0,1],[1,0] ])\n",
    "H = np.array([ ['no_feedback','no_feedback'], [0,1] ], dtype=object)\n",
    "N_bar = [0,1]\n",
    "mathcal_M = [0,1, 'no_feedback']\n",
    "N = len(L)\n",
    "n = np.zeros(N)\n",
    "mathcal_P = [ a for a in N_bar if geometry.isParetoOptimal(1, L)] # set of pareto optimal actions\n",
    "mathcal_N = [ pair for pair in list( itertools.combinations([0,1], 2) ) if geometry.areNeighbours(pair[0], pair[1], L) ] #set of unordered neighboring actions\n",
    "print(mathcal_N)\n",
    "mathcal_N_plus = collections.defaultdict(dict)\n",
    "for pair in mathcal_N:\n",
    "        mathcal_N_plus[ pair[0] ][ pair[1] ] = geometry.get_neighborhood_action_set(pair, N_bar, L)\n",
    "\n",
    "observer_set = collections.defaultdict(dict)\n",
    "for pair in mathcal_N : \n",
    "        if geometry.ObservablePair(pair[0], pair[1], L, [geometry.signal_vecs(i, H) for i in geometry.Neighbourhood(0, 1, L)]):\n",
    "                observer_set [ pair[0] ][ pair[1] ] =   mathcal_N_plus[ pair[0] ][ pair[1] ] \n",
    "        else:\n",
    "                observer_set [ pair[0] ][ pair[1] ] = None\n",
    "                print('Observer set -- not implemented')\n",
    "\n",
    "observer_vector = collections.defaultdict(dict)\n",
    "for pair in mathcal_N :\n",
    "        observer_set[ pair[0] ][ pair[1] ]  \n",
    "\n",
    "# Lij = L[0,...] - L[1,...]\n",
    "\n",
    "# observer_vector = []\n",
    "# for pair in mathcal_N:\n",
    "\n",
    "# observer_set = [   for pair in mathcal_N ]\n",
    "\n",
    "# A = np.vstack( A )\n",
    "# print(A)\n",
    "        \n",
    "        # np.vstack( global_signal(H) )\n",
    "        # v_ij = geometry.observer_vector(L, H, pair[0], pair[1], mathcal_N_plus)\n",
    "\n",
    "\n",
    "\n",
    "# def observer_vector(L, H, i, j, mathcal_K_plus):\n",
    "#     A = np.vstack( global_signal(H) )\n",
    "#     Lij = L[i,...] - L[j,...]\n",
    "#     # print('Lij', Lij)\n",
    "#     # print('globalsignal',global_signal(H))\n",
    "#     x, res, rank, s = np.linalg.lstsq(A.T, Lij) \n",
    "#     lenght = [ len( np.unique(H[k]) ) for k in mathcal_K_plus]\n",
    "#     x = iter( np.round(x) )\n",
    "#     return [ np.array( list(islice( x, i)) ) for i in lenght] \n",
    "\n",
    "# print( geometry.global_signal(H) )\n",
    "\n",
    "# print( geometry.signal_vecs(0, H) )\n",
    "# print( np.array(geometry.signal_vecs(1, H) ) )\n",
    "# product =  geometry.signal_vecs(0, H)[0] *  geometry.signal_vecs(1, H) \n",
    "# pinv = np.linalg.pinv( product )\n",
    "\n",
    "# print(product)\n",
    "# print(pinv)\n",
    "# print( Lij )\n",
    "# print( pinv * Lij )\n",
    "# print()\n",
    "# print( geometry.observer_vector(L, H, 0, 1, mathcal_N_plus[0]) )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, 1)]\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "geometry.global_signal(H)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[array([1., 1.])], [array([1., 0.]), array([0., 1.])]]"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "from itertools import islice\n",
    "\n",
    "def get_observer_vector(pair):\n",
    "    \n",
    "    Lij = L[pair[0],...] - L[pair[1],...]\n",
    "    S_vectors = [ geometry.signal_vecs(k, H) for k in observer_set[ pair[0] ][ pair[1] ] ]\n",
    "    print(S_vectors)\n",
    "    stacked_S =  np.linalg.pinv(  np.vstack( S_vectors ).T )\n",
    "\n",
    "    resultat = stacked_S * Lij \n",
    "    v_ij = resultat.T[0]\n",
    "    lenght = [ len(k)  for k in S_vectors]\n",
    "    v_ij = iter( v_ij )\n",
    "    return [ np.array( list( islice( v_ij, i)) ) for i in lenght] \n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-1  1]\n",
      "[[ 0.33333333  0.33333333]\n",
      " [ 0.66666667 -0.33333333]\n",
      " [-0.33333333  0.66666667]]\n",
      "[[-0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.33333333  0.66666667]]\n",
      "[-0.33333333 -0.66666667  0.33333333]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('climate-ai': conda)"
  },
  "interpreter": {
   "hash": "0215ed8d73c40df5de54d647d65b604dcf02460a7de2b27ed9878602c67cf72c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}