{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.special import logsumexp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "import geometry\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "import target\n",
    "import controler\n",
    "import utils\n",
    "from functools import reduce\n",
    "import linear_regression\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import geometry\n",
    "import itertools \n",
    "from itertools import islice\n",
    "import games\n",
    "import feedexp3\n",
    "import geometry_v2\n",
    "import cpb\n",
    "import feedexp3_v2\n",
    "import bpm\n",
    "import random_algo\n",
    "import feedexp3_v3\n",
    "import plotly.graph_objects as go\n",
    "import TSPM\n",
    "import eTSPM\n",
    "import ucbtspm\n",
    "\n",
    "def evaluate_parallel(nbCores, n_folds, horizon, alg, game):\n",
    "    print(\"nbCores:\", nbCores, \"nbFolds:\", n_folds, \"Horizon:\", horizon)\n",
    "    pool = Pool(processes = nbCores) \n",
    "    task = Evaluation(horizon)\n",
    "    return np.asarray(  pool.map( partial( task.eval_policy_once, alg, game ), range(n_folds) ) ) \n",
    "\n",
    "class Evaluation:\n",
    "\n",
    "    def __init__(self, horizon ):\n",
    "        self.horizon = horizon\n",
    "        # self.outcome_distribution = outcome_distribution\n",
    "\n",
    "    def get_outcomes(self, game, job_id):\n",
    "        # self.means = runif_in_simplex( self.game.n_outcomes )\n",
    "        outcomes = np.random.choice( game.n_outcomes , p= list( game.outcome_dist.values() ), size= self.horizon) \n",
    "        return outcomes\n",
    "\n",
    "    def get_feedback(self, game, action, outcome):\n",
    "        return game.FeedbackMatrix[ action ][ outcome ]\n",
    "\n",
    "    def eval_policy_once(self, alg, game, jobid):\n",
    "\n",
    "        np.random.seed(jobid)\n",
    "        \n",
    "        # outcome_distribution =  {'spam':0.05,'ham':0.95}\n",
    "\n",
    "        p = np.random.uniform(0,1)\n",
    "        outcome_distribution =  {'spam':p,'ham':1-p}\n",
    "\n",
    "        # p = get_easy() if game.mode == 'easy' else get_harsch() \n",
    "        # outcome_distribution =  {'a':p[0],'b':p[1],'c':p[2],'d':p[3],'e':p[4]}\n",
    "\n",
    "        game.set_outcome_distribution( outcome_distribution )\n",
    "        # print('optimal action', game.i_star)\n",
    "\n",
    "        action_counter = np.zeros( (game.n_actions, self.horizon) )\n",
    "\n",
    "        # generate outcomes obliviously\n",
    "        outcomes = self.get_outcomes(game, jobid)\n",
    "\n",
    "        for t in range(self.horizon):\n",
    "\n",
    "            # policy chooses one action\n",
    "            action = alg.get_action(t)\n",
    "\n",
    "            # Environment chooses one outcome\n",
    "            outcome = outcomes[t]\n",
    "\n",
    "            # print('t', t, 'action', action, 'outcome', outcome, )\n",
    "\n",
    "            feedback =  self.get_feedback( game, action, outcome )\n",
    "\n",
    "            alg.update(action, feedback, outcome)\n",
    "            \n",
    "            # print('nu', alg.nu / alg.n )\n",
    "\n",
    "            for i in range(game.n_actions):\n",
    "                if i == action:\n",
    "                    action_counter[i][t] = action_counter[i][t-1] +1\n",
    "                else:\n",
    "                    action_counter[i][t] = action_counter[i][t-1]\n",
    "\n",
    "        regret = np.array( [ game.delta(i) for i in range(game.n_actions) ]).T @ action_counter\n",
    "\n",
    "        return regret\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "n_cores = 16\n",
    "n_folds = 25\n",
    "horizon = 500\n",
    "\n",
    "game = games.apple_tasting(False)\n",
    "\n",
    "algos = [ random_algo.Random(  game, horizon, ), \n",
    "           feedexp3.FeedExp3(  game, horizon, ),\n",
    "           feedexp3_v3.FeedExp3(  game, horizon, ),\n",
    "           cpb.CPB(  game, horizon,),  \n",
    "           TSPM.TSPM_alg(  game, horizon,), \n",
    "           eTSPM.eTSPM_alg(  game, horizon, 1),\n",
    "           ucbtspm.ucbTSPM_alg(game, horizon)    ] #TSPM.TSPM_alg(  game, horizon,), bpm.BPM(  game, horizon,  [0.5, 0.5 ], np.identity(2) ) ,\n",
    "\n",
    "colors = [ [0,0,0], [29,176,0], [155,155,0], [255,0,0], [0,0,255] , [255,51,255], [255,20,200]  ] #\n",
    "labels = ['random', 'FeedExp3 (2001)', 'FeedExp3 (2006)', 'CPB',  'TSPM' , 'eTSPM (Auer)', 'ucbTSPM (Auer)'  ]  # \n",
    "fig = go.Figure( )\n",
    "\n",
    "for alg, color, label in zip( algos, colors, labels):\n",
    "\n",
    "    r,g,b = color\n",
    "    result = evaluate_parallel(n_cores, n_folds, horizon, alg, game)\n",
    "    regret = np.mean(result,0) \n",
    "    xcoords = np.arange(0,horizon,1).tolist()\n",
    "    std =  np.std(result,0) \n",
    "    upper_regret = regret + std\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b)), mode='lines',  name=label )) # \n",
    "\n",
    "    fig.add_trace(   go.Scatter( x=xcoords+xcoords[::-1], y=upper_regret.tolist()+regret.tolist()[::-1],  fill='toself', fillcolor='rgba({},{},{},0.2)'.format(r,g,b), \n",
    "                         line=dict(color='rgba(255,255,255,0)'),   hoverinfo=\"skip\",  showlegend=False )\n",
    "\n",
    "    )\n",
    "    \n",
    "fig.show(legend=True)\n",
    "fig.update_yaxes(range=[0, 30] )\n",
    "fig.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}