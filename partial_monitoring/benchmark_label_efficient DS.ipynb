{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from multiprocess import Pool\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "import itertools \n",
    "from itertools import islice\n",
    "import games\n",
    "\n",
    "import cpb\n",
    "import bpm\n",
    "import random_algo\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import TSPM\n",
    "\n",
    "import cpb_gaussian\n",
    "import PM_DMED\n",
    "import feedexp3_piccolboni\n",
    "from math import exp, pow\n",
    "\n",
    "def evaluate_parallel(nbCores, n_folds, horizon, alg, game, type):\n",
    "\n",
    "    print(\"nbCores:\", nbCores, \"nbFolds:\", n_folds, \"Horizon:\", horizon)\n",
    "    pool = Pool(processes = nbCores) \n",
    "    task = Evaluation(horizon, type)\n",
    "\n",
    "    np.random.seed(1)\n",
    "    distributions = []\n",
    "\n",
    "    for jobid in range(n_folds):\n",
    "\n",
    "        p_min = np.random.uniform(0, 0.2)\n",
    "        p_max = np.random.uniform(0.8,1.0)\n",
    "        distributions.append( [p_min, p_max] )\n",
    "\n",
    "    return np.asarray(  pool.map( partial( task.eval_policy_once, alg, game ), zip(distributions ,range(n_folds)) ) ) \n",
    "\n",
    "class Evaluation:\n",
    "\n",
    "    def __init__(self, horizon, type ):\n",
    "        self.horizon = horizon\n",
    "        self.type = type\n",
    "\n",
    "    def get_outcomes(self, game, job_id):\n",
    "        outcomes = np.random.choice( game.n_outcomes , p= list( game.outcome_dist.values() ), size= self.horizon) \n",
    "        return outcomes\n",
    "\n",
    "    def get_outcome(self, game, job_id):\n",
    "        outcome = np.random.choice( game.n_outcomes , p= list( game.outcome_dist.values() ) )\n",
    "        return outcome\n",
    "\n",
    "    def get_feedback(self, game, action, outcome):\n",
    "        return game.FeedbackMatrix[ action ][ outcome ]\n",
    "\n",
    "    def my_gauss(x, sigma=1, h=1, mid=0):\n",
    "        variance = pow(sigma, 2)\n",
    "        return h * exp(-pow(x-mid, 2)/(2*variance))\n",
    "\n",
    "    def attack_seasons(self, p_min, p_max, horizon, nb_changes = 3):\n",
    "        # res = False\n",
    "        # while res == False:\n",
    "        #     lengths = np.array( np.cumsum(   np.random.normal(horizon/nb_changes, 50, 3)  ) ,dtype = int )\n",
    "        #     if lengths[-1]<horizon:\n",
    "        #         res = True\n",
    "        # lengths = lengths.tolist()\n",
    "        # lengths.append(horizon)\n",
    "        lengths = [250,500,750, horizon]\n",
    "\n",
    "        init_outcome = 0 # np.random.randint(0,2,1)[0]\n",
    "        outcomes = []\n",
    "        for i in range(nb_changes+1):\n",
    "            if i == 0:\n",
    "                outcomes.append(init_outcome)\n",
    "            else:\n",
    "                outcomes.append(1-outcomes[i-1])\n",
    "\n",
    "        seq = [  ]\n",
    "        idx = 0\n",
    "        for i in range(horizon):\n",
    "            if i >= lengths[idx]:\n",
    "                idx +=1\n",
    "\n",
    "            if i < lengths[idx]  and outcomes[idx] == 0:\n",
    "                seq.append(p_min)\n",
    "            elif i < lengths[idx] and outcomes[idx] == 1:\n",
    "                seq.append(p_max)\n",
    "                \n",
    "        return seq\n",
    "\n",
    "    def eval_policy_once(self, alg, game, job):\n",
    "\n",
    "        alg.reset()\n",
    "\n",
    "        distribution, jobid = job\n",
    "        np.random.seed(jobid)\n",
    "\n",
    "        action_counter = np.zeros( (game.n_actions, self.horizon) )\n",
    "        cum_regret = []\n",
    "\n",
    "        if self.type == 'constant':\n",
    "            seq = [ distribution[0] for i in range(self.horizon) ]\n",
    "        if self.type == 'linear':\n",
    "            seq = np.geomspace(distribution[0], distribution[1], num=self.horizon)\n",
    "        elif self.type == 'exp':\n",
    "            seq = np.linspace(distribution[0], distribution[1], num=self.horizon)\n",
    "        elif self.type == 'gaussian':\n",
    "            x =  np.linspace(-20, 20, 1000) #np.linspace(norm.ppf(0.01,500, 1), norm.ppf(0.99,500, 1), 1000)\n",
    "            seq = [ my_gauss(i, sigma=3, h=b, mid=0) for i in x ]\n",
    "        elif self.type == 'realistic':\n",
    "            seq = self.attack_seasons(distribution[0],distribution[1],1000)\n",
    "\n",
    "        for t in range(self.horizon):\n",
    "\n",
    "            # policy chooses one action\n",
    "            action = alg.get_action(t)\n",
    "\n",
    "            # Environment chooses one outcome\n",
    "            outcome_distribution = {'spam':seq[t], 'ham':1-seq[t]}\n",
    "            game.set_outcome_distribution( outcome_distribution )\n",
    "            outcome = self.get_outcome(game, jobid)\n",
    "\n",
    "            #print('t', t, 'action', action, 'outcome', outcome, )\n",
    "\n",
    "            feedback =  self.get_feedback( game, action, outcome )\n",
    "\n",
    "            alg.update(action, feedback, outcome, None, t)\n",
    "            \n",
    "            # print('nu', alg.nu / alg.n )\n",
    "\n",
    "            for i in range(game.n_actions):\n",
    "                if i == action:\n",
    "                    action_counter[i][t] = action_counter[i][t-1] + 1\n",
    "                else:\n",
    "                    action_counter[i][t] = action_counter[i][t-1]\n",
    "\n",
    "        # regret = []\n",
    "        # for t in range(self.horizon):\n",
    "        #     regret.append(  self.delta_t( game, summary, t )  @ action_counter[:,t] )\n",
    "            # cum_regret.append(  game.LossMatrix[action,outcome] - min( game.LossMatrix[...,outcome ] )  )\n",
    "            \n",
    "        regret = np.array( [ game.delta(i) for i in range(game.n_actions) ]).T @ action_counter\n",
    "        \n",
    "        return regret #np.cumsum(cum_regret)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "a = 0.05\n",
    "b = 0.9\n",
    "\n",
    "seq = np.geomspace(a,b, num=1000)\n",
    "plt.plot(seq)\n",
    "\n",
    "seq = np.linspace(a,b, num=1000)\n",
    "plt.plot(seq)\n",
    "\n",
    "\n",
    "def my_gauss(x, sigma=1, h=1, mid=0):\n",
    "    from math import exp, pow\n",
    "    variance = pow(sigma, 2)\n",
    "    return h * exp(-pow(x-mid, 2)/(2*variance))\n",
    "\n",
    "\n",
    "x =  np.linspace(-20, 20, 1000) #np.linspace(norm.ppf(0.01,500, 1), norm.ppf(0.99,500, 1), 1000)\n",
    "seq = [ my_gauss(i, sigma=3, h=b, mid=0) for i in x ]\n",
    "plt.plot(range(1000), seq,  'r-',  label='norm pdf')\n",
    "\n",
    "\n",
    "def attack_seasons(self, p_min, p_max, horizon, nb_changes = 3):\n",
    "    # res = False\n",
    "    # while res == False:\n",
    "    #     lengths = np.array( np.cumsum(   np.random.normal(horizon/nb_changes, 50, 3)  ) ,dtype = int )\n",
    "    #     if lengths[-1]<horizon:\n",
    "    #         res = True\n",
    "    # lengths = lengths.tolist()\n",
    "    # lengths.append(horizon)\n",
    "    lengths = [250,500,750, horizon]\n",
    "\n",
    "    init_outcome =  np.random.randint(0,2,1)[0]\n",
    "    outcomes = []\n",
    "    for i in range(nb_changes+1):\n",
    "        if i == 0:\n",
    "            outcomes.append(init_outcome)\n",
    "        else:\n",
    "            outcomes.append(1-outcomes[i-1])\n",
    "\n",
    "    seq = [  ]\n",
    "    idx = 0\n",
    "    for i in range(horizon):\n",
    "        if i >= lengths[idx]:\n",
    "            idx +=1\n",
    "\n",
    "        if i < lengths[idx]  and outcomes[idx] == 0:\n",
    "            seq.append(p_min)\n",
    "        elif i < lengths[idx] and outcomes[idx] == 1:\n",
    "            seq.append(p_max)\n",
    "            \n",
    "    return seq\n",
    "\n",
    "seq = attack_seasons(a,b,3,1000)\n",
    "print(len(seq))\n",
    "plt.plot(seq)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f479197ae20>]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\n",
    "\n",
    "n_cores = 1\n",
    "n_folds = 1\n",
    "horizon = 1000\n",
    "\n",
    "# np.seterr(all='raise')\n",
    "\n",
    "# game = games.apple_tasting(False, outcome_distribution) \n",
    "\n",
    "\n",
    "\n",
    "outcome_distribution = [0.1077633468006714, 0.8922366531993287]\n",
    "job = (outcome_distribution, 9 )\n",
    "\n",
    "game =  games.label_efficient(  ) \n",
    "game.set_outcome_distribution( {'spam':outcome_distribution[0],'ham':outcome_distribution[1]} )\n",
    "print('optimal action', game.i_star)\n",
    "\n",
    "# print('optimal action', game.i_star)\n",
    "alg = PM_DMED.PM_DMED(  game, horizon,) #cpb.CPB(  game, horizon,1.01) #TSPM.TSPM_alg(  game, horizon, 1)\n",
    "task = Evaluation(horizon, 'easy')\n",
    "\n",
    "result = task.eval_policy_once(alg,game, job)\n",
    "#plt.plot(range(horizon), result)\n",
    "# fig = go.Figure( )\n",
    "# regret = np.array([ game.delta(i) for i in range(game.n_actions) ]).T @ np.mean(result,0) \n",
    "# xcoords = np.arange(0,horizon,1).tolist()\n",
    "\n",
    "# fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='blue'), mode='lines',  name='TPSM' )) # \n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "optimal action 1\n",
      "n-actions 3 n-outcomes 2 alphabet 3\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "UnboundLocalError",
     "evalue": "local variable 'seq' referenced before assignment",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m alg \u001b[38;5;241m=\u001b[39m PM_DMED\u001b[38;5;241m.\u001b[39mPM_DMED(  game, horizon,) \u001b[38;5;66;03m#cpb.CPB(  game, horizon,1.01) #TSPM.TSPM_alg(  game, horizon, 1)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m task \u001b[38;5;241m=\u001b[39m Evaluation(horizon, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124measy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_policy_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43malg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mEvaluation.eval_policy_once\u001b[0;34m(self, alg, game, job)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrealistic\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    124\u001b[0m     seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_seasons(distribution[\u001b[38;5;241m0\u001b[39m],distribution[\u001b[38;5;241m1\u001b[39m],\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mseq\u001b[49m))\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhorizon):\n\u001b[1;32m    128\u001b[0m \n\u001b[1;32m    129\u001b[0m     \u001b[38;5;66;03m# policy chooses one action\u001b[39;00m\n\u001b[1;32m    130\u001b[0m     action \u001b[38;5;241m=\u001b[39m alg\u001b[38;5;241m.\u001b[39mget_action(t)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'seq' referenced before assignment"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_cores = 16\n",
    "n_folds = 50\n",
    "horizon = 1000\n",
    "\n",
    "# constant, linear, exp, gaussian, realistic\n",
    "\n",
    "game = games.label_efficient(  )\n",
    "\n",
    "algos = [   random_algo.Random(  game, horizon, ),\n",
    "\n",
    "            feedexp3_piccolboni.FeedExp3(  game, horizon, ),\n",
    "\n",
    "            cpb.CPB(  game, horizon, 1.01), \n",
    "            cpb_gaussian.CPB_gaussian(  game, horizon, 1.01, True, 1/16, 10), \n",
    "\n",
    "            PM_DMED.PM_DMED(  game, horizon,),   \n",
    "\n",
    "            TSPM.TSPM_alg(  game, horizon, 1),\n",
    "            TSPM.TSPM_alg(  game, horizon, 0), \n",
    "\n",
    "            bpm.BPM(game,horizon),  ] \n",
    "\n",
    "colors = [  [0,0,0], [250,0,0], [0,250,0], [0,125,0], [250,0,250], [0,0,250], [0,0,125],  [0,125,125]  ]\n",
    "labels = [   'random', 'Piccolboni','CBP', 'RandCBP', 'PM_DMED', 'TSPM_R1', 'TSPM_R0', 'BPM_LEAST'   ] \n",
    "\n",
    "fig = go.Figure( )\n",
    "\n",
    "final_regrets = []\n",
    "\n",
    "for alg, color, label in zip( algos, colors, labels):\n",
    "\n",
    "    r,g,b = color\n",
    "    result = evaluate_parallel(n_cores, n_folds, horizon, alg, game, 'realistic')\n",
    "    # result = np.load('./results/label_efficient/drifts/{}_{}_{}_{}.npy'.format(type, horizon,n_folds,label) )\n",
    "    final_regrets.append( result[:,-1] )\n",
    "    regret =  np.mean(result, 0) \n",
    "    xcoords = np.arange(0,horizon,1).tolist()\n",
    "    std =  np.std(result,0) \n",
    "    upper_regret = regret + std\n",
    "\n",
    "    np.save('./results/label_efficient/drifts/{}_{}_{}_{}.npy'.format(type, horizon,n_folds,label), result)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b)), mode='lines',  name=label )) # \n",
    "\n",
    "    fig.add_trace(   go.Scatter( x=xcoords+xcoords[::-1], y=upper_regret.tolist()+regret.tolist()[::-1],  fill='toself', fillcolor='rgba({},{},{},0.2)'.format(r,g,b), \n",
    "                         line=dict(color='rgba(255,255,255,0)'),   hoverinfo=\"skip\",  showlegend=False )  )\n",
    "    \n",
    "# fig.show(legend=True)\n",
    "fig.update_layout(legend= dict(yanchor=\"top\",y=0.98,xanchor=\"left\",x=0.77), autosize=False,\n",
    "                  xaxis_title=\"Sequence\", yaxis_title=\"Regret\",  margin=go.layout.Margin( l=0,   r=0,   b=0,    t=0, ),   font=dict(size=13,) )\n",
    "# fig.write_image(\"./hard_LE.pdf\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.update_xaxes(type=\"log\")\n",
    "# fig.write_image(\"./hard_LE_log.pdf\")\n",
    "fig.show()\n",
    "final_regrets = np.array(final_regrets)\n",
    "final = [ ( np.argmin(final_regrets[:,i]), i) for i in range(n_folds) ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_cores = 16\n",
    "n_folds = 100\n",
    "horizon = 5000\n",
    "game = games.label_efficient(  )\n",
    "\n",
    "algos = [   random_algo.Random(  game, horizon, ),\n",
    "\n",
    "            feedexp3_piccolboni.FeedExp3(  game, horizon, ),\n",
    "\n",
    "            cpb.CPB(  game, horizon, 1.01), \n",
    "            cpb_gaussian.CPB_gaussian(  game, horizon, 1.01, True, 1/16, 10), \n",
    "\n",
    "            PM_DMED.PM_DMED(  game, horizon,),   \n",
    "\n",
    "            TSPM.TSPM_alg(  game, horizon, 1),\n",
    "            TSPM.TSPM_alg(  game, horizon, 0), \n",
    "\n",
    "            bpm.BPM(game,horizon),  ] \n",
    "\n",
    "colors = [  [0,0,0], [250,0,0], [0,250,0], [0,125,0], [250,0,250], [0,0,250], [0,0,125],  [0,125,125]  ]\n",
    "labels = [   'random', 'Piccolboni','CBP', 'RandCBP', 'PM_DMED', 'TSPM_R1', 'TSPM_R0', 'BPM_LEAST'   ] \n",
    "\n",
    "fig = go.Figure( )\n",
    "\n",
    "final_regrets = []\n",
    "\n",
    "for alg, color, label in zip( algos, colors, labels):\n",
    "\n",
    "    r,g,b = color\n",
    "    # result = evaluate_parallel(n_cores, n_folds, horizon, alg, game, 'easy')\n",
    "    result = np.load('./results/label_efficient/easy_{}_{}_{}.npy'.format(horizon,n_folds, label) )\n",
    "    final_regrets.append( result[:,-1] )\n",
    "    regret =  np.mean(result, 0) \n",
    "    xcoords = np.arange(0,horizon,1).tolist()\n",
    "    std =  np.std(result,0) \n",
    "    upper_regret = regret + std\n",
    "\n",
    "    # np.save('./results/label_efficient/easy_{}_{}_{}'.format(horizon,n_folds, label), result)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b)), mode='lines',  name=label )) # \n",
    "\n",
    "    fig.add_trace(   go.Scatter( x=xcoords+xcoords[::-1], y=upper_regret.tolist()+regret.tolist()[::-1],  fill='toself', fillcolor='rgba({},{},{},0.2)'.format(r,g,b), \n",
    "                         line=dict(color='rgba(255,255,255,0)'),   hoverinfo=\"skip\",  showlegend=False )  )\n",
    "    \n",
    "fig.show(legend=True)\n",
    "fig.update_yaxes(range=[0, 30] )\n",
    "fig.update_layout(legend= dict(yanchor=\"top\",y=0.98,xanchor=\"left\",x=0.77), autosize=False,\n",
    "                  xaxis_title=\"Sequence\", yaxis_title=\"Regret\",  margin=go.layout.Margin( l=0,   r=0,   b=0,    t=0, ),   font=dict(size=13,) )\n",
    "fig.write_image(\"./easy_LE.pdf\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig.update_xaxes(type=\"log\")\n",
    "fig.write_image(\"./easy_LE_log.pdf\")\n",
    "fig.show()\n",
    "\n",
    "final_regrets = np.array(final_regrets)\n",
    "final = [ ( np.argmin(final_regrets[:,i]), i) for i in range(n_folds) ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "res = []\n",
    "for i in range(n_folds):\n",
    "    opt = min(final_regrets[:,i])\n",
    "    vec = [ j == opt for j in final_regrets[:,i] ] \n",
    "    #if vec[1]==1 and vec[2] == 1:\n",
    "    #    pass\n",
    "    #else:\n",
    "    res.append(  vec  )\n",
    "\n",
    "#print( np.sum( res,0) )\n",
    "\n",
    "diff = []\n",
    "for i in range(n_folds):\n",
    "    if res[i][1] >= res[i][2]:\n",
    "        diff.append( i )\n",
    "\n",
    "np.random.seed(1)\n",
    "distributions = []\n",
    "for jobid in range(n_folds):\n",
    "    p = np.random.uniform(0.4, 0.5) \n",
    "    distributions.append( [p, 1-p] )\n",
    "\n",
    "distributions_rand = np.array([ distributions[i] for i in diff ])\n",
    "distributions_cbp = np.array([ distributions[i] for i in range(n_folds) if i not in diff ])\n",
    "#print( len( diff ) )\n",
    "print(np.mean(distributions_rand[:,0]), np.std(distributions_rand[:,0]) )\n",
    "print(np.mean(distributions_cbp[:,0]), np.std(distributions_cbp[:,0]) )\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.456154090331781 0.03132638699822154\n",
      "0.43466197585846006 0.024706747598054565\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig.update_xaxes(type=\"log\")\n",
    "fig.update_layout(legend= dict(yanchor=\"top\",y=0.98,xanchor=\"left\",x=0.77), autosize=False,\n",
    "                  xaxis_title=\"Sequence (log-scale)\", yaxis_title=\"Regret\",  margin=go.layout.Margin( l=0,   r=0,   b=0,    t=0, ),   font=dict(size=13,) )\n",
    "fig.write_image(\"./easy_LE_log.pdf\")\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "fig.write_image(\"./easy_LE.pdf\")\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0215ed8d73c40df5de54d647d65b604dcf02460a7de2b27ed9878602c67cf72c"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('climate-ai': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}