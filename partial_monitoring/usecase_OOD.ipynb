{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from mnist_c import corruptions\n",
    "\n",
    "x = 1\n",
    "\n",
    "corruptions.identity(x)\n",
    "\n",
    "\n",
    "perturbation_matrix = [  ]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(1., dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def get_stream(data, blackbox, horizon, outcome_distribution, m, s):\n",
    "    \n",
    "    sample = np.random.randint(0, len(data), horizon) #np.random.permutation( range(horizon) )\n",
    "    datastream = DataStream( horizon, sample, m, s)\n",
    "    stream = datastream.random_stream(  data, blackbox, list(  outcome_distribution.values() ) )\n",
    "    # stream = datastream.secretary_stream( data, blackbox, 25, 10, True )\n",
    "    return stream\n",
    "\n",
    "device = torch.device(\"cpu\") #\"cuda:0\" if torch.cuda.is_available() else  \n",
    "\n",
    "horizon = 10\n",
    "\n",
    "data = datasets.MNIST(\"../data\", train=False, download=True, transform=transforms.ToTensor() )\n",
    "\n",
    "\n",
    "perturbation_rate = 0.1\n",
    "n =1000\n",
    "attack = 0\n",
    "no_attack = 0\n",
    "for d in data:\n",
    "\n",
    "    if np.random.uniform( 0,1 ) <= perturbation_rate:\n",
    "        attack+=1\n",
    "\n",
    "\n",
    "    else:\n",
    "        no_attack+=1\n",
    "\n",
    "print(   attack/n, no_attack/n)\n",
    "\n",
    "\n",
    "\n",
    "gaussian_noise(x, severity=5)\n",
    "shot_noise(x, severity=5)\n",
    "impulse_noise(x, severity=4)\n",
    "speckle_noise(x, severity=5)\n",
    "pessimal_noise(x, severity=1)\n",
    "gaussian_blur(x, severity=2)\n",
    "glass_blur(x, severity=1)\n",
    "defocus_blur(x, severity=1)\n",
    "motion_blur(x, severity=1)\n",
    "zoom_blur(x, severity=5)\n",
    "fog(x, severity=5)\n",
    "frost(x, severity=5)\n",
    "snow(x, severity=5)\n",
    "spatter(x, severity=4)\n",
    "contrast(x, severity=4)\n",
    "brightness(x, severity=5)\n",
    "saturate(x, severity=5)\n",
    "pixelate(x, severity=3)\n",
    "shear(x, severity=2)\n",
    "\n",
    "\n",
    "    # print(d[0], d[1])\n",
    "\n",
    "\n",
    "\n",
    "# X_train = [  d[0]   for d in data_train ]\n",
    "# X_train = torch.stack(X_train)\n",
    "\n",
    "\n",
    "\n",
    "# m = X_train.mean(0, keepdim=True).to(device)\n",
    "# s = X_train.std(0, unbiased=False, keepdim=True).to(device)\n",
    "# sample = np.random.randint(0, len(data), horizon) \n",
    "# datastream = DataStream( horizon, sample, m, s)\n",
    "\n",
    "\n",
    "# stream = datastream.random_stream(  data, blackbox, list(  outcome_distribution.values() ) )\n",
    "\n",
    "\n",
    "# stream = get_stream( data, blackbox_model, horizon, outcome_distribution, m, s )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.097 0.903\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def gaussian_distribution(loc, scale):\n",
    "    loc = 5\n",
    "    scale = 2\n",
    "    x = np.arange(0, 10)\n",
    "    xU, xL = x + 0.5, x - 0.5 \n",
    "    prob = ss.norm.cdf(xU, loc=loc, scale=scale) - ss.norm.cdf(xL, loc=loc, scale=scale)\n",
    "    prob = prob / prob.sum() # normalize the probabilities so their sum is 1\n",
    "    return prob\n",
    "\n",
    "\n",
    "def multinomial_distribution(loc1, scale1, loc2, scale2):\n",
    "    loc = 5\n",
    "    scale = 2\n",
    "    x = np.arange(0, 10)\n",
    "    xU, xL = x + 0.5, x - 0.5 \n",
    "    prob1 = ss.norm.cdf(xU, loc=loc1, scale=scale1) - ss.norm.cdf(xL, loc=loc1, scale=scale1)\n",
    "    prob2 = ss.norm.cdf(xU, loc=loc2, scale=scale2) - ss.norm.cdf(xL, loc=loc2, scale=scale2)\n",
    "\n",
    "    prob = prob1+prob2 \n",
    "    prob = prob / prob.sum() # normalize the probabilities so their sum is 1\n",
    "    return prob\n",
    "\n",
    "\n",
    "x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "perturbation_rate = 0.2\n",
    "n_classes = 10\n",
    "\n",
    "y = np.ones( n_classes) / n_classes\n",
    "z = gaussian_distribution(5, 2)\n",
    "k = multinomial_distribution(2, 1, 7, 0.1)\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(x-0.2, y, width=0.2, color='b', align='center')\n",
    "ax.bar(x, z, width=0.2, color='g', align='center')\n",
    "ax.bar(x+0.2, k, width=0.2, color='r', align='center')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class DataStream:\n",
    "\n",
    "    def __init__(self, horizon, sample, m, s):\n",
    "        self.horizon = horizon #nombre de timesteps\n",
    "        self.sample = sample #longueur du stream d'images considere (je crois)\n",
    "        self.m = m #moyenne des pixels, cela est fait pour eviter des bugs\n",
    "        self.s = s # variance des pixels, cela est fait pour eviter des bugs\n",
    "        self.R = {} #cela est detaille dans le papier ICLR2022, algo 1\n",
    "        self.Sa = [] #cela est detaille dans le papier ICLR2022, algo 1\n",
    "\n",
    "    def random_stream(self, data, blackbox, outcome_distribution ):\n",
    "\n",
    "        stream = []\n",
    "        label = []\n",
    "        outcomes = []\n",
    "        for i, idx, in enumerate(self.sample) :\n",
    "            outcome = np.random.choice( [1, 0], p=outcome_distribution)\n",
    "            X,y =  data[idx]\n",
    "\n",
    "            X = X.reshape( (1,1,28,28) ).to(device)\n",
    "            # zero mask\n",
    "            mask = (self.s != 0)\n",
    "\n",
    "            # finally perform division\n",
    "            X[mask] = X[mask] / self.s[mask]\n",
    "\n",
    "            X -= self.m\n",
    "            print(X)\n",
    "            y = torch.Tensor([ y ]).type(torch.LongTensor).to(device)\n",
    "            if outcome==1:\n",
    "                delta = attacks.pgd_linf(blackbox, X , y).to(device)\n",
    "                X = X + delta\n",
    "            stream.append(  X[0] )\n",
    "            label.append(y)\n",
    "            outcomes.append([outcome])\n",
    "\n",
    "        stream = torch.stack(stream).to('cpu').detach() \n",
    "        label = torch.stack(label).to('cpu').detach() \n",
    "        status = torch.Tensor(outcomes).to('cpu').detach() \n",
    "        \n",
    "        return  TensorDataset( stream, label, status ) \n",
    "\n",
    "    def virtual_plus(self, i, v_i, t, k, exhaust):\n",
    "\n",
    "        outcome = 0\n",
    "\n",
    "        if i <= t: # sampling phase\n",
    "            self.R[i] = v_i\n",
    "            self.R = { k: v for k, v in sorted(self.R.items(), key=lambda item: item[1]) }\n",
    "            \n",
    "        else: # selection phase\n",
    "            last_value = list( self.R.values() )[-1]\n",
    "            last_key = list( self.R.keys() )[-1]\n",
    "            num_left_to_pick = k - len(self.Sa) \n",
    "            num_samples_left = self.horizon - i\n",
    "            if  num_samples_left <= num_left_to_pick and exhaust and num_left_to_pick > 0:\n",
    "                self.Sa.append(i)\n",
    "                outcome = 1\n",
    "\n",
    "            if v_i >= last_value and len(self.Sa) <= k:\n",
    "                del self.R[ last_key ]\n",
    "                self.R[i] = v_i\n",
    "                self.R = {k: v for k, v in sorted(self.R.items(), key=lambda item: item[1])}\n",
    "                self.Sa.append(i)\n",
    "                outcome = 1\n",
    "\n",
    "        return outcome\n",
    "\n",
    "    def secretary_stream(self, data, blackbox, t, k, exhaust):\n",
    "\n",
    "        stream = []\n",
    "        label = []\n",
    "        outcomes = []\n",
    "\n",
    "        for i, idx, in enumerate(self.sample) : \n",
    "\n",
    "            X, y =  data[idx]\n",
    "            X = X.reshape( (1,1,28,28) ).to(device)\n",
    "            y = torch.Tensor([ y ]).type(torch.LongTensor).to(device)\n",
    "\n",
    "            delta = attacks.pgd_linf(blackbox, X , y).to(device)\n",
    "            X_prime = X + delta\n",
    "            v_i = nn.CrossEntropyLoss()( blackbox(X_prime) ,y)\n",
    "\n",
    "            outcome = self.virtual_plus( i, v_i, t, k, exhaust)\n",
    "\n",
    "            stream.append(  X[0]  )\n",
    "            label.append(y )\n",
    "            outcomes.append([outcome])\n",
    "\n",
    "        stream = torch.stack(stream).to('cpu').detach().numpy()\n",
    "        label = torch.stack(label).to('cpu').detach().numpy()\n",
    "        status = torch.Tensor(outcomes).to('cpu').detach().numpy()\n",
    "        #\n",
    "        return  TensorDataset( stream, label, status ) \n",
    "\n",
    "\n",
    "# blackbox_model = blackbox.load()\n",
    "# mnist_val = datasets.MNIST(\"../data\", train=False, download=True, transform=transforms.ToTensor() )\n",
    "# datastream = DataStream()\n",
    "# # random_stream = datastream.random_stream( mnist_val, blackbox_model, [0.5,0.5] )\n",
    "# sec_stream = datastream.secretary_stream( mnist_val, blackbox_model  )"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.15",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('climate-ai': conda)"
  },
  "interpreter": {
   "hash": "0215ed8d73c40df5de54d647d65b604dcf02460a7de2b27ed9878602c67cf72c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}