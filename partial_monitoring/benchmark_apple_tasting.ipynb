{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "import geometry\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from multiprocess import Pool\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import geometry\n",
    "import itertools \n",
    "from itertools import islice\n",
    "import games\n",
    "import geometry_v2\n",
    "import cpb\n",
    "\n",
    "import cpb_gaussian\n",
    "import bpm\n",
    "import random_algo\n",
    "import plotly.graph_objects as go\n",
    "import TSPM\n",
    "\n",
    "import PM_DMED\n",
    "\n",
    "#import ucbTSPM_v2\n",
    "import cpb_gaussian_v2\n",
    "import feedexp3_piccolboni\n",
    "\n",
    "def evaluate_parallel(nbCores, n_folds, horizon, alg, game, type):\n",
    "    print(\"nbCores:\", nbCores, \"nbFolds:\", n_folds, \"Horizon:\", horizon)\n",
    "    pool = Pool(processes = nbCores) \n",
    "    task = Evaluation(horizon, type)\n",
    "\n",
    "    np.random.seed(1)\n",
    "    distributions = []\n",
    "\n",
    "    for jobid in range(n_folds):\n",
    "        \n",
    "        if type == 'easy' :\n",
    "            p = np.random.uniform(0, 0.2) if np.random.uniform(0,1)>0.5 else np.random.uniform(0.8, 1)\n",
    "        #elif type == 'easy' and jobid > 100:\n",
    "        #    p = np.random.uniform(0.8, 1)\n",
    "        else:\n",
    "            p = np.random.uniform(0.4,0.6)\n",
    "        distributions.append( [p, 1-p] )\n",
    "\n",
    "\n",
    "    return np.asarray(  pool.map( partial( task.eval_policy_once, alg, game ), zip(distributions ,range(n_folds)) ) ) \n",
    "\n",
    "\n",
    "class Evaluation:\n",
    "\n",
    "    def __init__(self, horizon,type ):\n",
    "        self.type = type\n",
    "        self.horizon = horizon\n",
    "        # self.outcome_distribution = outcome_distribution\n",
    "\n",
    "    \n",
    "\n",
    "    def get_outcomes(self, game, job_id):\n",
    "        # self.means = runif_in_simplex( self.game.n_outcomes )\n",
    "        outcomes = np.random.choice( game.n_outcomes , p= list( game.outcome_dist.values() ), size= self.horizon) \n",
    "        return outcomes\n",
    "\n",
    "    def get_feedback(self, game, action, outcome):\n",
    "        return game.FeedbackMatrix[ action ][ outcome ]\n",
    "\n",
    "    def eval_policy_once(self, alg, game, job):\n",
    "\n",
    "        alg.reset()\n",
    "\n",
    "        distribution, jobid = job\n",
    "\n",
    "\n",
    "        np.random.seed(jobid)\n",
    "        \n",
    "        # outcome_distribution =  {'spam':0.05,'ham':0.95}\n",
    "\n",
    "        outcome_distribution =  {'spam':distribution[0],'ham':distribution[1]}\n",
    "\n",
    "        # p = get_easy() if game.mode == 'easy' else get_harsch() \n",
    "        # outcome_distribution =  {'a':p[0],'b':p[1],'c':p[2],'d':p[3],'e':p[4]}\n",
    "\n",
    "        game.set_outcome_distribution( outcome_distribution, jobid )\n",
    "        # print('optimal action', game.i_star)\n",
    "\n",
    "        action_counter = np.zeros( (game.n_actions, self.horizon) )\n",
    "\n",
    "        # generate outcomes obliviously\n",
    "        outcomes = self.get_outcomes(game, jobid)\n",
    "\n",
    "        for t in range(self.horizon):\n",
    "\n",
    "            # policy chooses one action\n",
    "            action = alg.get_action(t)\n",
    "\n",
    "            # Environment chooses one outcome\n",
    "            outcome = outcomes[t]\n",
    "\n",
    "            # print('t', t, 'action', action, 'outcome', outcome, )\n",
    "\n",
    "            feedback =  self.get_feedback( game, action, outcome )\n",
    "\n",
    "            alg.update(action, feedback, outcome, None, t)\n",
    "            \n",
    "            # print('nu', alg.nu / alg.n )\n",
    "\n",
    "            for i in range(game.n_actions):\n",
    "                if i == action:\n",
    "                    action_counter[i][t] = action_counter[i][t-1] +1\n",
    "                else:\n",
    "\n",
    "                    action_counter[i][t] = action_counter[i][t-1]\n",
    "\n",
    "        regret = np.array( [ game.delta(i) for i in range(game.n_actions) ]).T @ action_counter\n",
    "\n",
    "        return regret\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "distributions = []\n",
    "\n",
    "for jobid in range(100):\n",
    "        \n",
    "    if type == 'easy' :\n",
    "        p = np.random.uniform(0, 0.2) if np.random.uniform(0,1)>0.5 else np.random.uniform(0.8, 1)\n",
    "        #elif type == 'easy' and jobid > 100:\n",
    "        #    p = np.random.uniform(0.8, 1)\n",
    "    else:\n",
    "        p = np.random.uniform(0.4,0.6)\n",
    "    distributions.append( [p, 1-p] )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\n",
    "\n",
    "n_cores = 1\n",
    "n_folds = 1\n",
    "horizon = 1000\n",
    "\n",
    "# np.seterr(all='raise')\n",
    "\n",
    "# game = games.apple_tasting(False, outcome_distribution) \n",
    "\n",
    "game =  games.apple_tasting( False ) \n",
    "\n",
    "# print('optimal action', game.i_star)\n",
    "alg = PM_DMED.PM_DMED(  game, horizon, 1)\n",
    "task = Evaluation(horizon, 'easy')\n",
    "\n",
    "# forced stop dist {'spam': 0.8131922181368049, 'ham': 0.18680778186319513} jobid 95\n",
    "# forced stop dist {'spam': 0.8468724172242842, 'ham': 0.1531275827757158} jobid 98\n",
    "idx = 4\n",
    "outcome_distribution = distributions[idx]\n",
    "job = (outcome_distribution, idx )\n",
    "\n",
    "result = task.eval_policy_once(alg,game, job)\n",
    "#plt.plot(range(horizon), result)\n",
    "# fig = go.Figure( )\n",
    "# regret = np.array([ game.delta(i) for i in range(game.n_actions) ]).T @ np.mean(result,0) \n",
    "# xcoords = np.arange(0,horizon,1).tolist()\n",
    "\n",
    "# fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='blue'), mode='lines',  name='TPSM' )) # "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "n-actions 2 n-outcomes 2 alphabet 2\n",
      "Restricted license - for non-production use only - expires 2023-10-25\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "plt.plot(result)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdf21dab940>]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_cores = 16\n",
    "n_folds = 100\n",
    "horizon = 100000\n",
    "\n",
    "game = games.apple_tasting(False)\n",
    "\n",
    "\n",
    "algos = [   random_algo.Random(  game, horizon, ),\n",
    "\n",
    "            #feedexp3_piccolboni.FeedExp3(  game, horizon, ),\n",
    "\n",
    "            cpb.CPB(  game, horizon, 1.01), \n",
    "            cpb_gaussian.CPB_gaussian(  game, horizon, 1.01, True, 1/16, 10, False), \n",
    "\n",
    "            PM_DMED.PM_DMED(  game, horizon, 1),    \n",
    "\n",
    "            TSPM.TSPM_alg(  game, horizon, 1),\n",
    "            TSPM.TSPM_alg(  game, horizon, 0), \n",
    "\n",
    "            bpm.BPM(game,horizon),  ] \n",
    "\n",
    "colors = [  [0,0,0],  [0,250,0], [0,125,0], [250,0,250] ,[0,0,250], [0,0,125],  [0,125,125]  ]\n",
    "labels = [   'random', 'CBP', 'RandCBP', 'PM_DMED', 'TSPM_R1', 'TSPM_R0', 'BPM_LEAST'   ] \n",
    "\n",
    "fig = go.Figure(    )\n",
    "\n",
    "for alg, color, label in zip( algos, colors, labels):\n",
    "\n",
    "    r,g,b = color\n",
    "    # result = evaluate_parallel(n_cores, n_folds, horizon, alg, game, 'easy')\n",
    "    # np.save('./results/apple_tasting/easy_{}_{}_{}'.format(horizon,n_folds, label), result)\n",
    "\n",
    "    result = np.load('./results/apple_tasting/easy_{}_{}_{}.npy'.format(horizon,n_folds, label) )\n",
    "\n",
    "    regret =  np.mean(result,0) \n",
    "    \n",
    "    xcoords = np.arange(0,horizon,1).tolist()\n",
    "    std =  np.std(result,0) \n",
    "    upper_regret = regret + std\n",
    "\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b)), mode='lines',  name=label )) # \n",
    "\n",
    "    fig.add_trace(   go.Scatter( x=xcoords+xcoords[::-1], y=upper_regret.tolist()+regret.tolist()[::-1],  fill='toself', fillcolor='rgba({},{},{},0.2)'.format(r,g,b), \n",
    "                         line=dict(color='rgba(255,255,255,0)'),   hoverinfo=\"skip\",  showlegend=False )   )\n",
    "    \n",
    "# fig.show(legend=True)\n",
    "\n",
    "fig.update_layout(legend= dict(yanchor=\"top\",y=0.98,xanchor=\"left\",x=0.77), autosize=False,\n",
    "                 xaxis_title=\"Sequence\",\n",
    "                 yaxis_title=\"Regret\",\n",
    "                 margin=go.layout.Margin( l=0,   r=0,   b=0,    t=0, ), \n",
    "                  font=dict(size=13,) )\n",
    "\n",
    "fig.update_yaxes( type=\"log\", range=[0, 5] )\n",
    "\n",
    "# fig.write_image(\"./easy_AT.pdf\")\n",
    "\n",
    "# fig.update_yaxes(range=[0, 15] )\n",
    "\n",
    "fig.write_image(\"./easy_AT.pdf\")\n",
    "\n",
    "# fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_cores = 16\n",
    "n_folds = 100\n",
    "horizon = 100000\n",
    "\n",
    "game = games.apple_tasting(False)\n",
    "\n",
    "algos = [   random_algo.Random(  game, horizon, ),\n",
    "\n",
    "            # feedexp3_piccolboni.FeedExp3(  game, horizon, ),\n",
    "\n",
    "            cpb.CPB(  game, horizon, 1.01), \n",
    "            cpb_gaussian.CPB_gaussian(  game, horizon, 1.01, True, 1/16, 10, False), \n",
    "\n",
    "            PM_DMED.PM_DMED(  game, horizon, 1),    \n",
    "\n",
    "            TSPM.TSPM_alg(  game, horizon, 1),\n",
    "            TSPM.TSPM_alg(  game, horizon, 0), \n",
    "\n",
    "            bpm.BPM(game,horizon),  ] \n",
    "\n",
    "colors = [  [0,0,0],  [0,250,0], [0,125,0], [250,0,250] ,[0,0,250], [0,0,125],  [0,125,125]  ]\n",
    "labels = [   'random', 'CBP', 'RandCBP', 'PM_DMEDc1', 'TSPM_R1', 'TSPM_R0', 'BPM_LEAST'   ] \n",
    "\n",
    "fig = go.Figure(    )\n",
    "\n",
    "for alg, color, label in zip( algos, colors, labels):\n",
    "\n",
    "    r,g,b = color\n",
    "    # result = evaluate_parallel(n_cores, n_folds, horizon, alg, game, 'hard')\n",
    "    result = np.load('./results/apple_tasting/hard_{}_{}_{}.npy'.format(horizon,n_folds, label) )\n",
    "\n",
    "    regret =  np.mean(result,0) \n",
    "    \n",
    "    xcoords = np.arange(0,horizon,1).tolist()\n",
    "    std =  np.std(result,0) \n",
    "    upper_regret = regret + std\n",
    "\n",
    "    # np.save('./results/apple_tasting/easy_{}_{}_{}'.format(horizon,n_folds, label), result)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b)), mode='lines',  name=label )) # \n",
    "\n",
    "    fig.add_trace(   go.Scatter( x=xcoords+xcoords[::-1], y=upper_regret.tolist()+regret.tolist()[::-1],  fill='toself', fillcolor='rgba({},{},{},0.2)'.format(r,g,b), \n",
    "                         line=dict(color='rgba(255,255,255,0)'),   hoverinfo=\"skip\",  showlegend=False )   )\n",
    "    \n",
    "# fig.show(legend=True)\n",
    "\n",
    "fig.update_layout(legend= dict(yanchor=\"top\",y=0.98,xanchor=\"left\",x=0.77), autosize=False,\n",
    "                 xaxis_title=\"Sequence\",\n",
    "                 yaxis_title=\"Regret\",\n",
    "                 margin=go.layout.Margin( l=0,   r=0,   b=0,    t=0, ), \n",
    "                  font=dict(size=13,) )\n",
    "\n",
    "\n",
    "fig.update_yaxes(range=[0, 270] )\n",
    "\n",
    "fig.write_image(\"./hard_AT.pdf\")\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('climate-ai': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea0114cb9172efb607fa3d4693544b55f200153fae449834f41fe7defbe1701a"
   }
  },
  "interpreter": {
   "hash": "0215ed8d73c40df5de54d647d65b604dcf02460a7de2b27ed9878602c67cf72c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}