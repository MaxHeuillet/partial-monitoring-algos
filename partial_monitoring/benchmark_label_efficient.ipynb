{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from multiprocess import Pool\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "import itertools \n",
    "from itertools import islice\n",
    "import games\n",
    "\n",
    "import cpb\n",
    "import bpm\n",
    "import random_algo\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import TSPM\n",
    "\n",
    "import cpb_gaussian\n",
    "import PM_DMED\n",
    "\n",
    "# import feedexp3_bianchi\n",
    "import feedexp3_piccolboni\n",
    "\n",
    "\n",
    "def evaluate_parallel(nbCores, n_folds, horizon, alg, game, type):\n",
    "\n",
    "    print(\"nbCores:\", nbCores, \"nbFolds:\", n_folds, \"Horizon:\", horizon)\n",
    "    pool = Pool(processes = nbCores) \n",
    "    task = Evaluation(horizon, type)\n",
    "\n",
    "    np.random.seed(1)\n",
    "    distributions = []\n",
    "\n",
    "    for jobid in range(n_folds):\n",
    "        \n",
    "        if type == 'easy' :\n",
    "            p = np.random.uniform(0, 0.2) #if np.random.uniform(0,1)>0.5 else np.random.uniform(0.8, 1)\n",
    "        #elif type == 'easy' and jobid > 100:\n",
    "        #    p = np.random.uniform(0.8, 1)\n",
    "        else:\n",
    "            p = np.random.uniform(0.4,0.6)\n",
    "        distributions.append( [p, 1-p] )\n",
    "\n",
    "    return np.asarray(  pool.map( partial( task.eval_policy_once, alg, game ), zip(distributions ,range(n_folds)) ) ) \n",
    "\n",
    "class Evaluation:\n",
    "\n",
    "    def __init__(self, horizon, type ):\n",
    "        self.horizon = horizon\n",
    "        self.type = type\n",
    "        # self.outcome_distribution = outcome_distribution\n",
    "\n",
    "    def get_outcomes(self, game, job_id):\n",
    "        # self.means = runif_in_simplex( self.game.n_outcomes )\n",
    "        outcomes = np.random.choice( game.n_outcomes , p= list( game.outcome_dist.values() ), size= self.horizon) \n",
    "        return outcomes\n",
    "\n",
    "    def get_feedback(self, game, action, outcome):\n",
    "        return game.FeedbackMatrix[ action ][ outcome ]\n",
    "\n",
    "    def eval_policy_once(self, alg, game, job):\n",
    "\n",
    "        alg.reset()\n",
    "\n",
    "        distribution, jobid = job\n",
    "\n",
    "        #print('seed {} distribution {}'.format(jobid, distribution)) \n",
    "        np.random.seed(jobid)\n",
    "        \n",
    "        # outcome_distribution =  {'spam':0.05,'ham':0.95}\n",
    "\n",
    "        outcome_distribution = {'spam':distribution[0],'ham':distribution[1]}\n",
    "\n",
    "        # p = get_easy() if game.mode == 'easy' else get_harsch() \n",
    "        # outcome_distribution =  {'a':p[0],'b':p[1],'c':p[2],'d':p[3],'e':p[4]}\n",
    "\n",
    "        game.set_outcome_distribution( outcome_distribution, jobid )\n",
    "        optimal_action = game.i_star\n",
    "\n",
    "        action_counter = np.zeros( (game.n_actions, self.horizon) )\n",
    "        cum_regret = []\n",
    "\n",
    "        # generate outcomes obliviously\n",
    "        outcomes = self.get_outcomes(game, jobid)\n",
    "        # outcomes, summary = self.distribution_shift(game )\n",
    "\n",
    "        for t in range(self.horizon):\n",
    "\n",
    "            # policy chooses one action\n",
    "            action = alg.get_action(t)\n",
    "\n",
    "            # Environment chooses one outcome\n",
    "            outcome = outcomes[t]\n",
    "\n",
    "            #print('t', t, 'action', action, 'outcome', outcome, )\n",
    "\n",
    "            feedback =  self.get_feedback( game, action, outcome )\n",
    "\n",
    "            alg.update(action, feedback, outcome, None, t)\n",
    "            \n",
    "            # print('nu', alg.nu / alg.n )\n",
    "\n",
    "            for i in range(game.n_actions):\n",
    "                if i == action:\n",
    "                    action_counter[i][t] = action_counter[i][t-1] + 1\n",
    "                else:\n",
    "                    \n",
    "                    action_counter[i][t] = action_counter[i][t-1]\n",
    "\n",
    "        # regret = []\n",
    "        # for t in range(self.horizon):\n",
    "        #     regret.append(  self.delta_t( game, summary, t )  @ action_counter[:,t] )\n",
    "            # cum_regret.append(  game.LossMatrix[action,outcome] - min( game.LossMatrix[...,outcome ] )  )\n",
    "            \n",
    "        regret = np.array( [ game.delta(i) for i in range(game.n_actions) ]).T @ action_counter\n",
    "        \n",
    "        return regret #np.cumsum(cum_regret)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_cores = 16\n",
    "n_folds = 100\n",
    "horizon = 100000\n",
    "\n",
    "game = games.label_efficient()\n",
    "\n",
    "algos = [ random_algo.Random(  game, horizon, ), \n",
    "          cpb.CPB(  game, horizon, 1.01),  \n",
    "          PM_DMED.PM_DMED(  game, horizon, 100), \n",
    "          PM_DMED.PM_DMED(  game, horizon, 10), \n",
    "          PM_DMED.PM_DMED(  game, horizon, 5), \n",
    "          PM_DMED.PM_DMED(  game, horizon, 1),\n",
    "          PM_DMED.PM_DMED(  game, horizon, 0.1),  \n",
    "          TSPM.TSPM_alg(  game, horizon, 1),\n",
    "          TSPM.TSPM_alg(  game, horizon, 0),\n",
    "          bpm.BPM(game, horizon) ]\n",
    "\n",
    "colors = [  [0,0,0],  [250,0,0], [0,250,0], [0,150,0], [0,0,250], [0,0,200], [0,0,150], [0,0,100],  [225,0,225], [150 , 0, 150] ] \n",
    "labels = [   'random', 'CBP',  'PM_DMEDc100', 'PM_DMEDc10', 'PM_DMEDc5', 'PM_DMEDc1', 'PM_DMEDc01', 'TSPM_R1', 'TSPM_R0', 'BPM_LEAST'  ]  \n",
    "\n",
    "fig = go.Figure(    )\n",
    "\n",
    "for alg, color, label in zip( algos, colors, labels):\n",
    "\n",
    "    result = evaluate_parallel(n_cores, n_folds, horizon, alg, game, 'easy')\n",
    "    np.save('./results/label_efficient/easy_{}_{}_{}'.format(horizon,n_folds, label), result)\n",
    "\n",
    "    result = evaluate_parallel(n_cores, n_folds, horizon, alg, game, 'hard')\n",
    "    np.save('./results/label_efficient/hard_{}_{}_{}'.format(horizon,n_folds, label), result)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "n_cores = 1\n",
    "n_folds = 1\n",
    "horizon = 100\n",
    "\n",
    "# np.seterr(all='raise')\n",
    "\n",
    "# game = games.apple_tasting(False, outcome_distribution) \n",
    "\n",
    "\n",
    "\n",
    "outcome_distribution = [0.1077633468006714, 0.8922366531993287]\n",
    "job = (outcome_distribution, 9 )\n",
    "\n",
    "game =  games.label_efficient(  ) \n",
    "game.set_outcome_distribution( {'spam':outcome_distribution[0],'ham':outcome_distribution[1]} )\n",
    "print('optimal action', game.i_star)\n",
    "\n",
    "# print('optimal action', game.i_star)\n",
    "alg = PM_DMED.PM_DMED(  game, horizon,) #cpb.CPB(  game, horizon,1.01) #TSPM.TSPM_alg(  game, horizon, 1)\n",
    "task = Evaluation(horizon, 'easy')\n",
    "\n",
    "result = task.eval_policy_once(alg,game, job)\n",
    "#plt.plot(range(horizon), result)\n",
    "# fig = go.Figure( )\n",
    "# regret = np.array([ game.delta(i) for i in range(game.n_actions) ]).T @ np.mean(result,0) \n",
    "# xcoords = np.arange(0,horizon,1).tolist()\n",
    "\n",
    "# fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='blue'), mode='lines',  name='TPSM' )) # \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "n_cores = 16\n",
    "n_folds = 100\n",
    "horizon = 100000\n",
    "\n",
    "game = games.label_efficient(  )\n",
    "\n",
    "#feedexp3.FeedExp3(  game, horizon, ),\n",
    "#feedexp3_v3.FeedExp3(  game, horizon, ),\n",
    "#eTSPM.eTSPM_alg(  game, horizon, 1),\n",
    "#TSPM.TSPM_alg(  game, horizon,), bpm.BPM(  game, horizon,  [0.5, 0.5 ], np.identity(2) ) ,\n",
    "\n",
    "#TSPM.TSPM_alg(  game, horizon,), \n",
    "#ucbTSPM_v2.TSPM_alg(game, horizon)  \n",
    "\n",
    "algos = [ random_algo.Random(  game, horizon, ), \n",
    "          cpb.CPB(  game, horizon, 1.01), \n",
    "          None, \n",
    "          PM_DMED.PM_DMED(  game, horizon, 100), \n",
    "          PM_DMED.PM_DMED(  game, horizon, 10), \n",
    "          TSPM.TSPM_alg(  game, horizon, 1),\n",
    "          TSPM.TSPM_alg(  game, horizon, 0),\n",
    "          bpm.BPM(game, horizon) ]\n",
    "\n",
    "colors = [  [0,0,0],  [250,0,0], [0,250,0], [255,128,0], [255,128,0],  [0 , 250, 250],  [255 , 0, 255] ] \n",
    "labels = [   'random', 'CBP', 'RandCBP', 'PM_DMEDc100', 'PM_DMEDc10', 'TSPM_R1', 'BPM_LEAST'  ]  \n",
    "\n",
    "fig = go.Figure( )\n",
    "\n",
    "final_regrets = []\n",
    "\n",
    "\n",
    "for alg, color, label in list(zip(algos, colors, labels))[::-1]:\n",
    "\n",
    "    r,g,b = color\n",
    "    # result = evaluate_parallel(n_cores, n_folds, horizon, alg, game, 'harsch')\n",
    "    # np.save('./results/label_efficient/hard_{}_{}_{}'.format(horizon,n_folds, label), result)\n",
    "    \n",
    "    if label == 'RandCBP':\n",
    "        result = np.load( './results/benchmark_randcbp/label_efficient/LE_hard_{}_{}_Gaussian_1_10_10e7.npy'.format(horizon,n_folds, label) )\n",
    "    else: \n",
    "        result = np.load( './results/label_efficient/hard_{}_{}_{}.npy'.format(horizon,n_folds, label) )\n",
    "\n",
    "    final_regrets.append( result[:,-1] )\n",
    "    regret =  np.mean(result, 0) \n",
    "    xcoords = np.arange(0,horizon,1).tolist()\n",
    "    std =  np.std(result,0) \n",
    "    upper_regret = regret + std\n",
    "\n",
    "    if label == 'PM_DMEDc100':\n",
    "        fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b),  dash=  'solid' ), mode='lines',  name='PMDMED (c=100)' ))  \n",
    "\n",
    "    elif label == 'PM_DMEDc10':\n",
    "        fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b),  dash=  'longdash' ), mode='lines',  name='PMDMED (c=10)' )) \n",
    "\n",
    "    elif label == 'TSPM_R1':\n",
    "        fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b),  dash=  'solid' ), mode='lines',  name='TSPM (R=1)' )) \n",
    "\n",
    "    elif label == 'TSPM_R0':\n",
    "        fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b),  dash=  'dot' ), mode='lines',  name='TSPM (R=0)' )) \n",
    "\n",
    "    else:\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b),  dash=  'solid' ), mode='lines',  name=label )) # \n",
    "\n",
    "    if label == 'PM_DMEDc100':\n",
    "        fig.add_trace(   go.Scatter( x=xcoords+xcoords[::-1], y=upper_regret.tolist()+regret.tolist()[::-1],  fill='toself', fillcolor='rgba({},{},{},0.4)'.format(r,g,b), \n",
    "                         line=dict(color='rgba(255,255,255,0)'),   hoverinfo=\"skip\",  showlegend=False )  )\n",
    "    else:\n",
    "        fig.add_trace(   go.Scatter( x=xcoords+xcoords[::-1], y=upper_regret.tolist()+regret.tolist()[::-1],  fill='toself', fillcolor='rgba({},{},{},0.2)'.format(r,g,b), \n",
    "                         line=dict(color='rgba(255,255,255,0)'),   hoverinfo=\"skip\",  showlegend=False )  )\n",
    "    \n",
    "fig.update_layout(legend= dict(yanchor=\"top\",y=0.98,xanchor=\"left\",x=0.1), autosize=False,\n",
    "                  xaxis_title=\"Sequence\", yaxis_title=\"Regret\",  margin=go.layout.Margin( l=0,   r=0,   b=0,    t=0, ),   font=dict(size=13,) )\n",
    "\n",
    "fig.update_yaxes( type=\"log\",range=[0, 5] )\n",
    "fig.write_image(\"./hard_LE.pdf\")\n",
    "\n",
    "fig.update_xaxes( type=\"log\" )\n",
    "fig.write_image(\"./hard_LE_log.pdf\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "final_regrets = np.array(final_regrets)\n",
    "final = [ ( np.argmin(final_regrets[:,i]), i) for i in range(n_folds) ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "### HARD LABEL EFFICIENT:\n",
    "\n",
    "labels = [  'CBP', 'RandCBP'  ]  \n",
    "\n",
    "final_regrets = {}\n",
    "\n",
    "for label in labels:\n",
    "\n",
    "    if label == 'RandCBP':\n",
    "        result = np.load( './results/benchmark_randcbp/label_efficient/LE_hard_{}_{}_Gaussian_1_10_10e7.npy'.format(horizon,n_folds, label) )\n",
    "    else: \n",
    "        result = np.load( './results/label_efficient/hard_{}_{}_{}.npy'.format(horizon,n_folds, label) )\n",
    "\n",
    "    final_regrets[label] =  result[:,-1] \n",
    "\n",
    "final = np.array( [ (1, i) if final_regrets['RandCBP'][i] <= final_regrets['CBP'][i] else (0, i) for i in range(n_folds) ] )\n",
    "\n",
    "print( sum(final[:,0]) )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "72\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "### EASY LABEL EFFICIENT:\n",
    "\n",
    "labels = [  'CBP', 'RandCBP'  ]  \n",
    "\n",
    "final_regrets = {}\n",
    "\n",
    "for label in labels:\n",
    "\n",
    "    if label == 'RandCBP':\n",
    "        result = np.load( './results/benchmark_randcbp/label_efficient/LE_easy_{}_{}_Gaussian_18_10_10e7.npy'.format(horizon,n_folds, label) )\n",
    "    else: \n",
    "        result = np.load( './results/label_efficient/easy_{}_{}_{}.npy'.format(horizon,n_folds, label) )\n",
    "\n",
    "    final_regrets[label] =  result[:,-1] \n",
    "\n",
    "final = np.array( [ (1, i) if final_regrets['RandCBP'][i] <= final_regrets['CBP'][i] else (0, i) for i in range(n_folds) ] )\n",
    "\n",
    "print( sum(final[:,0]) )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "90\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "n_cores = 16\n",
    "n_folds = 100\n",
    "horizon = 100000\n",
    "\n",
    "game = games.label_efficient(  )\n",
    "\n",
    "#feedexp3.FeedExp3(  game, horizon, ),\n",
    "#feedexp3_v3.FeedExp3(  game, horizon, ),\n",
    "#eTSPM.eTSPM_alg(  game, horizon, 1),\n",
    "#TSPM.TSPM_alg(  game, horizon,), bpm.BPM(  game, horizon,  [0.5, 0.5 ], np.identity(2) ) ,\n",
    "\n",
    "#TSPM.TSPM_alg(  game, horizon,), \n",
    "#ucbTSPM_v2.TSPM_alg(game, horizon)  \n",
    "\n",
    "algos = [ random_algo.Random(  game, horizon, ), \n",
    "          cpb.CPB(  game, horizon, 1.01), \n",
    "          None, \n",
    "          PM_DMED.PM_DMED(  game, horizon, 100), \n",
    "          PM_DMED.PM_DMED(  game, horizon, 10), \n",
    "          PM_DMED.PM_DMED(  game, horizon, 5), \n",
    "          PM_DMED.PM_DMED(  game, horizon, 1), \n",
    "          PM_DMED.PM_DMED(  game, horizon, 0.1), \n",
    "          PM_DMED.PM_DMED(  game, horizon, 10), \n",
    "          TSPM.TSPM_alg(  game, horizon, 1),\n",
    "          #TSPM.TSPM_alg(  game, horizon, 0),\n",
    "          bpm.BPM(game, horizon) ]\n",
    "\n",
    "colors = [  [0,0,0],  [250,0,0], [0,250,0], [255,128,0], [255,128,0], [255,128,0], [255,128,0],   [0 , 250, 250], [255 , 0, 255] ] \n",
    "labels = [   'random', 'CBP', 'RandCBP', 'PM_DMEDc100', 'PM_DMEDc10','PM_DMEDc5','PM_DMEDc1', 'TSPM_R1', 'BPM_LEAST'  ]  \n",
    "\n",
    "fig = go.Figure( )\n",
    "\n",
    "final_regrets = []\n",
    "\n",
    "\n",
    "for alg, color, label in list(zip(algos, colors, labels))[::-1]:\n",
    "\n",
    "    r,g,b = color\n",
    "    # result = evaluate_parallel(n_cores, n_folds, horizon, alg, game, 'harsch')\n",
    "    # np.save('./results/label_efficient/hard_{}_{}_{}'.format(horizon,n_folds, label), result)\n",
    "    \n",
    "    if label == 'RandCBP':\n",
    "        result = np.load( './results/benchmark_randcbp/label_efficient/LE_easy_{}_{}_Gaussian_18_10_10e7.npy'.format(horizon,n_folds, label) )\n",
    "    else: \n",
    "        result = np.load( './results/label_efficient/easy_{}_{}_{}.npy'.format(horizon,n_folds, label) )\n",
    "\n",
    "    final_regrets.append( result[:,-1] )\n",
    "    regret =  np.mean(result, 0) \n",
    "    xcoords = np.arange(0,horizon,1).tolist()\n",
    "    std =  np.std(result,0) \n",
    "    upper_regret = regret + std\n",
    "\n",
    "    if label == 'PM_DMEDc100':\n",
    "        fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b),  dash=  'dot' ), mode='lines',  name='PMDMED (c=100)' ))  \n",
    "    elif label == 'PM_DMEDc10':\n",
    "        fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b),  dash=  'longdash' ), mode='lines',  name='PMDMED (c=10)' )) \n",
    "    elif label == 'PM_DMEDc5':\n",
    "        fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b),  dash=  'solid' ), mode='lines',  name='PMDMED (c=5)' )) \n",
    "    elif label == 'PM_DMEDc1':\n",
    "        fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b),  dash=  'longdashdot' ), mode='lines',  name='PMDMED (c=1)' )) \n",
    "    elif label == 'TSPM_R1':\n",
    "        fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b),  dash=  'solid' ), mode='lines',  name='TSPM (R=1)' )) \n",
    "    elif label == 'TSPM_R0':\n",
    "        fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b),  dash=  'dot' ), mode='lines',  name='TSPM (R=0)' )) \n",
    "    else:\n",
    "        fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b),  dash=  'solid' ), mode='lines',  name=label )) # \n",
    "\n",
    "    fig.add_trace(   go.Scatter( x=xcoords+xcoords[::-1], y=upper_regret.tolist()+regret.tolist()[::-1],  fill='toself', fillcolor='rgba({},{},{},0.2)'.format(r,g,b), \n",
    "                         line=dict(color='rgba(255,255,255,0)'),   hoverinfo=\"skip\",  showlegend=False )  )\n",
    "    \n",
    "\n",
    "\n",
    "fig.update_layout(legend= dict(yanchor=\"top\",y=0.98,xanchor=\"left\",x=0.1), autosize=False,\n",
    "                  xaxis_title=\"Sequence\", yaxis_title=\"Regret\",  margin=go.layout.Margin( l=0,   r=0,   b=0,    t=0, ),   font=dict(size=13,) )\n",
    "\n",
    "\n",
    "fig.update_yaxes( type=\"log\",range=[0, 3] )\n",
    "fig.write_image(\"./easy_LE.pdf\")\n",
    "\n",
    "fig.update_xaxes( type=\"log\" )\n",
    "fig.write_image(\"./easy_LE_log.pdf\")\n",
    "\n",
    "# fig.show()\n",
    "\n",
    "final_regrets = np.array(final_regrets)\n",
    "final = [ ( np.argmin(final_regrets[:,i]), i) for i in range(n_folds) ]"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.15 64-bit ('climate-ai': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "interpreter": {
   "hash": "0215ed8d73c40df5de54d647d65b604dcf02460a7de2b27ed9878602c67cf72c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}