{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from functools import partial\n",
    "import pickle as pkl\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "import games\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def evaluate_parallel(nbCores, n_folds, horizon, alg, game, type, label):\n",
    "    print(\"nbCores:\", nbCores, \"nbFolds:\", n_folds, \"Horizon:\", horizon)\n",
    "    pool = Pool(processes = nbCores) \n",
    "    task = Evaluation(horizon, )\n",
    "\n",
    "    np.random.seed(1)\n",
    "    distributions = []\n",
    "    tasks = []\n",
    "    nfold_list =[]\n",
    "    labels = []\n",
    "\n",
    "    for jobid in range(n_folds):\n",
    "        \n",
    "        if type == 'imbalanced' :\n",
    "            p = np.random.uniform(0, 0.2) if np.random.random() < 0.5 else np.random.uniform(0.8, 1)\n",
    "        elif type == 'balanced':\n",
    "            p = np.random.uniform(0.4,0.6)\n",
    "        else:\n",
    "            p = np.random.uniform(0,1)\n",
    "\n",
    "        distributions.append( [p, 1-p] )\n",
    "        tasks.append( type )\n",
    "        nfold_list.append(n_folds)\n",
    "        labels.append( label )\n",
    "\n",
    "    return np.asarray(  pool.map( partial( task.eval_policy_once, alg, game ), zip(distributions ,tasks, nfold_list, labels, range(n_folds)) ) ) \n",
    "\n",
    "\n",
    "\n",
    "class Evaluation:\n",
    "\n",
    "    def __init__(self, horizon, ):\n",
    "        self.horizon = horizon\n",
    "\n",
    "    def get_outcomes(self, game):\n",
    "        outcomes = np.random.choice( game.n_outcomes , p= list( game.outcome_dist.values() ), size= self.horizon) \n",
    "        return outcomes\n",
    "\n",
    "    def get_feedback(self, game, action, outcome):\n",
    "        return game.FeedbackMatrix[ action ][ outcome ]\n",
    "\n",
    "    def eval_policy_once(self, alg, game, job):\n",
    "\n",
    "        alg.reset()\n",
    "\n",
    "        distribution, task, nfold, label, jobid = job\n",
    "\n",
    "        np.random.seed(jobid)\n",
    "\n",
    "        outcome_distribution =  {'spam':distribution[0],'ham':distribution[1]}\n",
    "\n",
    "        game.set_outcome_distribution( outcome_distribution, jobid )\n",
    "        outcomes = self.get_outcomes(game)\n",
    "\n",
    "        action_counter = np.zeros( (game.n_actions, self.horizon) )        \n",
    "\n",
    "        for t in range(self.horizon):\n",
    "\n",
    "            # policy chooses one action\n",
    "            action = alg.get_action(t, None)\n",
    "\n",
    "            # Environment chooses one outcome\n",
    "            outcome = outcomes[t]\n",
    "\n",
    "            # print('t', t, 'action', action, 'outcome', outcome, )\n",
    "            feedback =  self.get_feedback( game, action, outcome )\n",
    "\n",
    "            alg.update(action, feedback, outcome, None, t)\n",
    "\n",
    "            for i in range(game.n_actions):\n",
    "                if i == action:\n",
    "                    action_counter[i][t] = action_counter[i][t-1] +1\n",
    "                else:\n",
    "                    action_counter[i][t] = action_counter[i][t-1]\n",
    "\n",
    "        regret = np.array( [ game.delta(i) for i in range(game.n_actions) ] ).T @ action_counter\n",
    "\n",
    "        with gzip.open( './results/{}/icml_{}_{}_{}_{}_{}.pkl.gz'.format(game.name, task,  self.horizon, nfold, label, jobid) ,'wb') as f:\n",
    "                pkl.dump(regret,f)\n",
    "\n",
    "        print('finished {}'.format(jobid))\n",
    "\n",
    "        return regret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def divide_interval(start, end, k):\n",
    "    intervals = np.linspace(start, end, k ).tolist()\n",
    "    return intervals\n",
    "\n",
    "def obtain_probability(t):\n",
    "    alpha = 1.01\n",
    "    K = 10\n",
    "    sigma = 1/32\n",
    "    epsilon = 0.01\n",
    "    U = np.sqrt( alpha  * np.log(t) ) \n",
    "    rhos = divide_interval(0, U, K)\n",
    "    p_m_hat =  np.array([ np.exp( -(rhos[i]**2) / 2*(sigma**2)  )  for i in range(len(rhos)-1) ] )\n",
    "    p_m = (1 - epsilon) * p_m_hat / p_m_hat.sum()\n",
    "    p_m = p_m.tolist()\n",
    "    p_m.append(epsilon)\n",
    "        \n",
    "    Z = np.random.choice(rhos, p= p_m)\n",
    "    return Z\n",
    "\n",
    "rand = []\n",
    "det = []\n",
    "for t in range(2,20000):\n",
    "    z = obtain_probability(t)\n",
    "    rand.append(z)\n",
    "    det.append( np.sqrt( 1.01 * np.log(t) ) )\n",
    "\n",
    "plt.plot( range(2,20000) , rand, '.', markersize = 2  )\n",
    "plt.plot( range(2,20000) , det  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import randcbp\n",
    "\n",
    "horizon = 5000\n",
    "game = games.apple_tasting(False)\n",
    "# alg = TSPM.TSPM_alg(game, horizon, 1) #, TSPM.TSPM_alg(game, horizon, 0),\n",
    "# alg = cbp.CBP(  game, 1.01) \n",
    "alg = randcbp.RandCBP(  game, 1.01, 1/8, 10, 10e-7) \n",
    "label = 'CBP' #, 'TSPM_0'   \n",
    "task = Evaluation(horizon, )\n",
    "p = 0.9\n",
    "job = [p, 1-p],'imbalanced',96,'CBP', 6\n",
    "result = task.eval_policy_once(alg, game, job)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(len(result)),result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadall_results(path, horizon, n_folds):\n",
    "    result = np.zeros( (n_folds, horizon) )\n",
    "    with gzip.open(  path ,'rb') as f:\n",
    "        for i in range(n_folds):\n",
    "            try:\n",
    "                res = pkl.load(f)\n",
    "                result[i] = res\n",
    "            except EOFError:\n",
    "                break\n",
    "    return result\n",
    "\n",
    "game = 'AT'\n",
    "direct = './results/{}/'.format(game)\n",
    "path = os.path.join(direct, 'other_imbalanced_20000_96_RandCBP.pkl.gz'.format(task) )\n",
    "result = loadall_results(path, horizon, n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# algos = [  randcbp.RandCBP(  game, 1.01, 1/32, 5, 10e-7),  ]\n",
    "# labels = [ 'RandCBP',  ] \n",
    "\n",
    "# algos = [  PM_DMED.PM_DMED(  game, horizon, 1) ]\n",
    "# labels = [ 'PM_DMED'  ] \n",
    "\n",
    "# algos = [ bpm.BPM(game,horizon) ]\n",
    "# labels = [ 'BPM_LEAST' ] \n",
    "\n",
    "# algos = [ random_algo.Random(game,horizon) ]\n",
    "# labels = [ 'random' ] \n",
    "\n",
    "# algos = [ cbp.CBP(  game, 1.01), PM_DMED.PM_DMED(  game, horizon, 1),  ]\n",
    "# labels = [ 'CBP', 'PM_DMED',  ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_cores = 8\n",
    "n_folds = 96\n",
    "horizon = 20000\n",
    "\n",
    "import TSPM\n",
    "import PM_DMED\n",
    "import bpm\n",
    "import cbp\n",
    "# import randcbp\n",
    "import random_algo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "game = games.apple_tasting(False)\n",
    "\n",
    "# algos = [ cbp.CBP(  game, 1.01), \n",
    "#           PM_DMED.PM_DMED(  game, horizon, 1),\n",
    "#           TSPM.TSPM_alg(game, horizon, 1),\n",
    "#           TSPM.TSPM_alg(game, horizon, 0),\n",
    "#           bpm.BPM(game,horizon) ]\n",
    "# labels = [ 'CBP', 'PM_DMED', 'TSPM_1', 'TSPM_0', 'BPM_LEAST',  ]  \n",
    "\n",
    "algos = [ cbp.CBP(  game, 1.01),]\n",
    "labels = [ 'CBP',  ]  \n",
    "\n",
    "\n",
    "# randcbp.RandCBP(  game, 1.01, 1, 10, 10e-7), 'RandCBP',\n",
    "\n",
    "#game = games.label_efficient()\n",
    "#algos = [ cbp.CBP(  game, 1.01),  ] #PM_DMED.PM_DMED(  game, horizon, 1)\n",
    "#labels = [  'CBP' ] #'PM_DMED_1',\n",
    "\n",
    "for game in [ games.apple_tasting(False) ]: #,games.label_efficient()\n",
    "\n",
    "    for task in ['all']:\n",
    "        \n",
    "        for alg, label in zip( algos,  labels):\n",
    "\n",
    "            result = evaluate_parallel(n_cores, n_folds, horizon, alg, game, task, label)\n",
    "\n",
    "            with gzip.open( './results/{}/icml_{}_{}_{}_{}.pkl.gz'.format(game.name, task , horizon, n_folds,  label) ,'wb') as g:\n",
    "\n",
    "                for jobid in range(n_folds):\n",
    "\n",
    "                    with gzip.open(  './results/{}/icml_{}_{}_{}_{}_{}.pkl.gz'.format(game.name, task, horizon, n_folds,  label, jobid) ,'rb') as f:\n",
    "                        r = pkl.load(f)\n",
    "\n",
    "                    pkl.dump(r, g)\n",
    "                            \n",
    "                    bashCommand = 'rm ./results/{}/icml_{}_{}_{}_{}_{}.pkl.gz'.format(game.name, task, horizon, n_folds,  label, jobid)\n",
    "                    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "                    output, error = process.communicate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
