{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocess import Pool\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "import games\n",
    "\n",
    "import cpb\n",
    "# import cpb_uniform\n",
    "import cpb_gaussian\n",
    "\n",
    "import random_algo\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import synthetic_data\n",
    "import cpb_side\n",
    "import cpb_side_gaussian\n",
    "\n",
    "\n",
    "import gzip\n",
    "import pickle as pkl\n",
    "\n",
    "import linucb\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_parallel(nbCores, n_folds, horizon, alg, game, type):\n",
    "    print(\"nbCores:\", nbCores, \"nbFolds:\", n_folds, \"Horizon:\", horizon)\n",
    "    pool = Pool(processes = nbCores) \n",
    "    task = Evaluation(horizon, type)\n",
    "\n",
    "    np.random.seed(1)\n",
    "    distributions = []\n",
    "    context_generators = []\n",
    "\n",
    "    for jobid in range(n_folds):\n",
    "        \n",
    "        p = np.random.uniform(0, 0.2) if type == 'easy' else np.random.uniform(0.4,0.5)\n",
    "        distributions.append( [p, 1-p] )\n",
    "\n",
    "        d = 2\n",
    "        margin =0.01\n",
    "        contexts = synthetic_data.LinearContexts( np.array([0.5,0.5]), 0, d, margin) #synthetic_data.ToyContexts( )\n",
    "        context_generators.append( contexts )\n",
    "\n",
    "    return np.asarray(  pool.map( partial( task.eval_policy_once, alg, game ), zip(distributions , context_generators ,range(n_folds)) ) ) \n",
    "\n",
    "class Evaluation:\n",
    "\n",
    "    def __init__(self, horizon,type ):\n",
    "        self.type = type\n",
    "        self.horizon = horizon\n",
    "        # self.outcome_distribution = outcome_distribution\n",
    "\n",
    "    def get_outcomes(self, game, job_id):\n",
    "        # self.means = runif_in_simplex( self.game.n_outcomes )\n",
    "        outcomes = np.random.choice( game.n_outcomes , p= list( game.outcome_dist.values() ), size= self.horizon) \n",
    "        return outcomes\n",
    "\n",
    "    def get_feedback(self, game, action, outcome):\n",
    "        return game.FeedbackMatrix[ action ][ outcome ]\n",
    "\n",
    "    def get_bandit_feedback(self, game, action, outcome):\n",
    "        return game.banditFeedbackMatrix[ action ][ outcome ]\n",
    "\n",
    "    def eval_policy_once(self, alg, game, job):\n",
    "\n",
    "        distribution, context_generator, jobid = job\n",
    "\n",
    "        np.random.seed(jobid)\n",
    "\n",
    "        # outcome_distribution =  {'spam':0.5,'ham':0.5}\n",
    "        outcome_distribution =  {'spam':distribution[0],'ham':distribution[1]}\n",
    "\n",
    "        game.set_outcome_distribution( outcome_distribution, jobid )\n",
    "        #print('optimal action', game.i_star)\n",
    "\n",
    "        # action_counter = np.zeros( (game.n_actions, self.horizon) )\n",
    "\n",
    "        # generate outcomes obliviously\n",
    "        outcomes = self.get_outcomes(game, jobid)\n",
    "        # contexts = [ context_generator.get_context(outcome) for outcome in outcomes ]\n",
    "        context_generator.generate_unique_context()\n",
    "        contexts = [ context_generator.get_same_context(outcome) for outcome in outcomes ]\n",
    "\n",
    "        cumRegret =  np.zeros(self.horizon, dtype =float)\n",
    "\n",
    "        for t in range(self.horizon):\n",
    "\n",
    "            if t % 10 == 0 :\n",
    "                print(t)\n",
    "\n",
    "            # Environment chooses one outcome and one context associated to this outcome\n",
    "            outcome = outcomes[t]\n",
    "            context = contexts[t]\n",
    "\n",
    "            # print(context.T.shape)\n",
    "            # policy chooses one action\n",
    "            # print('t', t,  'outcome', outcome, 'context', context)\n",
    "            action = alg.get_action(t, context)\n",
    "            # print('t', t, 'action', action, 'outcome', outcome, 'context', context)\n",
    "            \n",
    "            feedback =  self.get_feedback( game, action, outcome )\n",
    "            bandit_feedback =  self.get_bandit_feedback( game, action, outcome )\n",
    "\n",
    "            alg.update(action, feedback, outcome, t, context )\n",
    "            \n",
    "            # print('nu', alg.nu / alg.n )\n",
    "            regret = game.LossMatrix[action, outcome] - np.min( game.LossMatrix[...,outcome] )\n",
    "            # print( 'regret:' , regret )\n",
    "            cumRegret[t] =  regret\n",
    "            # print()\n",
    "            # print()\n",
    "        # regret = np.array( [ game.delta(i) for i in range(game.n_actions) ]).T @ action_counter\n",
    "        #context_regret = np.cumsum( \n",
    "        # cumRegret )\n",
    "\n",
    "        alg.reset()\n",
    "\n",
    "        return  np.cumsum( cumRegret ) #regret"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import PGIDSratio\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "n_cores = 1\n",
    "n_folds = 1\n",
    "horizon = 500\n",
    "\n",
    "game =  games.apple_tasting( False ) \n",
    "\n",
    "\n",
    "alg = PGIDSratio.PGIDSratio( game, horizon, 2 )\n",
    "task = Evaluation(horizon, 'difficult')\n",
    "\n",
    "outcome_distribution = [0.4, 0.6]\n",
    "d = 2\n",
    "margin = 0.01\n",
    "contexts_generator = synthetic_data.LinearContexts( np.array(outcome_distribution), 0, d, margin) #synthetic_data.ToyContexts( ) #\n",
    "job = (outcome_distribution, contexts_generator, 4 )\n",
    "\n",
    "result = task.eval_policy_once(alg, game, job)\n",
    "\n",
    "# n_cores = 8\n",
    "# n_folds = 8\n",
    "# horizon = 1000\n",
    "\n",
    "# result = evaluate_parallel(n_cores, n_folds, horizon, alg, game, 'easy')\n",
    "# regret =  np.mean(result, 0) \n",
    "# xcoords = np.arange(0,horizon,1).tolist()\n",
    "# std =  np.std(result,0) \n",
    "\n",
    "# plt.plot( regret )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "plt.plot(result)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5c767ebeb0>]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "a = np.ones((100,2))\n",
    "b = np.ones(2)\n",
    "c = a @ b\n",
    "c.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import PM_DMED\n",
    "\n",
    "n_cores = 1\n",
    "n_folds = 1\n",
    "horizon = 100\n",
    "\n",
    "# np.seterr(all='raise')\n",
    "\n",
    "# game = games.apple_tasting(False, outcome_distribution) \n",
    "\n",
    "outcome_distribution = [0.8,0.2]\n",
    "job = (outcome_distribution, 1 )\n",
    "\n",
    "\n",
    "game =  games.label_efficient(  ) \n",
    "game.set_outcome_distribution( {'spam':outcome_distribution[0],'ham':outcome_distribution[1]} )\n",
    "print('optimal action', game.i_star)\n",
    "\n",
    "\n",
    "# print('optimal action', game.i_star)\n",
    "alg = cpb.CPB(  game, horizon,1.01) #TSPM.TSPM_alg(  game, horizon, 1)\n",
    "task = Evaluation(horizon, 'easy')\n",
    "\n",
    "result = task.eval_policy_once(alg,game, job)\n",
    "#plt.plot(range(horizon), result)\n",
    "# fig = go.Figure( )\n",
    "# regret = np.array([ game.delta(i) for i in range(game.n_actions) ]).T @ np.mean(result,0) \n",
    "# xcoords = np.arange(0,horizon,1).tolist()\n",
    "\n",
    "# fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='blue'), mode='lines',  name='TPSM' )) # \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_cores = 8\n",
    "n_folds = 50\n",
    "horizon = 10000\n",
    "# outcome_distribution =  {'spam':0.05,'ham':0.95}\n",
    "\n",
    "game = games.label_efficient(  )\n",
    " \n",
    "algos = [ PGIDSratio.PGIDSratio( game, horizon, 2 )   ]\n",
    "\n",
    "\n",
    "colors = [  [0,0,0], [250,0,0], [200,0,0], [0,200,0]   ] #[0,150,0], [0,250,0], [0,150,0], [0,0,250], [0,0,0],  [0,255,0], [0 , 150, 0], [155,155,0], [255,0,0], [0,0,255] , [255,51,255], [255,51,255], [255,20,200]  ] #\n",
    "labels = [  'random',  'CPB',  'RandCPB', 'TSPM'   ]  # 'random', 'TSPM' , 'TSPM (R=0)', 'RandCBP (uncoupled)','CPB uniform', ,'TSPM' , 'ucbTSPM (Auer)' 'FeedExp3 (2001)', 'FeedExp3 (2006)', 'CPB',  'eTSPM (Auer)',\n",
    "\n",
    "fig = go.Figure( )\n",
    "\n",
    "final_regrets = []\n",
    "\n",
    "for alg, color, label in zip( algos, colors, labels):\n",
    "\n",
    "    r,g,b = color\n",
    "    result = evaluate_parallel(n_cores, n_folds, horizon, alg, game, 'harsch')\n",
    "    final_regrets.append( result[:,-1] )\n",
    "    regret =  np.mean(result, 0) \n",
    "    xcoords = np.arange(0,horizon,1).tolist()\n",
    "    std =  np.std(result,0) \n",
    "    upper_regret = regret + std\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b)), mode='lines',  name=label )) # \n",
    "\n",
    "    fig.add_trace(   go.Scatter( x=xcoords+xcoords[::-1], y=upper_regret.tolist()+regret.tolist()[::-1],  fill='toself', fillcolor='rgba({},{},{},0.2)'.format(r,g,b), \n",
    "                         line=dict(color='rgba(255,255,255,0)'),   hoverinfo=\"skip\",  showlegend=False )  )\n",
    "    \n",
    "fig.show(legend=True)\n",
    "fig.update_yaxes(range=[0, 30] )\n",
    "fig.update_layout(legend= dict(yanchor=\"top\",y=0.98,xanchor=\"left\",x=0.77), autosize=False,\n",
    "                  xaxis_title=\"Sequence\", yaxis_title=\"Regret\",  margin=go.layout.Margin( l=0,   r=0,   b=0,    t=0, ),   font=dict(size=13,) )\n",
    "fig.write_image(\"./hard_LE.pdf\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "final_regrets = np.array(final_regrets)\n",
    "final = [ ( np.argmin(final_regrets[:,i]), i) for i in range(n_folds) ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig.update_xaxes(type=\"linear\")\n",
    "fig.update_yaxes(range=[0, 12000] )\n",
    "fig.update_layout(legend= dict(yanchor=\"top\",y=0.98,xanchor=\"left\",x=0.77), autosize=False,\n",
    "                  xaxis_title=\"Sequence\", yaxis_title=\"Regret\",  margin=go.layout.Margin( l=0,   r=0,   b=0,    t=0, ),   font=dict(size=13,) )\n",
    "fig.write_image(\"./hard_LE_log.pdf\")\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_cores = 8\n",
    "n_folds = 200\n",
    "horizon = 5000\n",
    "# outcome_distribution =  {'spam':0.05,'ham':0.95}\n",
    "\n",
    "game = games.label_efficient(  )\n",
    "\n",
    "#feedexp3.FeedExp3(  game, horizon, ),\n",
    "#feedexp3_v3.FeedExp3(  game, horizon, ),\n",
    "#eTSPM.eTSPM_alg(  game, horizon, 1),\n",
    "#TSPM.TSPM_alg(  game, horizon,), bpm.BPM(  game, horizon,  [0.5, 0.5 ], np.identity(2) ) ,\n",
    "\n",
    "#TSPM.TSPM_alg(  game, horizon,), \n",
    "#ucbTSPM_v2.TSPM_alg(game, horizon)  \n",
    "\n",
    "algos = [ random_algo.Random(  game, horizon, ),      \n",
    "        cpb.CPB(  game, horizon, 1.01), \n",
    "        cpb_gaussian.CPB_gaussian(  game, horizon, 1.01, True, 1/16, 10),\n",
    "        TSPM.TSPM_alg(  game, horizon, 1),   ] \n",
    "\n",
    "        #cpb_gaussian_v2.CPB_gaussian(  game, horizon, 1.01, True), \n",
    "        #cpb_gaussian_v2.CPB_gaussian(  game, horizon, 1.01, False), ]\n",
    "        #cpb_gaussian_v2.CPB_gaussian(  game, horizon, 1.01),\n",
    "        #TSPM.TSPM_alg(game, horizon, 1 ) ]\n",
    "        #TSPM.TSPM_alg(game, horizon, 0 )   #eTSPM.eTSPM_alg(game, horizon, 1), cpb_uniform.CPB_uniform(  game, horizon, 1.01), \n",
    "\n",
    "colors = [  [0,0,0], [250,0,0], [200,0,0], [0,200,0]   ] #[0,150,0], [0,250,0], [0,150,0], [0,0,250], [0,0,0],  [0,255,0], [0 , 150, 0], [155,155,0], [255,0,0], [0,0,255] , [255,51,255], [255,51,255], [255,20,200]  ] #\n",
    "labels = [  'random',  'CPB',  'RandCPB', 'TSPM'   ]  # 'random', 'TSPM' , 'TSPM (R=0)', 'RandCBP (uncoupled)','CPB uniform', ,'TSPM' , 'ucbTSPM (Auer)' 'FeedExp3 (2001)', 'FeedExp3 (2006)', 'CPB',  'eTSPM (Auer)',\n",
    "\n",
    "fig = go.Figure( )\n",
    "\n",
    "final_regrets = []\n",
    "\n",
    "for alg, color, label in zip( algos, colors, labels):\n",
    "\n",
    "    r,g,b = color\n",
    "    result = evaluate_parallel(n_cores, n_folds, horizon, alg, game, 'easy')\n",
    "    final_regrets.append( result[:,-1] )\n",
    "    regret =  np.mean(result, 0) \n",
    "    xcoords = np.arange(0,horizon,1).tolist()\n",
    "    std =  np.std(result,0) \n",
    "    upper_regret = regret + std\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b)), mode='lines',  name=label )) # \n",
    "\n",
    "    fig.add_trace(   go.Scatter( x=xcoords+xcoords[::-1], y=upper_regret.tolist()+regret.tolist()[::-1],  fill='toself', fillcolor='rgba({},{},{},0.2)'.format(r,g,b), \n",
    "                         line=dict(color='rgba(255,255,255,0)'),   hoverinfo=\"skip\",  showlegend=False )  )\n",
    "    \n",
    "fig.show(legend=True)\n",
    "fig.update_yaxes(range=[0, 30] )\n",
    "fig.update_layout(legend= dict(yanchor=\"top\",y=0.98,xanchor=\"left\",x=0.77), autosize=False,\n",
    "                  xaxis_title=\"Sequence\", yaxis_title=\"Regret\",  margin=go.layout.Margin( l=0,   r=0,   b=0,    t=0, ),   font=dict(size=13,) )\n",
    "fig.write_image(\"./easy_LE.pdf\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "final_regrets = np.array(final_regrets)\n",
    "final = [ ( np.argmin(final_regrets[:,i]), i) for i in range(n_folds) ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "res = []\n",
    "for i in range(n_folds):\n",
    "    opt = min(final_regrets[:,i])\n",
    "    vec = [ j == opt for j in final_regrets[:,i] ] \n",
    "    #if vec[1]==1 and vec[2] == 1:\n",
    "    #    pass\n",
    "    #else:\n",
    "    res.append(  vec  )\n",
    "\n",
    "#print( np.sum( res,0) )\n",
    "\n",
    "diff = []\n",
    "for i in range(n_folds):\n",
    "    if res[i][1] >= res[i][2]:\n",
    "        diff.append( i )\n",
    "\n",
    "np.random.seed(1)\n",
    "distributions = []\n",
    "for jobid in range(n_folds):\n",
    "    p = np.random.uniform(0.4, 0.5) \n",
    "    distributions.append( [p, 1-p] )\n",
    "\n",
    "distributions_rand = np.array([ distributions[i] for i in diff ])\n",
    "distributions_cbp = np.array([ distributions[i] for i in range(n_folds) if i not in diff ])\n",
    "#print( len( diff ) )\n",
    "print(np.mean(distributions_rand[:,0]), np.std(distributions_rand[:,0]) )\n",
    "print(np.mean(distributions_cbp[:,0]), np.std(distributions_cbp[:,0]) )\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.456154090331781 0.03132638699822154\n",
      "0.43466197585846006 0.024706747598054565\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig.update_xaxes(type=\"log\")\n",
    "fig.update_layout(legend= dict(yanchor=\"top\",y=0.98,xanchor=\"left\",x=0.77), autosize=False,\n",
    "                  xaxis_title=\"Sequence (log-scale)\", yaxis_title=\"Regret\",  margin=go.layout.Margin( l=0,   r=0,   b=0,    t=0, ),   font=dict(size=13,) )\n",
    "fig.write_image(\"./easy_LE_log.pdf\")\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "fig.write_image(\"./easy_LE.pdf\")\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0215ed8d73c40df5de54d647d65b604dcf02460a7de2b27ed9878602c67cf72c"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.15 64-bit ('climate-ai': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}