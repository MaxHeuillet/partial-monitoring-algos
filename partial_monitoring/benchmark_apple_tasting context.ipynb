{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocess import Pool\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "import games\n",
    "\n",
    "import cpb\n",
    "# import cpb_uniform\n",
    "import cpb_gaussian\n",
    "\n",
    "import random_algo\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import synthetic_data\n",
    "import cpb_side\n",
    "import cpb_side_gaussian\n",
    "\n",
    "\n",
    "import gzip\n",
    "import pickle as pkl\n",
    "\n",
    "import linucb\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_parallel(nbCores, n_folds, horizon, alg, game, type):\n",
    "    print(\"nbCores:\", nbCores, \"nbFolds:\", n_folds, \"Horizon:\", horizon)\n",
    "    pool = Pool(processes = nbCores) \n",
    "    task = Evaluation(horizon, type)\n",
    "\n",
    "    np.random.seed(1)\n",
    "    distributions = []\n",
    "    context_generators = []\n",
    "\n",
    "    for jobid in range(n_folds):\n",
    "        \n",
    "        p = np.random.uniform(0, 0.2) if type == 'easy' else np.random.uniform(0.4,0.5)\n",
    "        distributions.append( [p, 1-p] )\n",
    "\n",
    "        d = 2\n",
    "        margin =0.01\n",
    "        contexts = synthetic_data.LinearContexts( np.array([0.5,0.5]), 0, d, margin) #synthetic_data.ToyContexts( )\n",
    "        context_generators.append( contexts )\n",
    "\n",
    "    return np.asarray(  pool.map( partial( task.eval_policy_once, alg, game ), zip(distributions , context_generators ,range(n_folds)) ) ) \n",
    "\n",
    "class Evaluation:\n",
    "\n",
    "    def __init__(self, horizon,type ):\n",
    "        self.type = type\n",
    "        self.horizon = horizon\n",
    "        # self.outcome_distribution = outcome_distribution\n",
    "\n",
    "    def get_outcomes(self, game, job_id):\n",
    "        # self.means = runif_in_simplex( self.game.n_outcomes )\n",
    "        outcomes = np.random.choice( game.n_outcomes , p= list( game.outcome_dist.values() ), size= self.horizon) \n",
    "        return outcomes\n",
    "\n",
    "    def get_feedback(self, game, action, outcome):\n",
    "        return game.FeedbackMatrix[ action ][ outcome ]\n",
    "\n",
    "    def get_bandit_feedback(self, game, action, outcome):\n",
    "        return game.banditFeedbackMatrix[ action ][ outcome ]\n",
    "\n",
    "    def eval_policy_once(self, alg, game, job):\n",
    "\n",
    "        distribution, context_generator, jobid = job\n",
    "\n",
    "        np.random.seed(jobid)\n",
    "\n",
    "        # outcome_distribution =  {'spam':0.5,'ham':0.5}\n",
    "        outcome_distribution =  {'spam':distribution[0],'ham':distribution[1]}\n",
    "\n",
    "        game.set_outcome_distribution( outcome_distribution, jobid )\n",
    "        #print('optimal action', game.i_star)\n",
    "\n",
    "        # action_counter = np.zeros( (game.n_actions, self.horizon) )\n",
    "\n",
    "        # generate outcomes obliviously\n",
    "        outcomes = self.get_outcomes(game, jobid)\n",
    "        # contexts = [ context_generator.get_context(outcome) for outcome in outcomes ]\n",
    "        context_generator.generate_unique_context()\n",
    "        contexts = [ context_generator.get_same_context(outcome) for outcome in outcomes ]\n",
    "\n",
    "        cumRegret =  np.zeros(self.horizon, dtype =float)\n",
    "\n",
    "        for t in range(self.horizon):\n",
    "\n",
    "            if t % 10 == 0 :\n",
    "                print(t)\n",
    "\n",
    "            # Environment chooses one outcome and one context associated to this outcome\n",
    "            outcome = outcomes[t]\n",
    "            context = contexts[t]\n",
    "\n",
    "            # print(context.T.shape)\n",
    "            # policy chooses one action\n",
    "            # print('t', t,  'outcome', outcome, 'context', context)\n",
    "            action = alg.get_action(t, context)\n",
    "            # print('t', t, 'action', action, 'outcome', outcome, 'context', context)\n",
    "            \n",
    "            feedback =  self.get_feedback( game, action, outcome )\n",
    "            bandit_feedback =  self.get_bandit_feedback( game, action, outcome )\n",
    "\n",
    "            alg.update(action, feedback, outcome, t, context )\n",
    "            \n",
    "            # print('nu', alg.nu / alg.n )\n",
    "            regret = game.LossMatrix[action, outcome] - np.min( game.LossMatrix[...,outcome] )\n",
    "            # print( 'regret:' , regret )\n",
    "            cumRegret[t] =  regret\n",
    "            # print()\n",
    "            # print()\n",
    "        # regret = np.array( [ game.delta(i) for i in range(game.n_actions) ]).T @ action_counter\n",
    "        #context_regret = np.cumsum( \n",
    "        # cumRegret )\n",
    "\n",
    "        alg.reset()\n",
    "\n",
    "        return  np.cumsum( cumRegret ) #regret"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "t = 1011\n",
    "a = (t>100) and ( (t%10)==0 )\n",
    "a"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import PGIDSratio\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "n_cores = 1\n",
    "n_folds = 1\n",
    "horizon = 10000\n",
    "\n",
    "game =  games.apple_tasting( False ) \n",
    "\n",
    "\n",
    "alg = PGIDSratio.PGIDSratio( game, horizon, 2 )\n",
    "task = Evaluation(horizon, 'difficult')\n",
    "\n",
    "outcome_distribution = [0.5, 0.5]\n",
    "d = 2\n",
    "margin = 0.01\n",
    "contexts_generator = synthetic_data.LinearContexts( np.array(outcome_distribution), 0, d, margin) #synthetic_data.ToyContexts( ) #\n",
    "job = (outcome_distribution, contexts_generator, 4 )\n",
    "\n",
    "result = task.eval_policy_once(alg, game, job)\n",
    "\n",
    "# n_cores = 8\n",
    "# n_folds = 8\n",
    "# horizon = 1000\n",
    "\n",
    "# result = evaluate_parallel(n_cores, n_folds, horizon, alg, game, 'easy')\n",
    "# regret =  np.mean(result, 0) \n",
    "# xcoords = np.arange(0,horizon,1).tolist()\n",
    "# std =  np.std(result,0) \n",
    "\n",
    "# plt.plot( regret )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/mheuillet/Desktop/attack-detection/partial_monitoring/PGIDSratio.py:86: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tuneidsparam2 = min(1, deltazero / ( abs(deltaone-deltazero) ) )\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "2250\n",
      "2260\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "2330\n",
      "2340\n",
      "2350\n",
      "2360\n",
      "2370\n",
      "2380\n",
      "2390\n",
      "2400\n",
      "2410\n",
      "2420\n",
      "2430\n",
      "2440\n",
      "2450\n",
      "2460\n",
      "2470\n",
      "2480\n",
      "2490\n",
      "2500\n",
      "2510\n",
      "2520\n",
      "2530\n",
      "2540\n",
      "2550\n",
      "2560\n",
      "2570\n",
      "2580\n",
      "2590\n",
      "2600\n",
      "2610\n",
      "2620\n",
      "2630\n",
      "2640\n",
      "2650\n",
      "2660\n",
      "2670\n",
      "2680\n",
      "2690\n",
      "2700\n",
      "2710\n",
      "2720\n",
      "2730\n",
      "2740\n",
      "2750\n",
      "2760\n",
      "2770\n",
      "2780\n",
      "2790\n",
      "2800\n",
      "2810\n",
      "2820\n",
      "2830\n",
      "2840\n",
      "2850\n",
      "2860\n",
      "2870\n",
      "2880\n",
      "2890\n",
      "2900\n",
      "2910\n",
      "2920\n",
      "2930\n",
      "2940\n",
      "2950\n",
      "2960\n",
      "2970\n",
      "2980\n",
      "2990\n",
      "3000\n",
      "3010\n",
      "3020\n",
      "3030\n",
      "3040\n",
      "3050\n",
      "3060\n",
      "3070\n",
      "3080\n",
      "3090\n",
      "3100\n",
      "3110\n",
      "3120\n",
      "3130\n",
      "3140\n",
      "3150\n",
      "3160\n",
      "3170\n",
      "3180\n",
      "3190\n",
      "3200\n",
      "3210\n",
      "3220\n",
      "3230\n",
      "3240\n",
      "3250\n",
      "3260\n",
      "3270\n",
      "3280\n",
      "3290\n",
      "3300\n",
      "3310\n",
      "3320\n",
      "3330\n",
      "3340\n",
      "3350\n",
      "3360\n",
      "3370\n",
      "3380\n",
      "3390\n",
      "3400\n",
      "3410\n",
      "3420\n",
      "3430\n",
      "3440\n",
      "3450\n",
      "3460\n",
      "3470\n",
      "3480\n",
      "3490\n",
      "3500\n",
      "3510\n",
      "3520\n",
      "3530\n",
      "3540\n",
      "3550\n",
      "3560\n",
      "3570\n",
      "3580\n",
      "3590\n",
      "3600\n",
      "3610\n",
      "3620\n",
      "3630\n",
      "3640\n",
      "3650\n",
      "3660\n",
      "3670\n",
      "3680\n",
      "3690\n",
      "3700\n",
      "3710\n",
      "3720\n",
      "3730\n",
      "3740\n",
      "3750\n",
      "3760\n",
      "3770\n",
      "3780\n",
      "3790\n",
      "3800\n",
      "3810\n",
      "3820\n",
      "3830\n",
      "3840\n",
      "3850\n",
      "3860\n",
      "3870\n",
      "3880\n",
      "3890\n",
      "3900\n",
      "3910\n",
      "3920\n",
      "3930\n",
      "3940\n",
      "3950\n",
      "3960\n",
      "3970\n",
      "3980\n",
      "3990\n",
      "4000\n",
      "4010\n",
      "4020\n",
      "4030\n",
      "4040\n",
      "4050\n",
      "4060\n",
      "4070\n",
      "4080\n",
      "4090\n",
      "4100\n",
      "4110\n",
      "4120\n",
      "4130\n",
      "4140\n",
      "4150\n",
      "4160\n",
      "4170\n",
      "4180\n",
      "4190\n",
      "4200\n",
      "4210\n",
      "4220\n",
      "4230\n",
      "4240\n",
      "4250\n",
      "4260\n",
      "4270\n",
      "4280\n",
      "4290\n",
      "4300\n",
      "4310\n",
      "4320\n",
      "4330\n",
      "4340\n",
      "4350\n",
      "4360\n",
      "4370\n",
      "4380\n",
      "4390\n",
      "4400\n",
      "4410\n",
      "4420\n",
      "4430\n",
      "4440\n",
      "4450\n",
      "4460\n",
      "4470\n",
      "4480\n",
      "4490\n",
      "4500\n",
      "4510\n",
      "4520\n",
      "4530\n",
      "4540\n",
      "4550\n",
      "4560\n",
      "4570\n",
      "4580\n",
      "4590\n",
      "4600\n",
      "4610\n",
      "4620\n",
      "4630\n",
      "4640\n",
      "4650\n",
      "4660\n",
      "4670\n",
      "4680\n",
      "4690\n",
      "4700\n",
      "4710\n",
      "4720\n",
      "4730\n",
      "4740\n",
      "4750\n",
      "4760\n",
      "4770\n",
      "4780\n",
      "4790\n",
      "4800\n",
      "4810\n",
      "4820\n",
      "4830\n",
      "4840\n",
      "4850\n",
      "4860\n",
      "4870\n",
      "4880\n",
      "4890\n",
      "4900\n",
      "4910\n",
      "4920\n",
      "4930\n",
      "4940\n",
      "4950\n",
      "4960\n",
      "4970\n",
      "4980\n",
      "4990\n",
      "5000\n",
      "5010\n",
      "5020\n",
      "5030\n",
      "5040\n",
      "5050\n",
      "5060\n",
      "5070\n",
      "5080\n",
      "5090\n",
      "5100\n",
      "5110\n",
      "5120\n",
      "5130\n",
      "5140\n",
      "5150\n",
      "5160\n",
      "5170\n",
      "5180\n",
      "5190\n",
      "5200\n",
      "5210\n",
      "5220\n",
      "5230\n",
      "5240\n",
      "5250\n",
      "5260\n",
      "5270\n",
      "5280\n",
      "5290\n",
      "5300\n",
      "5310\n",
      "5320\n",
      "5330\n",
      "5340\n",
      "5350\n",
      "5360\n",
      "5370\n",
      "5380\n",
      "5390\n",
      "5400\n",
      "5410\n",
      "5420\n",
      "5430\n",
      "5440\n",
      "5450\n",
      "5460\n",
      "5470\n",
      "5480\n",
      "5490\n",
      "5500\n",
      "5510\n",
      "5520\n",
      "5530\n",
      "5540\n",
      "5550\n",
      "5560\n",
      "5570\n",
      "5580\n",
      "5590\n",
      "5600\n",
      "5610\n",
      "5620\n",
      "5630\n",
      "5640\n",
      "5650\n",
      "5660\n",
      "5670\n",
      "5680\n",
      "5690\n",
      "5700\n",
      "5710\n",
      "5720\n",
      "5730\n",
      "5740\n",
      "5750\n",
      "5760\n",
      "5770\n",
      "5780\n",
      "5790\n",
      "5800\n",
      "5810\n",
      "5820\n",
      "5830\n",
      "5840\n",
      "5850\n",
      "5860\n",
      "5870\n",
      "5880\n",
      "5890\n",
      "5900\n",
      "5910\n",
      "5920\n",
      "5930\n",
      "5940\n",
      "5950\n",
      "5960\n",
      "5970\n",
      "5980\n",
      "5990\n",
      "6000\n",
      "6010\n",
      "6020\n",
      "6030\n",
      "6040\n",
      "6050\n",
      "6060\n",
      "6070\n",
      "6080\n",
      "6090\n",
      "6100\n",
      "6110\n",
      "6120\n",
      "6130\n",
      "6140\n",
      "6150\n",
      "6160\n",
      "6170\n",
      "6180\n",
      "6190\n",
      "6200\n",
      "6210\n",
      "6220\n",
      "6230\n",
      "6240\n",
      "6250\n",
      "6260\n",
      "6270\n",
      "6280\n",
      "6290\n",
      "6300\n",
      "6310\n",
      "6320\n",
      "6330\n",
      "6340\n",
      "6350\n",
      "6360\n",
      "6370\n",
      "6380\n",
      "6390\n",
      "6400\n",
      "6410\n",
      "6420\n",
      "6430\n",
      "6440\n",
      "6450\n",
      "6460\n",
      "6470\n",
      "6480\n",
      "6490\n",
      "6500\n",
      "6510\n",
      "6520\n",
      "6530\n",
      "6540\n",
      "6550\n",
      "6560\n",
      "6570\n",
      "6580\n",
      "6590\n",
      "6600\n",
      "6610\n",
      "6620\n",
      "6630\n",
      "6640\n",
      "6650\n",
      "6660\n",
      "6670\n",
      "6680\n",
      "6690\n",
      "6700\n",
      "6710\n",
      "6720\n",
      "6730\n",
      "6740\n",
      "6750\n",
      "6760\n",
      "6770\n",
      "6780\n",
      "6790\n",
      "6800\n",
      "6810\n",
      "6820\n",
      "6830\n",
      "6840\n",
      "6850\n",
      "6860\n",
      "6870\n",
      "6880\n",
      "6890\n",
      "6900\n",
      "6910\n",
      "6920\n",
      "6930\n",
      "6940\n",
      "6950\n",
      "6960\n",
      "6970\n",
      "6980\n",
      "6990\n",
      "7000\n",
      "7010\n",
      "7020\n",
      "7030\n",
      "7040\n",
      "7050\n",
      "7060\n",
      "7070\n",
      "7080\n",
      "7090\n",
      "7100\n",
      "7110\n",
      "7120\n",
      "7130\n",
      "7140\n",
      "7150\n",
      "7160\n",
      "7170\n",
      "7180\n",
      "7190\n",
      "7200\n",
      "7210\n",
      "7220\n",
      "7230\n",
      "7240\n",
      "7250\n",
      "7260\n",
      "7270\n",
      "7280\n",
      "7290\n",
      "7300\n",
      "7310\n",
      "7320\n",
      "7330\n",
      "7340\n",
      "7350\n",
      "7360\n",
      "7370\n",
      "7380\n",
      "7390\n",
      "7400\n",
      "7410\n",
      "7420\n",
      "7430\n",
      "7440\n",
      "7450\n",
      "7460\n",
      "7470\n",
      "7480\n",
      "7490\n",
      "7500\n",
      "7510\n",
      "7520\n",
      "7530\n",
      "7540\n",
      "7550\n",
      "7560\n",
      "7570\n",
      "7580\n",
      "7590\n",
      "7600\n",
      "7610\n",
      "7620\n",
      "7630\n",
      "7640\n",
      "7650\n",
      "7660\n",
      "7670\n",
      "7680\n",
      "7690\n",
      "7700\n",
      "7710\n",
      "7720\n",
      "7730\n",
      "7740\n",
      "7750\n",
      "7760\n",
      "7770\n",
      "7780\n",
      "7790\n",
      "7800\n",
      "7810\n",
      "7820\n",
      "7830\n",
      "7840\n",
      "7850\n",
      "7860\n",
      "7870\n",
      "7880\n",
      "7890\n",
      "7900\n",
      "7910\n",
      "7920\n",
      "7930\n",
      "7940\n",
      "7950\n",
      "7960\n",
      "7970\n",
      "7980\n",
      "7990\n",
      "8000\n",
      "8010\n",
      "8020\n",
      "8030\n",
      "8040\n",
      "8050\n",
      "8060\n",
      "8070\n",
      "8080\n",
      "8090\n",
      "8100\n",
      "8110\n",
      "8120\n",
      "8130\n",
      "8140\n",
      "8150\n",
      "8160\n",
      "8170\n",
      "8180\n",
      "8190\n",
      "8200\n",
      "8210\n",
      "8220\n",
      "8230\n",
      "8240\n",
      "8250\n",
      "8260\n",
      "8270\n",
      "8280\n",
      "8290\n",
      "8300\n",
      "8310\n",
      "8320\n",
      "8330\n",
      "8340\n",
      "8350\n",
      "8360\n",
      "8370\n",
      "8380\n",
      "8390\n",
      "8400\n",
      "8410\n",
      "8420\n",
      "8430\n",
      "8440\n",
      "8450\n",
      "8460\n",
      "8470\n",
      "8480\n",
      "8490\n",
      "8500\n",
      "8510\n",
      "8520\n",
      "8530\n",
      "8540\n",
      "8550\n",
      "8560\n",
      "8570\n",
      "8580\n",
      "8590\n",
      "8600\n",
      "8610\n",
      "8620\n",
      "8630\n",
      "8640\n",
      "8650\n",
      "8660\n",
      "8670\n",
      "8680\n",
      "8690\n",
      "8700\n",
      "8710\n",
      "8720\n",
      "8730\n",
      "8740\n",
      "8750\n",
      "8760\n",
      "8770\n",
      "8780\n",
      "8790\n",
      "8800\n",
      "8810\n",
      "8820\n",
      "8830\n",
      "8840\n",
      "8850\n",
      "8860\n",
      "8870\n",
      "8880\n",
      "8890\n",
      "8900\n",
      "8910\n",
      "8920\n",
      "8930\n",
      "8940\n",
      "8950\n",
      "8960\n",
      "8970\n",
      "8980\n",
      "8990\n",
      "9000\n",
      "9010\n",
      "9020\n",
      "9030\n",
      "9040\n",
      "9050\n",
      "9060\n",
      "9070\n",
      "9080\n",
      "9090\n",
      "9100\n",
      "9110\n",
      "9120\n",
      "9130\n",
      "9140\n",
      "9150\n",
      "9160\n",
      "9170\n",
      "9180\n",
      "9190\n",
      "9200\n",
      "9210\n",
      "9220\n",
      "9230\n",
      "9240\n",
      "9250\n",
      "9260\n",
      "9270\n",
      "9280\n",
      "9290\n",
      "9300\n",
      "9310\n",
      "9320\n",
      "9330\n",
      "9340\n",
      "9350\n",
      "9360\n",
      "9370\n",
      "9380\n",
      "9390\n",
      "9400\n",
      "9410\n",
      "9420\n",
      "9430\n",
      "9440\n",
      "9450\n",
      "9460\n",
      "9470\n",
      "9480\n",
      "9490\n",
      "9500\n",
      "9510\n",
      "9520\n",
      "9530\n",
      "9540\n",
      "9550\n",
      "9560\n",
      "9570\n",
      "9580\n",
      "9590\n",
      "9600\n",
      "9610\n",
      "9620\n",
      "9630\n",
      "9640\n",
      "9650\n",
      "9660\n",
      "9670\n",
      "9680\n",
      "9690\n",
      "9700\n",
      "9710\n",
      "9720\n",
      "9730\n",
      "9740\n",
      "9750\n",
      "9760\n",
      "9770\n",
      "9780\n",
      "9790\n",
      "9800\n",
      "9810\n",
      "9820\n",
      "9830\n",
      "9840\n",
      "9850\n",
      "9860\n",
      "9870\n",
      "9880\n",
      "9890\n",
      "9900\n",
      "9910\n",
      "9920\n",
      "9930\n",
      "9940\n",
      "9950\n",
      "9960\n",
      "9970\n",
      "9980\n",
      "9990\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "plt.plot(result)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5c767ebeb0>]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "a = np.random.randint(5, size=(10,3))\n",
    "idx = np.random.randint(10, size=2)\n",
    "idx\n",
    "b = a[idx,:]\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "# b = np.random.choice(a, size=50, replace=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10, 3)\n",
      "(2, 3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import PM_DMED\n",
    "\n",
    "n_cores = 1\n",
    "n_folds = 1\n",
    "horizon = 100\n",
    "\n",
    "# np.seterr(all='raise')\n",
    "\n",
    "# game = games.apple_tasting(False, outcome_distribution) \n",
    "\n",
    "outcome_distribution = [0.8,0.2]\n",
    "job = (outcome_distribution, 1 )\n",
    "\n",
    "\n",
    "game =  games.label_efficient(  ) \n",
    "game.set_outcome_distribution( {'spam':outcome_distribution[0],'ham':outcome_distribution[1]} )\n",
    "print('optimal action', game.i_star)\n",
    "\n",
    "\n",
    "# print('optimal action', game.i_star)\n",
    "alg = cpb.CPB(  game, horizon,1.01) #TSPM.TSPM_alg(  game, horizon, 1)\n",
    "task = Evaluation(horizon, 'easy')\n",
    "\n",
    "result = task.eval_policy_once(alg,game, job)\n",
    "#plt.plot(range(horizon), result)\n",
    "# fig = go.Figure( )\n",
    "# regret = np.array([ game.delta(i) for i in range(game.n_actions) ]).T @ np.mean(result,0) \n",
    "# xcoords = np.arange(0,horizon,1).tolist()\n",
    "\n",
    "# fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='blue'), mode='lines',  name='TPSM' )) # \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_cores = 8\n",
    "n_folds = 50\n",
    "horizon = 10000\n",
    "# outcome_distribution =  {'spam':0.05,'ham':0.95}\n",
    "\n",
    "game = games.label_efficient(  )\n",
    " \n",
    "algos = [ PGIDSratio.PGIDSratio( game, horizon, 2 )   ]\n",
    "\n",
    "\n",
    "colors = [  [0,0,0], [250,0,0], [200,0,0], [0,200,0]   ] #[0,150,0], [0,250,0], [0,150,0], [0,0,250], [0,0,0],  [0,255,0], [0 , 150, 0], [155,155,0], [255,0,0], [0,0,255] , [255,51,255], [255,51,255], [255,20,200]  ] #\n",
    "labels = [  'random',  'CPB',  'RandCPB', 'TSPM'   ]  # 'random', 'TSPM' , 'TSPM (R=0)', 'RandCBP (uncoupled)','CPB uniform', ,'TSPM' , 'ucbTSPM (Auer)' 'FeedExp3 (2001)', 'FeedExp3 (2006)', 'CPB',  'eTSPM (Auer)',\n",
    "\n",
    "fig = go.Figure( )\n",
    "\n",
    "final_regrets = []\n",
    "\n",
    "for alg, color, label in zip( algos, colors, labels):\n",
    "\n",
    "    r,g,b = color\n",
    "    result = evaluate_parallel(n_cores, n_folds, horizon, alg, game, 'harsch')\n",
    "    final_regrets.append( result[:,-1] )\n",
    "    regret =  np.mean(result, 0) \n",
    "    xcoords = np.arange(0,horizon,1).tolist()\n",
    "    std =  np.std(result,0) \n",
    "    upper_regret = regret + std\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b)), mode='lines',  name=label )) # \n",
    "\n",
    "    fig.add_trace(   go.Scatter( x=xcoords+xcoords[::-1], y=upper_regret.tolist()+regret.tolist()[::-1],  fill='toself', fillcolor='rgba({},{},{},0.2)'.format(r,g,b), \n",
    "                         line=dict(color='rgba(255,255,255,0)'),   hoverinfo=\"skip\",  showlegend=False )  )\n",
    "    \n",
    "fig.show(legend=True)\n",
    "fig.update_yaxes(range=[0, 30] )\n",
    "fig.update_layout(legend= dict(yanchor=\"top\",y=0.98,xanchor=\"left\",x=0.77), autosize=False,\n",
    "                  xaxis_title=\"Sequence\", yaxis_title=\"Regret\",  margin=go.layout.Margin( l=0,   r=0,   b=0,    t=0, ),   font=dict(size=13,) )\n",
    "fig.write_image(\"./hard_LE.pdf\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "final_regrets = np.array(final_regrets)\n",
    "final = [ ( np.argmin(final_regrets[:,i]), i) for i in range(n_folds) ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig.update_xaxes(type=\"linear\")\n",
    "fig.update_yaxes(range=[0, 12000] )\n",
    "fig.update_layout(legend= dict(yanchor=\"top\",y=0.98,xanchor=\"left\",x=0.77), autosize=False,\n",
    "                  xaxis_title=\"Sequence\", yaxis_title=\"Regret\",  margin=go.layout.Margin( l=0,   r=0,   b=0,    t=0, ),   font=dict(size=13,) )\n",
    "fig.write_image(\"./hard_LE_log.pdf\")\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_cores = 8\n",
    "n_folds = 200\n",
    "horizon = 5000\n",
    "# outcome_distribution =  {'spam':0.05,'ham':0.95}\n",
    "\n",
    "game = games.label_efficient(  )\n",
    "\n",
    "#feedexp3.FeedExp3(  game, horizon, ),\n",
    "#feedexp3_v3.FeedExp3(  game, horizon, ),\n",
    "#eTSPM.eTSPM_alg(  game, horizon, 1),\n",
    "#TSPM.TSPM_alg(  game, horizon,), bpm.BPM(  game, horizon,  [0.5, 0.5 ], np.identity(2) ) ,\n",
    "\n",
    "#TSPM.TSPM_alg(  game, horizon,), \n",
    "#ucbTSPM_v2.TSPM_alg(game, horizon)  \n",
    "\n",
    "algos = [ random_algo.Random(  game, horizon, ),      \n",
    "        cpb.CPB(  game, horizon, 1.01), \n",
    "        cpb_gaussian.CPB_gaussian(  game, horizon, 1.01, True, 1/16, 10),\n",
    "        TSPM.TSPM_alg(  game, horizon, 1),   ] \n",
    "\n",
    "        #cpb_gaussian_v2.CPB_gaussian(  game, horizon, 1.01, True), \n",
    "        #cpb_gaussian_v2.CPB_gaussian(  game, horizon, 1.01, False), ]\n",
    "        #cpb_gaussian_v2.CPB_gaussian(  game, horizon, 1.01),\n",
    "        #TSPM.TSPM_alg(game, horizon, 1 ) ]\n",
    "        #TSPM.TSPM_alg(game, horizon, 0 )   #eTSPM.eTSPM_alg(game, horizon, 1), cpb_uniform.CPB_uniform(  game, horizon, 1.01), \n",
    "\n",
    "colors = [  [0,0,0], [250,0,0], [200,0,0], [0,200,0]   ] #[0,150,0], [0,250,0], [0,150,0], [0,0,250], [0,0,0],  [0,255,0], [0 , 150, 0], [155,155,0], [255,0,0], [0,0,255] , [255,51,255], [255,51,255], [255,20,200]  ] #\n",
    "labels = [  'random',  'CPB',  'RandCPB', 'TSPM'   ]  # 'random', 'TSPM' , 'TSPM (R=0)', 'RandCBP (uncoupled)','CPB uniform', ,'TSPM' , 'ucbTSPM (Auer)' 'FeedExp3 (2001)', 'FeedExp3 (2006)', 'CPB',  'eTSPM (Auer)',\n",
    "\n",
    "fig = go.Figure( )\n",
    "\n",
    "final_regrets = []\n",
    "\n",
    "for alg, color, label in zip( algos, colors, labels):\n",
    "\n",
    "    r,g,b = color\n",
    "    result = evaluate_parallel(n_cores, n_folds, horizon, alg, game, 'easy')\n",
    "    final_regrets.append( result[:,-1] )\n",
    "    regret =  np.mean(result, 0) \n",
    "    xcoords = np.arange(0,horizon,1).tolist()\n",
    "    std =  np.std(result,0) \n",
    "    upper_regret = regret + std\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=xcoords, y=regret, line=dict(color='rgb({},{},{})'.format(r,g,b)), mode='lines',  name=label )) # \n",
    "\n",
    "    fig.add_trace(   go.Scatter( x=xcoords+xcoords[::-1], y=upper_regret.tolist()+regret.tolist()[::-1],  fill='toself', fillcolor='rgba({},{},{},0.2)'.format(r,g,b), \n",
    "                         line=dict(color='rgba(255,255,255,0)'),   hoverinfo=\"skip\",  showlegend=False )  )\n",
    "    \n",
    "fig.show(legend=True)\n",
    "fig.update_yaxes(range=[0, 30] )\n",
    "fig.update_layout(legend= dict(yanchor=\"top\",y=0.98,xanchor=\"left\",x=0.77), autosize=False,\n",
    "                  xaxis_title=\"Sequence\", yaxis_title=\"Regret\",  margin=go.layout.Margin( l=0,   r=0,   b=0,    t=0, ),   font=dict(size=13,) )\n",
    "fig.write_image(\"./easy_LE.pdf\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "final_regrets = np.array(final_regrets)\n",
    "final = [ ( np.argmin(final_regrets[:,i]), i) for i in range(n_folds) ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "res = []\n",
    "for i in range(n_folds):\n",
    "    opt = min(final_regrets[:,i])\n",
    "    vec = [ j == opt for j in final_regrets[:,i] ] \n",
    "    #if vec[1]==1 and vec[2] == 1:\n",
    "    #    pass\n",
    "    #else:\n",
    "    res.append(  vec  )\n",
    "\n",
    "#print( np.sum( res,0) )\n",
    "\n",
    "diff = []\n",
    "for i in range(n_folds):\n",
    "    if res[i][1] >= res[i][2]:\n",
    "        diff.append( i )\n",
    "\n",
    "np.random.seed(1)\n",
    "distributions = []\n",
    "for jobid in range(n_folds):\n",
    "    p = np.random.uniform(0.4, 0.5) \n",
    "    distributions.append( [p, 1-p] )\n",
    "\n",
    "distributions_rand = np.array([ distributions[i] for i in diff ])\n",
    "distributions_cbp = np.array([ distributions[i] for i in range(n_folds) if i not in diff ])\n",
    "#print( len( diff ) )\n",
    "print(np.mean(distributions_rand[:,0]), np.std(distributions_rand[:,0]) )\n",
    "print(np.mean(distributions_cbp[:,0]), np.std(distributions_cbp[:,0]) )\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.456154090331781 0.03132638699822154\n",
      "0.43466197585846006 0.024706747598054565\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig.update_xaxes(type=\"log\")\n",
    "fig.update_layout(legend= dict(yanchor=\"top\",y=0.98,xanchor=\"left\",x=0.77), autosize=False,\n",
    "                  xaxis_title=\"Sequence (log-scale)\", yaxis_title=\"Regret\",  margin=go.layout.Margin( l=0,   r=0,   b=0,    t=0, ),   font=dict(size=13,) )\n",
    "fig.write_image(\"./easy_LE_log.pdf\")\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "fig.write_image(\"./easy_LE.pdf\")\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0215ed8d73c40df5de54d647d65b604dcf02460a7de2b27ed9878602c67cf72c"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.15 64-bit ('climate-ai': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}