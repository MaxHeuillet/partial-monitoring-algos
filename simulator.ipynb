{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "\n",
    "def cumsum(vector):\n",
    "    cumulative = []\n",
    "    sum =0\n",
    "    for i in vector:\n",
    "        if i == None:\n",
    "            cumulative.append(None)\n",
    "        else:\n",
    "            sum += i\n",
    "            cumulative.append(sum)\n",
    "    return cumulative\n",
    "\n",
    "def fgsm_attack(target, epsilon, x, y, n_classes):\n",
    "    \n",
    "    if n_classes <=2:\n",
    "        label = y.copy()\n",
    "        dlt =  [target.predict_proba(x)[0][0] - label]\n",
    "    else:\n",
    "        label = np.zeros(n_classes)\n",
    "        label[y] = 1\n",
    "        dlt =  target.predict_proba(x) - label\n",
    "\n",
    "    direction = np.sign( np.matmul( dlt, target[1].coef_ ) )\n",
    "    x_attacked = x + epsilon * direction\n",
    "    return x_attacked[0]\n",
    "\n",
    "\n",
    "\n",
    "def STAP(controler_clf, controler_input, nb_mistakes, i):    \n",
    "\n",
    "    initial_action = controler_clf.predict(controler_input)[0]\n",
    "    r = np.random.uniform(0,1)\n",
    "    flip_proba = np.sqrt( (1+nb_mistakes)/(i+1) )\n",
    "    if (initial_action == 1 or initial_action == 0) and r <= flip_proba:\n",
    "        STAP_action = 1\n",
    "    else:\n",
    "        STAP_action = 0\n",
    "    \n",
    "    return initial_action, STAP_action\n",
    "\n",
    "def CesaBianchi(controler_clf, controler_input, beta, K):\n",
    "\n",
    "    controler_pred = controler_clf.decision_function(controler_input)[0]\n",
    "    initial_action = controler_clf.predict(controler_input)[0] \n",
    "    p = beta / ( beta + abs( controler_pred ) )\n",
    "    cesa_action = np.random.binomial(1, p)\n",
    "    \n",
    "    \n",
    "    return initial_action, cesa_action\n",
    "    \n",
    "\n",
    "def PLOT(epsilon,):\n",
    "    q = np.random.binomial(1, epsilon)\n",
    "\n",
    "\n",
    "def generate_sequence(target, k, t, X_test, y_test,n_classes,epsilon):\n",
    "\n",
    "        R = {}\n",
    "        Sa = []\n",
    "        for i,x,y in enumerate(zip(X_test, y_test)):\n",
    "            x_attacked = fgsm_attack(target, epsilon, [x], y, n_classes)\n",
    "\n",
    "            if i < t:\n",
    "                v = target.loss_function_(x_attacked,y)\n",
    "                R[i] = v\n",
    "                R = {k: v for k, v in sorted(R.items(), key=lambda item: item[1])}\n",
    "            else:\n",
    "                v = target.loss_function_(x_attacked,y)\n",
    "                if v>=R.values()[-1] and len(Sa)<=k:\n",
    "                    del R[ R.values()[-1] ]\n",
    "                    R[i] = v\n",
    "                    R = {k: v for k, v in sorted(R.items(), key=lambda item: item[1])}\n",
    "                    Sa.append(i)\n",
    "\n",
    "        attack_label = [ 1 if i in Sa else 0 for i in range(len(X_test)) ]\n",
    "                    \n",
    "        return attack_label\n",
    "\n",
    "def epoch(loader, model, opt=None):\n",
    "    \"\"\"Standard training/evaluation epoch over the dataset\"\"\"\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "    total_loss, total_err = 0.,0.\n",
    "    for X,y in loader:\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        yp = model(X)\n",
    "        loss = nn.CrossEntropyLoss()(yp,y)\n",
    "        if opt:\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
    "        total_loss += loss.item() * X.shape[0]\n",
    "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\n",
    "\n",
    "class Task:\n",
    "\n",
    "    def __init__(self, n, n_features, n_classes, class_sep, percent_flip, attack_proba, epsilon, seed = 42):\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "        X, y = make_classification(n_samples = n, n_features = n_features,  n_informative = 2, n_redundant = 1, n_classes = n_classes, flip_y = percent_flip, class_sep = class_sep, n_clusters_per_class = 1 )\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=seed)\n",
    "          \n",
    "        train_loader = DataLoader( TensorDataset( Tensor(X_train), Tensor(y_train).type(torch.LongTensor) ) , batch_size = 32, shuffle=True)\n",
    "        test_loader = DataLoader(  TensorDataset( Tensor(X_test), Tensor(y_test).type(torch.LongTensor) ), batch_size = 1, shuffle=False)\n",
    "\n",
    "        ### Train the target classifier:\n",
    "\n",
    "        self.target = nn.Sequential( nn.Linear(n_features, n_classes)).to(device)\n",
    "        opt = optim.SGD( self.target.parameters(), lr=1e-1 )\n",
    "\n",
    "        for t in range(10):\n",
    "            train_err, train_loss = epoch(train_loader, self.target, opt)\n",
    "\n",
    "        self.X_train, self.y_train = X_train, y_train\n",
    "\n",
    "        attack_label = generate_sequence(self.target, 10, 10, X_test, y_test, n_classes, epsilon)\n",
    "        #attack_label = [  np.random.choice([1,0], p=[attack_proba, 1-attack_proba]) for _ in range(len(X_test)) ]\n",
    "        X_test = [ fgsm_attack(self.target, epsilon, [x], y, n_classes) if is_attacked else x for x,y, is_attacked in zip(X_test, y_test, attack_label)  ]\n",
    "        X_test = np.stack( X_test, axis=0 )\n",
    "        self.X_test, self.y_test = X_test, y_test\n",
    "        self.attack_label = attack_label\n",
    "    \n",
    "\n",
    "    def init_controler(self,n_classes):\n",
    "        controler_clf = SGDClassifier(loss = 'hinge')\n",
    "        y_class = np.zeros(n_classes)\n",
    "        y_class[self.y_train[0]]=1\n",
    "        x_init = np.concatenate([self.X_train[0], y_class])\n",
    "        controler_clf.partial_fit( [x_init], [0], [1,0]  ) \n",
    "        return controler_clf\n",
    "\n",
    "    def online(self, method, beta=1 ):\n",
    "\n",
    "        controler_clf = self.init_controler()\n",
    "        regrets = []\n",
    "        K, attacks,i, abs_false_pos, abs_true_pos, false_pos, true_pos,  = 0,0,0,0,0,0,0\n",
    "        for x, y_true, is_attacked in zip(self.X_test, self.y_test, self.attack_label):\n",
    "\n",
    "            target_pred = self.target.predict_proba([x]) \n",
    "            controler_input = np.reshape( np.concatenate(( x, target_pred[0])), (1,-1) )\n",
    "\n",
    "            if method == 'STAP':\n",
    "                initial_action, decision = STAP(controler_clf, controler_input, K, i) \n",
    "            elif method == 'Cesa':\n",
    "                initial_action, decision = CesaBianchi(controler_clf, controler_input, beta, K)\n",
    "\n",
    "            if decision == 1:\n",
    "                if is_attacked != initial_action:\n",
    "                    controler_clf.partial_fit(controler_input, [is_attacked], [1,0])  \n",
    "                    K = K+1  \n",
    "\n",
    "            abs_true_pos = abs_true_pos+1 if decision == 1 and is_attacked == 1 else abs_true_pos\n",
    "            abs_false_pos = abs_false_pos+1 if decision == 1 and is_attacked == 0 else abs_false_pos\n",
    "            true_pos = true_pos+1 if initial_action == 1 and is_attacked == 1 else true_pos\n",
    "            false_pos = false_pos+1 if initial_action == 1 and is_attacked == 0 else false_pos\n",
    "            regret = abs( decision - is_attacked)\n",
    "            regrets.append(regret)\n",
    "            attacks = attacks+1 if is_attacked == 1 else attacks\n",
    "            i+=1\n",
    "\n",
    "        plt.plot( cumsum(regrets) )\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Cumulative Regret')\n",
    "        print('     True positive:{},      False positive:{}'.format(true_pos,false_pos,attacks))\n",
    "        print('Abs. True positive:{}, Abs. False positive:{}, Attacks:{}'.format(abs_true_pos,abs_false_pos,attacks))\n",
    "                \n",
    "    def offline(self):\n",
    "\n",
    "        attack_clf = SGDClassifier(loss = 'hinge')\n",
    "        train_attack_label = [  np.random.choice([1,0], p=[attack_proba, 1-attack_proba]) for _ in range(len(self.X_train)) ]\n",
    "        X_train_attacks = [ fgsm_attack(self.target, epsilon, [x], y, n_classes) if is_attacked else x for x,y, is_attacked in zip(self.X_train, self.y_train, train_attack_label)  ]\n",
    "        X_train_attacks = np.stack( X_train_attacks, axis=0 )\n",
    "    \n",
    "        attack_clf.fit( X_train_attacks, train_attack_label ) \n",
    "        y_pred = attack_clf.predict( self.X_test )\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix( self.attack_label , y_pred).ravel()\n",
    "        print('True positive:{}, False positive:{}, Attacks:{}'.format(tp,fp,sum(self.attack_label) ) )\n",
    "        \n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "n = 1000\n",
    "n_classes = 2\n",
    "classes =  np.arange(0, n_classes)\n",
    "attack_proba =  0.1\n",
    "epsilon = 1\n",
    "n_features = 10\n",
    "class_sep = 1\n",
    "percent_flip = 0.1\n",
    "\n",
    "task = Task(n, n_features, n_classes, class_sep, percent_flip, attack_proba, epsilon)\n",
    "\n",
    "# print(\"Online STAP:\")\n",
    "# task.online('STAP')\n",
    "# print()\n",
    "# print(\"Online Cesa Bianchi:\")\n",
    "# task.online('Cesa',5)\n",
    "# print()\n",
    "# print(\"Offline:\")\n",
    "# task.offline()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m class_sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      8\u001b[0m percent_flip \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m---> 10\u001b[0m task \u001b[38;5;241m=\u001b[39m \u001b[43mTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_sep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpercent_flip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattack_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mTask.__init__\u001b[0;34m(self, n, n_features, n_classes, class_sep, percent_flip, attack_proba, epsilon, seed)\u001b[0m\n\u001b[1;32m     18\u001b[0m     train_err, train_loss \u001b[38;5;241m=\u001b[39m epoch(train_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget, opt)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train \u001b[38;5;241m=\u001b[39m X_train, y_train\n\u001b[0;32m---> 22\u001b[0m attack_label \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#attack_label = [  np.random.choice([1,0], p=[attack_proba, 1-attack_proba]) for _ in range(len(X_test)) ]\u001b[39;00m\n\u001b[1;32m     24\u001b[0m X_test \u001b[38;5;241m=\u001b[39m [ fgsm_attack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget, epsilon, [x], y, n_classes) \u001b[38;5;28;01mif\u001b[39;00m is_attacked \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x,y, is_attacked \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X_test, y_test, attack_label)  ]\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mgenerate_sequence\u001b[0;34m(target, k, t, X_test, y_test, n_classes, epsilon)\u001b[0m\n\u001b[1;32m     79\u001b[0m R \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     80\u001b[0m Sa \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,x,y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(X_test, y_test)):\n\u001b[1;32m     82\u001b[0m     x_attacked \u001b[38;5;241m=\u001b[39m fgsm_attack(target, epsilon, [x], y, n_classes)\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m t:\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0215ed8d73c40df5de54d647d65b604dcf02460a7de2b27ed9878602c67cf72c"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('climate-ai': conda)"
  },
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}