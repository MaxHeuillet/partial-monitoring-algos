{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "\n",
    "def cumsum(vector):\n",
    "    cumulative = []\n",
    "    sum =0\n",
    "    for i in vector:\n",
    "        if i == None:\n",
    "            cumulative.append(None)\n",
    "        else:\n",
    "            sum += i\n",
    "            cumulative.append(sum)\n",
    "    return cumulative\n",
    "\n",
    "\n",
    "\n",
    "def STAP(clf, controler_input, nb_mistakes, i):    \n",
    "\n",
    "    prediction = clf(controler_input)\n",
    "    initial_action = torch.round( nn.Sigmoid()(prediction) )\n",
    "\n",
    "    r = np.random.uniform(0,1)\n",
    "    flip_proba = np.sqrt( (1+nb_mistakes)/(i+1) )\n",
    "\n",
    "    if (initial_action == 1 ) or (initial_action == 0 and r <= flip_proba):\n",
    "        STAP_action = 1\n",
    "    else:\n",
    "        STAP_action = 0\n",
    "    \n",
    "    return initial_action, STAP_action\n",
    "\n",
    "def CesaBianchi(clf, controler_input, beta, K):\n",
    "\n",
    "    prediction = clf(controler_input)\n",
    "    initial_action = torch.round( nn.Sigmoid()(prediction) )\n",
    "\n",
    "    p = beta / ( beta + abs( prediction.item() ) )\n",
    "    cesa_action = np.random.binomial(1, p)\n",
    "    \n",
    "    \n",
    "    return initial_action, cesa_action\n",
    "    \n",
    "\n",
    "def PLOT(epsilon,):\n",
    "    q = np.random.binomial(1, epsilon)\n",
    "\n",
    "\n",
    "def generate_sequence(target, k, t, test_loader,n_classes,epsilon):\n",
    "\n",
    "        R = {}\n",
    "        Sa = []\n",
    "        for i,data in enumerate(test_loader):\n",
    "            x,y = data\n",
    "            x_attacked = fgsm_attack(target, epsilon, x, y, n_classes)\n",
    "\n",
    "            if i < t:\n",
    "                v =  nn.CrossEntropyLoss()( target.clf(x_attacked) ,y)\n",
    "                R[i] = v\n",
    "                R = {k: v for k, v in sorted(R.items(), key=lambda item: item[1])}\n",
    "            else:\n",
    "                v =  nn.CrossEntropyLoss()( target.clf(x_attacked) ,y)\n",
    "                last_value = list(R.values())[-1]\n",
    "                last_key = list(R.keys())[-1]\n",
    "                if v>=last_value and len(Sa)<=k:\n",
    "                    del R[ last_key ]\n",
    "                    R[i] = v\n",
    "                    R = {k: v for k, v in sorted(R.items(), key=lambda item: item[1])}\n",
    "                    Sa.append(i)\n",
    "\n",
    "        attack_label = [ 1 if i in Sa else 0 for i in range(len(test_loader)) ]\n",
    "                    \n",
    "        return attack_label\n",
    "\n",
    "def fgsm_attack(target, epsilon, x, y, n_classes):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "    \n",
    "    if n_classes <=2:\n",
    "        dlt =  target.clf(x)[0] - y\n",
    "    else:\n",
    "        label = torch.zeros(n_classes)\n",
    "        label[y] = 1\n",
    "        dlt =  target.clf( x ) - label\n",
    "\n",
    "    direction = torch.sign( torch.matmul( dlt, target.clf[0].weight ) ).to(device)\n",
    "    x_attacked = x + epsilon * direction\n",
    "    return x_attacked\n",
    "\n",
    "def reset(clf):\n",
    "    for layer in clf.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "\n",
    "\n",
    "class Target:\n",
    "\n",
    "    def __init__(self,  n_classes, n_features, seed = 42):\n",
    "\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "        self.clf = nn.Sequential( nn.Linear(n_features, n_classes)).to(device)\n",
    "        self.opt = optim.SGD( self.clf.parameters(), lr=1e-1 )\n",
    "\n",
    "    def epoch(self, loader, model, opt=None):\n",
    "        \"\"\"Standard training/evaluation epoch over the dataset\"\"\"\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "        total_loss, total_err = 0.,0.\n",
    "        for X,y in loader:\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            yp = model(X)\n",
    "            loss = nn.CrossEntropyLoss()(yp,y)\n",
    "            if opt:\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            \n",
    "            total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
    "            total_loss += loss.item() * X.shape[0]\n",
    "        return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
    "\n",
    "    def train(self, loader, n_epochs=1):\n",
    "        for t in range(n_epochs):\n",
    "            train_err, train_loss = self.epoch(loader, self.clf, self.opt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Controler:\n",
    "\n",
    "    def __init__(self,  n_classes, n_features, seed = 42):\n",
    "\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "        self.clf = nn.Sequential( nn.Linear(n_features, 1) ).to(self.device)\n",
    "        self.opt = optim.SGD( self.clf.parameters(), lr=1e-1 )\n",
    "        self.X_train = torch.Tensor([]).to(self.device)\n",
    "        self.y_train = torch.Tensor([]).to(self.device)\n",
    "\n",
    "    def epoch(self, loader, model, opt=None):\n",
    "        \"\"\"Standard training/evaluation epoch over the dataset\"\"\"\n",
    "        \n",
    "        #total_loss, total_err = 0., 0.\n",
    "        for X,y in loader:\n",
    "            X,y = X.to(self.device), y.to(self.device)\n",
    "            yp = model(X)\n",
    "\n",
    "            loss = nn.BCELoss()(  nn.Sigmoid()(yp) ,y)\n",
    "\n",
    "            if opt:\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            \n",
    "            #total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
    "            #total_loss += loss.item() * X.shape[0]\n",
    "        #return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
    "\n",
    "    def train(self, loader, n_epochs=1):\n",
    "        for _ in range(n_epochs):\n",
    "            self.epoch(loader, self.clf, self.opt)\n",
    "\n",
    "    def append(self, x, y):\n",
    "        self.X_train = torch.cat( (self.X_train,x[0]) )\n",
    "        self.y_train = torch.cat( ( self.y_train,  torch.Tensor([[y]]).to(self.device) ) )\n",
    "\n",
    "    def get_loader(self, batch_size=32):\n",
    "        return DataLoader(  TensorDataset( self.X_train, self.y_train  ), batch_size = batch_size, shuffle=False) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Task:\n",
    "\n",
    "    def __init__(self, n, n_features, n_classes, class_sep, percent_flip, attack_proba, epsilon, seed = 42):\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "        self.attack_proba = attack_proba\n",
    "\n",
    "        self.n_features, self.n_classes = n_features, n_classes\n",
    "        X, y = make_classification(n_samples = n, n_features = n_features,  n_informative = 2, n_redundant = 1, n_classes = n_classes, flip_y = percent_flip, class_sep = class_sep, n_clusters_per_class = 1 )\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=seed)\n",
    "        self.X_train, self.y_train = X_train, y_train\n",
    "        train_loader = DataLoader( TensorDataset( Tensor(X_train).to(self.device), Tensor(y_train).type(torch.LongTensor).to(self.device) ) , batch_size = 32, shuffle=True)\n",
    "        test_loader = DataLoader(  TensorDataset( Tensor(X_test).to(self.device), Tensor(y_test).type(torch.LongTensor).to(self.device) ), batch_size = 1, shuffle=False)\n",
    "\n",
    "        ### Train the target classifier:\n",
    "        self.target = Target(n_classes,n_features)\n",
    "        self.target.train(train_loader, 10)\n",
    "\n",
    "        #attack_label = generate_sequence(self.target, 10, 10, test_loader, n_classes, epsilon)\n",
    "        attack_label = [  np.random.choice([1,0], p=[attack_proba, 1-attack_proba]) for _ in range(len(X_test)) ]\n",
    "        X_test = [ fgsm_attack(self.target, epsilon, data[0], data[1], n_classes) if attack_label[i] else data[0] for i,data in enumerate(test_loader) ]\n",
    "\n",
    "        self.test_loader = DataLoader(  TensorDataset( torch.stack( X_test ).to(self.device), Tensor(y_test).type(torch.LongTensor).to(self.device) ), batch_size = 1, shuffle=False)\n",
    "        self.attack_label = torch.Tensor(attack_label).to(torch.float32)\n",
    "\n",
    "    def online(self, method, beta=1 ):\n",
    "\n",
    "        controler = Controler( 2, self.n_features+self.n_classes)\n",
    "        regrets = []\n",
    "        K, attacks,i, abs_false_pos, abs_true_pos, false_pos, true_pos,  = 0,0,0,0,0,0,0\n",
    "        for i,data in enumerate(self.test_loader):\n",
    "\n",
    "            x, y_true = data[0][0], data[1] \n",
    "            is_attacked = self.attack_label[i]\n",
    "\n",
    "            target_pred = self.target.clf(x) \n",
    "            controler_input = torch.concat( (x, target_pred), axis = 1)\n",
    "\n",
    "            if method == 'STAP':\n",
    "                initial_action, decision = STAP(controler.clf, controler_input, K, i) \n",
    "            elif method == 'Cesa':\n",
    "                initial_action, decision = CesaBianchi(controler.clf, controler_input, beta, K)\n",
    "\n",
    "\n",
    "            if decision == 1:\n",
    "                if is_attacked != initial_action:\n",
    "                    controler.append([controler_input.detach()], is_attacked)\n",
    "                    controler.clf.apply(reset)\n",
    "                    controler.train(  controler.get_loader(), n_epochs=1)  \n",
    "                    K = K+1  \n",
    "\n",
    "            abs_true_pos = abs_true_pos+1 if decision == 1 and is_attacked == 1 else abs_true_pos\n",
    "            abs_false_pos = abs_false_pos+1 if decision == 1 and is_attacked == 0 else abs_false_pos\n",
    "            true_pos = true_pos+1 if initial_action == 1 and is_attacked == 1 else true_pos\n",
    "            false_pos = false_pos+1 if initial_action == 1 and is_attacked == 0 else false_pos\n",
    "            regret = abs( decision - is_attacked)\n",
    "\n",
    "            regrets.append(regret.item())\n",
    "            attacks = attacks+1 if is_attacked == 1 else attacks\n",
    "            i+=1\n",
    "\n",
    "        plt.plot( cumsum(regrets) )\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Cumulative Regret')\n",
    "        print('     True positive:{},      False positive:{}'.format(true_pos,false_pos,attacks))\n",
    "        print('Abs. True positive:{}, Abs. False positive:{}, Attacks:{}'.format(abs_true_pos,abs_false_pos,attacks))\n",
    "                \n",
    "    def offline(self):\n",
    "\n",
    "        attack_clf = Controler( 2, self.n_features)\n",
    "        #train_attack_label = generate_sequence(self.target, 10, 10, test_loader, n_classes, epsilon)\n",
    "        train_attack_label = [  np.random.choice([1,0], p=[self.attack_proba, 1-self.attack_proba]) for _ in range(len(self.X_train)) ]\n",
    "        train_loader = DataLoader( TensorDataset( Tensor(self.X_train).to(self.device), Tensor(self.train_attack_label).type(torch.LongTensor).to(self.device) ) , batch_size = 1, shuffle=True)\n",
    "        X_train_attacks = [ fgsm_attack(self.target, epsilon, data[0], data[1], n_classes) if train_attack_label[i] else data[0] for i,data in enumerate(train_loader) ]\n",
    "        train_loader = DataLoader( TensorDataset( Tensor(X_train_attacks).to(self.device), Tensor(self.y_train).type(torch.LongTensor).to(self.device) ) , batch_size = 1, shuffle=True)\n",
    "        \n",
    "        attack_clf.train(  train_loader, n_epochs=30)  \n",
    "        y_pred = attack_clf.predict( self.X_test )\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix( self.attack_label , y_pred).ravel()\n",
    "        print('True positive:{}, False positive:{}, Attacks:{}'.format(tp,fp,sum(self.attack_label) ) )\n",
    "        \n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "\n",
    "\n",
    "n = 1000\n",
    "n_classes = 2\n",
    "classes =  np.arange(0, n_classes)\n",
    "attack_proba =  0.1\n",
    "epsilon = 10\n",
    "n_features = 10\n",
    "class_sep = 3\n",
    "percent_flip = 0.1\n",
    "\n",
    "\n",
    "# for _ in range(10):\n",
    "\n",
    "task = Task(n, n_features, n_classes, class_sep, percent_flip, attack_proba, epsilon)\n",
    "\n",
    "# task.online('STAP')\n",
    "# task.online('Cesa', 3)\n",
    "# print()\n",
    "print(\"Offline:\")\n",
    "task.offline()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Offline:\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [111]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# task.online('STAP')\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# task.online('Cesa', 3)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# print()\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOffline:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [110]\u001b[0m, in \u001b[0;36mTask.offline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader( TensorDataset( Tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), Tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mLongTensor)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) ) , batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    155\u001b[0m X_train_attacks \u001b[38;5;241m=\u001b[39m [ fgsm_attack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget, epsilon, data[\u001b[38;5;241m0\u001b[39m], data[\u001b[38;5;241m1\u001b[39m], n_classes) \u001b[38;5;28;01mif\u001b[39;00m train_attack_label[i] \u001b[38;5;28;01melse\u001b[39;00m data[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i,data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader) ]\n\u001b[0;32m--> 157\u001b[0m \u001b[43mattack_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[1;32m    158\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m attack_clf\u001b[38;5;241m.\u001b[39mpredict( \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test )\n\u001b[1;32m    160\u001b[0m tn, fp, fn, tp \u001b[38;5;241m=\u001b[39m confusion_matrix( \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_label , y_pred)\u001b[38;5;241m.\u001b[39mravel()\n",
      "Input \u001b[0;32mIn [110]\u001b[0m, in \u001b[0;36mControler.train\u001b[0;34m(self, loader, n_epochs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, loader, n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m---> 64\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [110]\u001b[0m, in \u001b[0;36mControler.epoch\u001b[0;34m(self, loader, model, opt)\u001b[0m\n\u001b[1;32m     48\u001b[0m X,y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     49\u001b[0m yp \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[0;32m---> 51\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBCELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43myp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt:\n\u001b[1;32m     54\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/climate-ai/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/climate-ai/lib/python3.9/site-packages/torch/nn/modules/loss.py:612\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/climate-ai/lib/python3.9/site-packages/torch/nn/functional.py:3056\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3054\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m-> 3056\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3057\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3059\u001b[0m     )\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3062\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def CPB_side():\n",
    "    L = [ [0,1],[1,0] ]\n",
    "    H = [ [None,None],[0,1] ]\n",
    "    N = len(L)\n",
    "    n = np.zeros(N)\n",
    "    P, K, V_ij, v_ijk, W_k, r = 0\n",
    "    for a in range(N): # initialisation\n",
    "        x_a = 0\n",
    "        I_t  = a\n",
    "        n[a] += 1\n",
    "        J_t = H[a]\n",
    "        Y_t = Y_it(J_t)\n",
    "        pi = fit_linear_model(x_t, Y_t)\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0215ed8d73c40df5de54d647d65b604dcf02460a7de2b27ed9878602c67cf72c"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('climate-ai': conda)"
  },
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}