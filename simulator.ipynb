{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "import geometry\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "import target\n",
    "import controler\n",
    "\n",
    "def cumsum(vector):\n",
    "    cumulative = []\n",
    "    sum =0\n",
    "    for i in vector:\n",
    "        if i == None:\n",
    "            cumulative.append(None)\n",
    "        else:\n",
    "            sum += i\n",
    "            cumulative.append(sum)\n",
    "    return cumulative\n",
    "\n",
    "\n",
    "\n",
    "def STAP(clf, controler_input, nb_mistakes, i):    \n",
    "\n",
    "    prediction = clf(controler_input)\n",
    "    initial_action = torch.round( nn.Sigmoid()(prediction) )\n",
    "\n",
    "    r = np.random.uniform(0,1)\n",
    "    flip_proba = np.sqrt( (1+nb_mistakes)/(i+1) )\n",
    "\n",
    "    if (initial_action == 1 ) or (initial_action == 0 and r <= flip_proba):\n",
    "        STAP_action = 1\n",
    "    else:\n",
    "        STAP_action = 0\n",
    "    \n",
    "    return initial_action, STAP_action\n",
    "\n",
    "def CesaBianchi(clf, controler_input, beta, K):\n",
    "\n",
    "    prediction = clf(controler_input)\n",
    "    initial_action = torch.round( nn.Sigmoid()(prediction) )\n",
    "\n",
    "    p = beta / ( beta + abs( prediction.item() ) )\n",
    "    cesa_action = np.random.binomial(1, p)\n",
    "    \n",
    "    \n",
    "    return initial_action, cesa_action\n",
    "    \n",
    "\n",
    "def PLOT(epsilon,):\n",
    "    q = np.random.binomial(1, epsilon)\n",
    "\n",
    "\n",
    "def generate_sequence(target, k, t, test_loader,n_classes,epsilon):\n",
    "\n",
    "        R = {}\n",
    "        Sa = []\n",
    "        for i,data in enumerate(test_loader):\n",
    "            x,y = data\n",
    "            x_attacked = fgsm_attack(target, epsilon, x, y, n_classes)\n",
    "\n",
    "            if i < t:\n",
    "                v =  nn.CrossEntropyLoss()( target.clf(x_attacked) ,y)\n",
    "                R[i] = v\n",
    "                R = {k: v for k, v in sorted(R.items(), key=lambda item: item[1])}\n",
    "            else:\n",
    "                v =  nn.CrossEntropyLoss()( target.clf(x_attacked) ,y)\n",
    "                last_value = list(R.values())[-1]\n",
    "                last_key = list(R.keys())[-1]\n",
    "                if v>=last_value and len(Sa)<=k:\n",
    "                    del R[ last_key ]\n",
    "                    R[i] = v\n",
    "                    R = {k: v for k, v in sorted(R.items(), key=lambda item: item[1])}\n",
    "                    Sa.append(i)\n",
    "\n",
    "        attack_label = [ 1 if i in Sa else 0 for i in range(len(test_loader)) ]\n",
    "                    \n",
    "        return attack_label\n",
    "\n",
    "def fgsm_attack(target, epsilon, x, y, n_classes):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "    \n",
    "    if n_classes <=2:\n",
    "        dlt =  target.clf(x)[0] - y\n",
    "    else:\n",
    "        label = torch.zeros(n_classes)\n",
    "        label[y] = 1\n",
    "        dlt =  target.clf( x ) - label\n",
    "\n",
    "    direction = torch.sign( torch.matmul( dlt, target.clf[0].weight ) ).to(device)\n",
    "    x_attacked = x + epsilon * direction\n",
    "    return x_attacked\n",
    "\n",
    "def reset(clf):\n",
    "    for layer in clf.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class Task:\n",
    "\n",
    "    def __init__(self, n, n_features, n_classes, class_sep, percent_flip, attack_proba, epsilon, seed = 42):\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "        self.attack_proba = attack_proba\n",
    "\n",
    "        self.n_features, self.n_classes = n_features, n_classes\n",
    "        X, y = make_classification(n_samples = n, n_features = n_features,  n_informative = 2, n_redundant = 1, n_classes = n_classes, flip_y = percent_flip, class_sep = class_sep, n_clusters_per_class = 1 )\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=seed)\n",
    "        self.X_train, self.y_train = X_train, y_train\n",
    "        train_loader = DataLoader( TensorDataset( Tensor(X_train).to(self.device), Tensor(y_train).type(torch.LongTensor).to(self.device) ) , batch_size = 32, shuffle=True)\n",
    "        test_loader = DataLoader(  TensorDataset( Tensor(X_test).to(self.device), Tensor(y_test).type(torch.LongTensor).to(self.device) ), batch_size = 1, shuffle=False)\n",
    "\n",
    "        ### Train the target classifier:\n",
    "        self.target = target.Target(n_classes,n_features)\n",
    "        self.target.train(train_loader, 10)\n",
    "\n",
    "        #attack_label = generate_sequence(self.target, 10, 10, test_loader, n_classes, epsilon)\n",
    "        attack_label = [  np.random.choice([1,0], p=[attack_proba, 1-attack_proba]) for _ in range(len(X_test)) ]\n",
    "        X_test = [ fgsm_attack(self.target, epsilon, data[0], data[1], n_classes) if attack_label[i] else data[0] for i,data in enumerate(test_loader) ]\n",
    "\n",
    "        self.test_loader = DataLoader(  TensorDataset( torch.stack( X_test ).to(self.device), Tensor(y_test).type(torch.LongTensor).to(self.device) ), batch_size = 1, shuffle=False)\n",
    "        self.attack_label = torch.Tensor(attack_label).to(torch.float32)\n",
    "\n",
    "                    \n",
    "    # def offline(self):\n",
    "\n",
    "    #     attack_clf = Controler( 2, self.n_features)\n",
    "    #     #train_attack_label = generate_sequence(self.target, 10, 10, test_loader, n_classes, epsilon)\n",
    "    #     train_attack_label = [  np.random.choice([1,0], p=[self.attack_proba, 1-self.attack_proba]) for _ in range(len(self.X_train)) ]\n",
    "    #     train_loader = DataLoader( TensorDataset( Tensor(self.X_train).to(self.device), Tensor(self.train_attack_label).type(torch.LongTensor).to(self.device) ) , batch_size = 1, shuffle=True)\n",
    "    #     X_train_attacks = [ fgsm_attack(self.target, epsilon, data[0], data[1], n_classes) if train_attack_label[i] else data[0] for i,data in enumerate(train_loader) ]\n",
    "    #     train_loader = DataLoader( TensorDataset( Tensor(X_train_attacks).to(self.device), Tensor(self.y_train).type(torch.LongTensor).to(self.device) ) , batch_size = 1, shuffle=True)\n",
    "        \n",
    "    #     attack_clf.train(  train_loader, n_epochs=30)  \n",
    "    #     y_pred = attack_clf.predict( self.X_test )\n",
    "\n",
    "    #     tn, fp, fn, tp = confusion_matrix( self.attack_label , y_pred).ravel()\n",
    "    #     print('True positive:{}, False positive:{}, Attacks:{}'.format(tp,fp,sum(self.attack_label) ) )\n",
    "\n",
    "    def online(self, method, beta=1 ):\n",
    "\n",
    "        control = controler.Controler( 2, self.n_features+self.n_classes)\n",
    "        regrets = []\n",
    "        K, attacks,i, abs_false_pos, abs_true_pos, false_pos, true_pos,  = 0,0,0,0,0,0,0\n",
    "        for i,data in enumerate(self.test_loader):\n",
    "\n",
    "            x, y_true = data[0][0], data[1] \n",
    "            is_attacked = self.attack_label[i]\n",
    "\n",
    "            target_pred = self.target.clf(x) \n",
    "            controler_input = torch.concat( (x, target_pred), axis = 1)\n",
    "\n",
    "            if method == 'STAP':\n",
    "                initial_action, decision = STAP(control.clf, controler_input, K, i) \n",
    "            elif method == 'Cesa':\n",
    "                initial_action, decision = CesaBianchi(control.clf, controler_input, beta, K)\n",
    "\n",
    "            if decision == 1:\n",
    "                if is_attacked != initial_action:\n",
    "                    control.collect_fit([controler_input.detach()], is_attacked)\n",
    "                    K = K+1  \n",
    "\n",
    "            abs_true_pos = abs_true_pos+1 if decision == 1 and is_attacked == 1 else abs_true_pos\n",
    "            abs_false_pos = abs_false_pos+1 if decision == 1 and is_attacked == 0 else abs_false_pos\n",
    "            true_pos = true_pos+1 if initial_action == 1 and is_attacked == 1 else true_pos\n",
    "            false_pos = false_pos+1 if initial_action == 1 and is_attacked == 0 else false_pos\n",
    "            regret = abs( decision - is_attacked)\n",
    "\n",
    "            regrets.append(regret.item())\n",
    "            attacks = attacks+1 if is_attacked == 1 else attacks\n",
    "            i+=1\n",
    "\n",
    "        plt.plot( cumsum(regrets) )\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Cumulative Regret')\n",
    "        print('     True positive:{},      False positive:{}'.format(true_pos,false_pos,attacks))\n",
    "        print('Abs. True positive:{}, Abs. False positive:{}, Attacks:{}'.format(abs_true_pos,abs_false_pos,attacks))\n",
    "\n",
    "    def f(self, alpha, t):\n",
    "        return (alpha ** 1/3) * (t**2/3) * ( np.log(t)**1/3 )\n",
    "\n",
    "    def W_k(L, H, pair,mathcal_K_plus):\n",
    "        v_ij = geometry.observer_vector(L, H, pair[0], pair[1], mathcal_K_plus)\n",
    "        return max( [ np.linalg.norm( v_ij[k],'inf') for k in mathcal_K_plus ]  )\n",
    "\n",
    "    def cpb_side(self,):\n",
    "\n",
    "        controlers = [ controler.Controler( 2, self.n_features+self.n_classes), controler.Controler( 2, self.n_features+self.n_classes) ]\n",
    "        # alpha = 1.1 #alpha > 1\n",
    "        L = [ [0,1],[1,0] ]\n",
    "        H = [ [None,None],[0,1] ]\n",
    "        mathcal_N = [0,1]\n",
    "        mathcal_M = [0,1,None]\n",
    "        N = len(L)\n",
    "        n = np.zeros(N)\n",
    "        # mathcal_P = [ a for a in mathcal_N if geometry.isParetoOptimal(1, L)] # set of pareto optimal actions\n",
    "        # mathcal_K = [ pair for pair in list( itertools.combinations([0,1], 2) ) if geometry.areNeighbours(pair[0], pair[1], L) ] #set of unordered neighboring actions\n",
    "        \n",
    "        V_ij, v_ijk, W_k, r = [0]*4\n",
    "\n",
    "        for t,data in enumerate(self.test_loader):\n",
    "            x, y_true = data[0][0], data[1] \n",
    "            target_pred = self.target.clf(x) \n",
    "            controler_input = torch.concat( (x, target_pred), axis = 1)\n",
    "            half_space = collections.defaultdict(dict)\n",
    "\n",
    "            if t < mathcal_N:  # initialisation\n",
    "                I  = t\n",
    "                n[t] += 1\n",
    "                J = H[ I ][ y_true ]\n",
    "                #print(str(I)+' '+str(J) )\n",
    "                controlers[t].collect_fit([controler_input.detach()], J)\n",
    "\n",
    "            else:\n",
    "                q,w = np.zeros(N), np.zeros(N)\n",
    "                for i in mathcal_N:\n",
    "                    q[i] = controlers[i].clf(controler_input)  \n",
    "                    w[i] =  controlers[i].confidence()\n",
    "\n",
    "                for pair in mathcal_K:\n",
    " \n",
    "                    mathcal_K_plus =  geometry.Neighbourhood(pair[0], pair[1], L) #neighborhood action set of pair \n",
    "                    v_ij = geometry.observer_vector(L, H, pair[0], pair[1], mathcal_K_plus)\n",
    "                    d_ij = sum( [  v_ij[k].T @ q[k]   for k in mathcal_K_plus ] )\n",
    "                    c_ij = sum( [  np.linalg.norm( v_ij[k] ) @ w[k]   for k in mathcal_K_plus ] )\n",
    "                    if abs( d_ij ) >= c_ij:\n",
    "                        half_space[ pair[0] ][ pair[1] ] = np.sign(d_ij)\n",
    "                    else:\n",
    "                        half_space[ pair[0] ][ pair[1] ] = 0\n",
    "\n",
    "                    mathcal_P_t, mathcal_K_t = geometry.get_polytope(half_space, L, mathcal_N, mathcal_P, mathcal_K)\n",
    "\n",
    "            mu_k = 0.1\n",
    "            K_plus_t = np.concatenate( [ geometry.Neighbourhood(pair[0], pair[1], L) for pair in mathcal_K_t ] )\n",
    "            mathcal_V_t = np.concatenate( [  geometry.observer_vector(L, H, pair[0], pair[1], mathcal_K_plus) for pair in mathcal_K_t ] )\n",
    "            mathcal_R_t = np.array( [ k for k in mathcal_N if n[k]<= mu_k * self.f(alpha, t) ] )\n",
    "            mathcal_S_t = np.concatenate( [ mathcal_P_t , K_plus_t , np.intersect1d(mathcal_V_t, mathcal_R_t) ] )\n",
    "            values = [ W_k(L, H, pair,mathcal_K_plus)/n[i] for i in mathcal_S_t ]\n",
    "            I = np.argmax(values)\n",
    "            if I in np.setdiff1d( mathcal_V_t, np.concatenate([mathcal_P_t,K_plus_t]) ):\n",
    "                r += 1\n",
    "            J = H[ I ][ y_true ]\n",
    "            controlers[ I ].collect_fit([controler_input.detach()], J)        \n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3305853621.py, line 206)",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [5]\u001b[0;36m\u001b[0m\n\u001b[0;31m    half_space[][] = np.sign(d_ij)\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "n = 1000\n",
    "n_classes = 2\n",
    "classes =  np.arange(0, n_classes)\n",
    "attack_proba =  0.1\n",
    "epsilon = 10\n",
    "n_features = 10\n",
    "class_sep = 3\n",
    "percent_flip = 0.1\n",
    "\n",
    "\n",
    "task = Task(n, n_features, n_classes, class_sep, percent_flip, attack_proba, epsilon)\n",
    "task.cpb_side()\n",
    "\n",
    "# task.online('STAP')\n",
    "# task.online('Cesa', 3)\n",
    "# print()\n",
    "#print(\"Offline:\")\n",
    "#task.offline()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "class PMGame:\n",
    "\n",
    "    def __init__(self, L, H):\n",
    "\n",
    "        self.LossMatrix = L\n",
    "        self.FeedbackMatrix = H\n",
    "        self.N = L.shape[0] # Number of learner actions\n",
    "        self.M = H.shape[0] # Number of environment outcomes\n",
    "        self.Actions_dict = { a : \"{0}\".format(a) for a in range(self.N)} # Actions semantic\n",
    "        self.Outcomes_dict = { a : \"{0}\".format(a) for a in range(self.M)} # Outcomes semantic\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "L = np.array([ [0,1],[1,0] ])\n",
    "H = np.array([ ['no_feedback','no_feedback'],[0,1] ])\n",
    "\n",
    "# pm = PMGame(L,H)\n",
    "# geometry.ProblemClass(pm)\n",
    "\n",
    "# print(\"Loss matrix:\")\n",
    "# print(L)\n",
    "# for i in range(L.shape[0]):\n",
    "#     print()\n",
    "#     print(\"Domination matrix for action\", i, \":\" )\n",
    "#     print(geometry.domination_matrix(i,L) )\n",
    "#     print(\"Domination polytope:\", geometry.DominationPolytope(i,L).minimized_generators() )\n",
    "#     print(\"dominating:\", geometry.isNonDominated(i,L) )\n",
    "#     print(\"Strict Domination polytope:\", geometry.StrictDominationPolytope(i,L).minimized_generators() )\n",
    "#     print(\"strictly dominating:\", geometry.isStrictlyNonDominated(i,L) )\n",
    "#     print(\"degenerated:\", geometry.isDegenerated(i,L) )\n",
    "#     print(\"Pareto Optimal:\", geometry.isParetoOptimal(i, L) )\n",
    "\n",
    "\n",
    "# geometry.global_signal(H)\n",
    "# mathcal_K = [ pair for pair in list( itertools.permutations([0,1], 2) ) if geometry.areNeighbours(pair[0], pair[1], L) ] #set of unordered neighboring actions\n",
    "# mathcal_K"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0215ed8d73c40df5de54d647d65b604dcf02460a7de2b27ed9878602c67cf72c"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('climate-ai': conda)"
  },
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}